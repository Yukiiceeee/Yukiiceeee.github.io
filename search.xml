<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>Mem0：Building Production-Ready AI Agents with Scalable Long-Term Memory</title>
      <link href="/2025/10/20/lun-wen-mem0-building-production-ready-ai-agents-with-scalable-long-term-memory/"/>
      <url>/2025/10/20/lun-wen-mem0-building-production-ready-ai-agents-with-scalable-long-term-memory/</url>
      
        <content type="html"><![CDATA[<p>原文链接：<a href="https://arxiv.org/abs/2504.19413">https://arxiv.org/abs/2504.19413</a></p><h3 id="Background-Motivation"><a href="#Background-Motivation" class="headerlink" title="Background &amp; Motivation"></a>Background &amp; Motivation</h3><p>论文针对现有 Agent 系统记忆能力有限，从而导致长时间对话时，容易忘记过去的信息或是给出错误解答的问题，尝试设计一种记忆架构来维护一个“记忆库”，从而帮助 Agent 在每次解决问题时，能够调用已有记忆解决问题，并能不断更新记忆。</p><p><img src="https://cyan-1314223569.cos.ap-beijing.myqcloud.com/test/Pasted%20image%2020251019220041.png" alt="缺乏记忆机制与具备记忆机制的 Agent 系统对比"></p><p>为了弥补这一缺陷，本文提出了 <strong>Mem0</strong>，一种记忆架构，它能够动态地提取和整合对话中的关键信息，让 AI 系统能记住重要内容并跨会话持续对话。进一步，论文还提出了 <strong>Mem0g</strong>，在 Mem0 的基础上加入了知识图谱，构建图结构记忆。</p><h3 id="Method"><a href="#Method" class="headerlink" title="Method"></a>Method</h3><h4 id="Mem0"><a href="#Mem0" class="headerlink" title="Mem0"></a>Mem0</h4><p><strong>Mem0</strong> 的架构核心在于记忆提取与记忆更新机制，旨在确保 AI 系统能够动态地提取对话中的关键信息，并有效地更新其记忆库。这个过程分为两个主要阶段：<strong>记忆提取（Extraction）</strong> 和 <strong>记忆更新（Update）</strong>。</p><p><img src="https://cyan-1314223569.cos.ap-beijing.myqcloud.com/test/Pasted%20image%2020251019220421.png" alt="Mem0 的整体架构图"></p><h5 id="提取阶段"><a href="#提取阶段" class="headerlink" title="提取阶段"></a>提取阶段</h5><p>当系统接收到一个新的消息对（如用户提问和AI回答）时，提取阶段便会启动。为了准确理解当前对话的上下文，系统会结合两种信息源：</p><ul><li><strong>全局上下文</strong>：从数据库中检索的整个对话的摘要 $S$，提供对话的宏观主题。</li><li><strong>局部上下文</strong>：最近消息序列 ${m_{t-m},…,m_{t-2}}$。</li></ul><p>组合成一个完整的提示（prompt）<strong>P</strong>，输入给LLM实现的抽取函数 <strong>ϕ</strong>。LLM会基于这些信息，抽取出本轮对话中值得记忆的关键信息（如“用户是素食主义者”），形成一组候选记忆。</p><p>在摘要生成阶段，会采用一个异步生成模块。当新的对话消息进入系统后，指导大模型根据对话信息生成摘要：</p><pre class=" language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">_create_procedural_memory</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> messages<span class="token punctuation">,</span> metadata<span class="token operator">=</span>None<span class="token punctuation">,</span> prompt<span class="token operator">=</span>None<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">"""    # 异步摘要生成模块：创建程序化记忆（会话摘要）    # 该函数接收对话消息，使用LLM生成一个摘要，并将其存储为特殊类型的记忆        Args:        messages (list): 待处理的对话消息列表        metadata (dict): 存储元数据信息        prompt (str, optional): 自定义提示词，默认使用系统提示    """</span>    logger<span class="token punctuation">.</span>info<span class="token punctuation">(</span><span class="token string">"Creating procedural memory"</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># 1. 构建系统提示和用户消息，用于指导LLM生成摘要</span>    parsed_messages <span class="token operator">=</span> <span class="token punctuation">[</span>        <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;"role": "system", "content": prompt or PROCEDURAL_MEMORY_SYSTEM_PROMPT&amp;#125;,</span>        <span class="token operator">*</span>messages<span class="token punctuation">,</span>        <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;</span>            <span class="token string">"role"</span><span class="token punctuation">:</span> <span class="token string">"user"</span><span class="token punctuation">,</span>            <span class="token string">"content"</span><span class="token punctuation">:</span> <span class="token string">"Create procedural memory of the above conversation."</span><span class="token punctuation">,</span>        <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#125;,</span>    <span class="token punctuation">]</span>    <span class="token keyword">try</span><span class="token punctuation">:</span>        <span class="token comment" spellcheck="true"># 2. 使用LLM生成对话的摘要记忆</span>        procedural_memory <span class="token operator">=</span> self<span class="token punctuation">.</span>llm<span class="token punctuation">.</span>generate_response<span class="token punctuation">(</span>messages<span class="token operator">=</span>parsed_messages<span class="token punctuation">)</span>    <span class="token keyword">except</span> Exception <span class="token keyword">as</span> e<span class="token punctuation">:</span>        logger<span class="token punctuation">.</span>error<span class="token punctuation">(</span>f<span class="token string">"Error generating procedural memory summary: &amp;#123;e&amp;#125;"</span><span class="token punctuation">)</span>        <span class="token keyword">raise</span>    <span class="token keyword">if</span> metadata <span class="token keyword">is</span> None<span class="token punctuation">:</span>        <span class="token keyword">raise</span> ValueError<span class="token punctuation">(</span><span class="token string">"Metadata cannot be done for procedural memory."</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># 3. 标记这是一个程序化记忆（会话摘要）</span>    metadata<span class="token punctuation">[</span><span class="token string">"memory_type"</span><span class="token punctuation">]</span> <span class="token operator">=</span> MemoryType<span class="token punctuation">.</span>PROCEDURAL<span class="token punctuation">.</span>value        <span class="token comment" spellcheck="true"># 4. 为摘要生成向量嵌入</span>    embeddings <span class="token operator">=</span> self<span class="token punctuation">.</span>embedding_model<span class="token punctuation">.</span>embed<span class="token punctuation">(</span>procedural_memory<span class="token punctuation">,</span> memory_action<span class="token operator">=</span><span class="token string">"add"</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># 5. 创建记忆并存储在向量数据库中</span>    memory_id <span class="token operator">=</span> self<span class="token punctuation">.</span>_create_memory<span class="token punctuation">(</span>procedural_memory<span class="token punctuation">,</span> <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;procedural_memory: embeddings&amp;#125;, metadata=metadata)</span>    capture_event<span class="token punctuation">(</span><span class="token string">"mem0._create_procedural_memory"</span><span class="token punctuation">,</span> self<span class="token punctuation">,</span> <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;"memory_id": memory_id, "sync_type": "sync"&amp;#125;)</span>    <span class="token comment" spellcheck="true"># 6. 返回创建的记忆结果</span>    result <span class="token operator">=</span> <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;"results": [&amp;#123;"id": memory_id, "memory": procedural_memory, "event": "ADD"&amp;#125;]&amp;#125;</span>    <span class="token keyword">return</span> result</code></pre><p>Mem0 会将 <strong>会话摘要</strong> 和 <strong>最近消息</strong> 结合起来（很常见的全局和局部信息结合的思想），与当前的新消息（用户和助手的最新一轮对话）一起，生成一个 <strong>综合提示（P）</strong>。这个提示会被送入一个<strong>提取函数</strong>，通过大语言模型（LLM）来处理和提取出一组 <strong>候选记忆（Ω）</strong>。这些候选记忆是与当前对话相关的关键信息，用于后续更新知识库中的记忆。</p><pre class=" language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">_add_to_vector_store</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> messages<span class="token punctuation">,</span> metadata<span class="token punctuation">,</span> filters<span class="token punctuation">,</span> infer<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">"""    提取记忆功能：处理消息并提取记忆事实    该函数实现了记忆的提取和存储过程    """</span>    <span class="token comment" spellcheck="true"># 如果不需要生成记忆片段，则直接存储原始消息(按原样存储)</span>    <span class="token keyword">if</span> <span class="token operator">not</span> infer<span class="token punctuation">:</span>        returned_memories <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>        <span class="token keyword">for</span> message <span class="token keyword">in</span> messages<span class="token punctuation">:</span>            <span class="token keyword">if</span> message<span class="token punctuation">[</span><span class="token string">"role"</span><span class="token punctuation">]</span> <span class="token operator">!=</span> <span class="token string">"system"</span><span class="token punctuation">:</span>                message_embeddings <span class="token operator">=</span> self<span class="token punctuation">.</span>embedding_model<span class="token punctuation">.</span>embed<span class="token punctuation">(</span>message<span class="token punctuation">[</span><span class="token string">"content"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">"add"</span><span class="token punctuation">)</span>                memory_id <span class="token operator">=</span> self<span class="token punctuation">.</span>_create_memory<span class="token punctuation">(</span>message<span class="token punctuation">[</span><span class="token string">"content"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> message_embeddings<span class="token punctuation">,</span> metadata<span class="token punctuation">)</span>                returned_memories<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;"id": memory_id, "memory": message["content"], "event": "ADD"&amp;#125;)</span>        <span class="token keyword">return</span> returned_memories    <span class="token comment" spellcheck="true"># 1. 解析对话消息，形成上下文</span>    parsed_messages <span class="token operator">=</span> parse_messages<span class="token punctuation">(</span>messages<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># 2. 构建提示，使用最近消息窗口作为上下文</span>    <span class="token keyword">if</span> self<span class="token punctuation">.</span>config<span class="token punctuation">.</span>custom_fact_extraction_prompt<span class="token punctuation">:</span>        system_prompt <span class="token operator">=</span> self<span class="token punctuation">.</span>config<span class="token punctuation">.</span>custom_fact_extraction_prompt        user_prompt <span class="token operator">=</span> f<span class="token string">"Input:\n&amp;#123;parsed_messages&amp;#125;"</span>    <span class="token keyword">else</span><span class="token punctuation">:</span>        system_prompt<span class="token punctuation">,</span> user_prompt <span class="token operator">=</span> get_fact_retrieval_messages<span class="token punctuation">(</span>parsed_messages<span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 提取记忆的system prompt自己看源码吧，比较长这里就不贴了</span>    <span class="token comment" spellcheck="true"># 3. 使用LLM提取事实（候选记忆）</span>    response <span class="token operator">=</span> self<span class="token punctuation">.</span>llm<span class="token punctuation">.</span>generate_response<span class="token punctuation">(</span>        messages<span class="token operator">=</span><span class="token punctuation">[</span>            <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;"role": "system", "content": system_prompt&amp;#125;,</span>            <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;"role": "user", "content": user_prompt&amp;#125;,</span>        <span class="token punctuation">]</span><span class="token punctuation">,</span>        response_format<span class="token operator">=</span><span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;"type": "json_object"&amp;#125;,</span>    <span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># 4. 解析LLM输出，获取候选记忆</span>    <span class="token keyword">try</span><span class="token punctuation">:</span>        response <span class="token operator">=</span> remove_code_blocks<span class="token punctuation">(</span>response<span class="token punctuation">)</span>        new_retrieved_facts <span class="token operator">=</span> json<span class="token punctuation">.</span>loads<span class="token punctuation">(</span>response<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token string">"facts"</span><span class="token punctuation">]</span>  <span class="token comment" spellcheck="true"># 候选记忆列表</span>    <span class="token keyword">except</span> Exception <span class="token keyword">as</span> e<span class="token punctuation">:</span>        logging<span class="token punctuation">.</span>error<span class="token punctuation">(</span>f<span class="token string">"Error in new_retrieved_facts: &amp;#123;e&amp;#125;"</span><span class="token punctuation">)</span>        new_retrieved_facts <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>            <span class="token comment" spellcheck="true"># 5. 准备从向量数据库检索相似记忆，以便后续进行更新决策</span>    retrieved_old_memory <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>    new_message_embeddings <span class="token operator">=</span> <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;&amp;#125;</span>    <span class="token keyword">for</span> new_mem <span class="token keyword">in</span> new_retrieved_facts<span class="token punctuation">:</span>        <span class="token comment" spellcheck="true"># 为每个候选记忆生成向量嵌入</span>        messages_embeddings <span class="token operator">=</span> self<span class="token punctuation">.</span>embedding_model<span class="token punctuation">.</span>embed<span class="token punctuation">(</span>new_mem<span class="token punctuation">,</span> <span class="token string">"add"</span><span class="token punctuation">)</span>        new_message_embeddings<span class="token punctuation">[</span>new_mem<span class="token punctuation">]</span> <span class="token operator">=</span> messages_embeddings        <span class="token comment" spellcheck="true"># 检索向量数据库中与候选记忆语义相似的现有记忆</span>        existing_memories <span class="token operator">=</span> self<span class="token punctuation">.</span>vector_store<span class="token punctuation">.</span>search<span class="token punctuation">(</span>            query<span class="token operator">=</span>new_mem<span class="token punctuation">,</span>            vectors<span class="token operator">=</span>messages_embeddings<span class="token punctuation">,</span>            limit<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span>            filters<span class="token operator">=</span>filters<span class="token punctuation">,</span>        <span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># 收集相似的现有记忆</span>        <span class="token keyword">for</span> mem <span class="token keyword">in</span> existing_memories<span class="token punctuation">:</span>            retrieved_old_memory<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;"id": mem.id, "text": mem.payload["data"]&amp;#125;)</span></code></pre><p>提取出的候选记忆并不会被直接存入数据库，而是会进入更新阶段，以确保记忆库的一致性和无冗余。该过程通过一个智能的“工具调用（Tool Call）”机制实现，具体流程如下：</p><p><img src="https://cyan-1314223569.cos.ap-beijing.myqcloud.com/test/Pasted%20image%2020251019221554.png"></p><p>Mem0 首先会检索出与候选记忆语义最相似的若干个现有记忆(向量数据库向量检索)。然后通过function call的形式调用记忆更新工具来更新记忆。工具有4个：</p><ul><li><strong>ADD</strong>：如果候选记忆是全新的信息，则添加。</li><li><strong>UPDATE</strong>：如果候选记忆是对现有信息的补充或更新，则进行修改。</li><li><strong>DELETE</strong>：如果候选记忆与现有信息相矛盾，则删除旧信息。</li><li><strong>NOOP</strong>：如果候选记忆是重复或无关的，则不执行任何操作。</li></ul><p>当现有记忆与新提取的候选记忆存在冲突时，Mem0 会决定是否删除、更新或添加新记忆。</p><h4 id="Mem0g"><a href="#Mem0g" class="headerlink" title="Mem0g"></a>Mem0g</h4><p><img src="https://cyan-1314223569.cos.ap-beijing.myqcloud.com/test/Pasted%20image%2020251019221749.png" alt="Mem0g 基本架构图"></p><p><strong>Mem0g</strong> 引入了传统知识图谱的思想来增强其对复杂关系的处理能力。与 Mem0 主要通过文本和摘要来管理记忆不同，Mem0g 通过三元组方式将记忆存储为头节点、尾节点和关系边的图，这种结构能更好地捕捉了不同实体之间的关系。同样是两个阶段（提取和更新）。</p><p>以图 $G&#x3D;(V,E,L)$ 建模记忆（实体、关系、Label）</p><p>首先通过一个<strong>实体提取模块</strong>从对话中识别出所有相关的实体（例如人物、地点、事件等）及实体类别。随后，系统会通过<strong>关系生成模块</strong>根据对话上下文建立实体之间的关系，形成一组三元组（如实体 A 、实体 B及关系 R）。这些三元组也就组成了一个记忆知识图谱。</p><p>Mem0g在抽取实体和关系的时候就是用<strong>大模型+prompt</strong>完成，没有用传统nlp中实体识别或者关系抽取的方法。并且，它是采用<strong>两阶段</strong>完成，即先实体抽取，再关系生成。</p><p>每个entity（node）包含三部分信息：</p><ul><li>entity type classification：用于标记这个实体属于哪一类  </li><li>embedding vector：实体语义含义的向量表示，便于后续做语义相似度检索和推理  </li><li>metadata： 主要包括创建时间戳（creation timestamp），用于记录这个实体被加入知识图谱的时间，有助于时序推理</li></ul><pre class=" language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">MemoryGraph</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> config<span class="token punctuation">:</span> MemoryConfig <span class="token operator">=</span> MemoryConfig<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token triple-quoted-string string">"""        知识图谱记忆模块初始化        负责实体提取、关系生成和图谱维护        """</span>        self<span class="token punctuation">.</span>config <span class="token operator">=</span> config        <span class="token comment" spellcheck="true"># 初始化图数据库存储</span>        self<span class="token punctuation">.</span>graph_store <span class="token operator">=</span> GraphStoreFactory<span class="token punctuation">.</span>create<span class="token punctuation">(</span>            self<span class="token punctuation">.</span>config<span class="token punctuation">.</span>graph_store<span class="token punctuation">.</span>provider<span class="token punctuation">,</span> self<span class="token punctuation">.</span>config<span class="token punctuation">.</span>graph_store<span class="token punctuation">.</span>config        <span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># 初始化LLM用于实体和关系提取</span>        self<span class="token punctuation">.</span>llm <span class="token operator">=</span> LlmFactory<span class="token punctuation">.</span>create<span class="token punctuation">(</span>self<span class="token punctuation">.</span>config<span class="token punctuation">.</span>llm<span class="token punctuation">.</span>provider<span class="token punctuation">,</span> self<span class="token punctuation">.</span>config<span class="token punctuation">.</span>llm<span class="token punctuation">.</span>config<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># 初始化嵌入模型用于语义相似度计算</span>        self<span class="token punctuation">.</span>embedding_model <span class="token operator">=</span> EmbedderFactory<span class="token punctuation">.</span>create<span class="token punctuation">(</span>            self<span class="token punctuation">.</span>config<span class="token punctuation">.</span>embedder<span class="token punctuation">.</span>provider<span class="token punctuation">,</span>            self<span class="token punctuation">.</span>config<span class="token punctuation">.</span>embedder<span class="token punctuation">.</span>config<span class="token punctuation">,</span>            self<span class="token punctuation">.</span>config<span class="token punctuation">.</span>vector_store<span class="token punctuation">.</span>config<span class="token punctuation">,</span>        <span class="token punctuation">)</span>            <span class="token keyword">def</span> <span class="token function">add</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> message<span class="token punctuation">,</span> filters<span class="token operator">=</span>None<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token triple-quoted-string string">"""        向知识图谱添加新信息        实现从文本中提取实体和关系并构建知识图谱        """</span>        filters <span class="token operator">=</span> filters <span class="token operator">or</span> <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;&amp;#125;</span>                <span class="token comment" spellcheck="true"># 1. 使用LLM提取实体</span>        <span class="token comment" spellcheck="true"># 实体提取模块：从文本中识别相关实体及其类别</span>        entity_prompt <span class="token operator">=</span> self<span class="token punctuation">.</span>_get_entity_extraction_prompt<span class="token punctuation">(</span>message<span class="token punctuation">)</span>        entity_response <span class="token operator">=</span> self<span class="token punctuation">.</span>llm<span class="token punctuation">.</span>generate_response<span class="token punctuation">(</span>            messages<span class="token operator">=</span><span class="token punctuation">[</span><span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;"role": "user", "content": entity_prompt&amp;#125;],</span>            response_format<span class="token operator">=</span><span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;"type": "json_object"&amp;#125;,</span>        <span class="token punctuation">)</span>                <span class="token keyword">try</span><span class="token punctuation">:</span>            <span class="token comment" spellcheck="true"># 解析LLM返回的实体列表</span>            entity_response <span class="token operator">=</span> remove_code_blocks<span class="token punctuation">(</span>entity_response<span class="token punctuation">)</span>            entity_data <span class="token operator">=</span> json<span class="token punctuation">.</span>loads<span class="token punctuation">(</span>entity_response<span class="token punctuation">)</span>            entities <span class="token operator">=</span> entity_data<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">"entities"</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">)</span>                        <span class="token comment" spellcheck="true"># 如果没有提取到实体，直接返回</span>            <span class="token keyword">if</span> <span class="token operator">not</span> entities<span class="token punctuation">:</span>                <span class="token keyword">return</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>                            <span class="token comment" spellcheck="true"># 2. 使用LLM生成实体间关系</span>            <span class="token comment" spellcheck="true"># 关系生成模块：根据上下文建立实体之间的语义关系</span>            relation_prompt <span class="token operator">=</span> self<span class="token punctuation">.</span>_get_relation_extraction_prompt<span class="token punctuation">(</span>message<span class="token punctuation">,</span> entities<span class="token punctuation">)</span>            relation_response <span class="token operator">=</span> self<span class="token punctuation">.</span>llm<span class="token punctuation">.</span>generate_response<span class="token punctuation">(</span>  <span class="token comment" spellcheck="true"># 核心还是构建prompt+调用大模型的方式</span>                messages<span class="token operator">=</span><span class="token punctuation">[</span><span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;"role": "user", "content": relation_prompt&amp;#125;],</span>                response_format<span class="token operator">=</span><span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;"type": "json_object"&amp;#125;,</span>            <span class="token punctuation">)</span>                        <span class="token comment" spellcheck="true"># 解析LLM返回的关系列表</span>            relation_response <span class="token operator">=</span> remove_code_blocks<span class="token punctuation">(</span>relation_response<span class="token punctuation">)</span>            relation_data <span class="token operator">=</span> json<span class="token punctuation">.</span>loads<span class="token punctuation">(</span>relation_response<span class="token punctuation">)</span>            relations <span class="token operator">=</span> relation_data<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">"relations"</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">)</span>                        <span class="token comment" spellcheck="true"># 3. 将实体和关系添加到图数据库中</span>            added_entities <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>            <span class="token keyword">for</span> relation <span class="token keyword">in</span> relations<span class="token punctuation">:</span>                <span class="token comment" spellcheck="true"># 处理头实体</span>                source_entity <span class="token operator">=</span> relation<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">"source"</span><span class="token punctuation">)</span>                source_entity_type <span class="token operator">=</span> relation<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">"source_type"</span><span class="token punctuation">)</span>                                <span class="token comment" spellcheck="true"># 处理尾实体</span>                target_entity <span class="token operator">=</span> relation<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">"target"</span><span class="token punctuation">)</span>                 target_entity_type <span class="token operator">=</span> relation<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">"target_type"</span><span class="token punctuation">)</span>                                <span class="token comment" spellcheck="true"># 处理关系</span>                relationship <span class="token operator">=</span> relation<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">"relationship"</span><span class="token punctuation">)</span>                                <span class="token comment" spellcheck="true"># 将实体和关系信息添加到图数据库</span>                <span class="token keyword">if</span> source_entity <span class="token operator">and</span> target_entity <span class="token operator">and</span> relationship<span class="token punctuation">:</span>                    <span class="token comment" spellcheck="true"># 为实体和关系生成向量嵌入，用于后续相似性检索</span>                    source_entity_embeddings <span class="token operator">=</span> self<span class="token punctuation">.</span>embedding_model<span class="token punctuation">.</span>embed<span class="token punctuation">(</span>source_entity<span class="token punctuation">,</span> <span class="token string">"add"</span><span class="token punctuation">)</span>                    target_entity_embeddings <span class="token operator">=</span> self<span class="token punctuation">.</span>embedding_model<span class="token punctuation">.</span>embed<span class="token punctuation">(</span>target_entity<span class="token punctuation">,</span> <span class="token string">"add"</span><span class="token punctuation">)</span>                                        <span class="token comment" spellcheck="true"># 添加到图数据库并记录结果</span>                    result <span class="token operator">=</span> self<span class="token punctuation">.</span>graph_store<span class="token punctuation">.</span>add_triple<span class="token punctuation">(</span>                        source<span class="token operator">=</span>source_entity<span class="token punctuation">,</span>                        source_type<span class="token operator">=</span>source_entity_type<span class="token punctuation">,</span>                        relationship<span class="token operator">=</span>relationship<span class="token punctuation">,</span>                        target<span class="token operator">=</span>target_entity<span class="token punctuation">,</span>                        target_type<span class="token operator">=</span>target_entity_type<span class="token punctuation">,</span>                        source_embedding<span class="token operator">=</span>source_entity_embeddings<span class="token punctuation">,</span>                        target_embedding<span class="token operator">=</span>target_entity_embeddings<span class="token punctuation">,</span>                        metadata<span class="token operator">=</span>filters                    <span class="token punctuation">)</span>                                        added_entities<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;</span>                        <span class="token string">"source"</span><span class="token punctuation">:</span> source_entity<span class="token punctuation">,</span>                        <span class="token string">"source_type"</span><span class="token punctuation">:</span> source_entity_type<span class="token punctuation">,</span>                        <span class="token string">"relationship"</span><span class="token punctuation">:</span> relationship<span class="token punctuation">,</span>                        <span class="token string">"destination"</span><span class="token punctuation">:</span> target_entity<span class="token punctuation">,</span>                        <span class="token string">"destination_type"</span><span class="token punctuation">:</span> target_entity_type                    <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#125;)</span>                        <span class="token keyword">return</span> added_entities                    <span class="token keyword">except</span> Exception <span class="token keyword">as</span> e<span class="token punctuation">:</span>            logger<span class="token punctuation">.</span>error<span class="token punctuation">(</span>f<span class="token string">"Error in entity/relation extraction: &amp;#123;e&amp;#125;"</span><span class="token punctuation">)</span>            <span class="token keyword">return</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>                <span class="token keyword">def</span> <span class="token function">_get_entity_extraction_prompt</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> message<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token triple-quoted-string string">"""        生成实体提取的提示词        指导LLM识别文本中的各类实体        """</span>        <span class="token keyword">return</span> <span class="token triple-quoted-string string">"""You are an entity extraction system. Your task is to identify the most important entities in the given text.                An entity can be a person, place, organization, product, or concept. For each entity, provide its type.                Format your response as a JSON object with a single key "entities", containing a list of entity objects.        Each entity object should have "name" (the entity) and "type" fields.                Here is the text to analyze:                /```        &amp;#123;message&amp;#125;        /```                JSON Response:        """</span><span class="token punctuation">.</span>format<span class="token punctuation">(</span>message<span class="token operator">=</span>message<span class="token punctuation">)</span>        <span class="token keyword">def</span> <span class="token function">_get_relation_extraction_prompt</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> message<span class="token punctuation">,</span> entities<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token triple-quoted-string string">"""        生成关系提取的提示词        指导LLM识别已提取实体之间的关系        """</span>        entity_names <span class="token operator">=</span> <span class="token punctuation">[</span>e<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">"name"</span><span class="token punctuation">)</span> <span class="token keyword">for</span> e <span class="token keyword">in</span> entities<span class="token punctuation">]</span>        entity_str <span class="token operator">=</span> <span class="token string">", "</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>entity_names<span class="token punctuation">)</span>                <span class="token keyword">return</span> <span class="token triple-quoted-string string">"""You are a relationship extraction system. Your task is to identify meaningful relationships between the entities in the given text.                Text:        /```        &amp;#123;message&amp;#125;        /```                Entities: &amp;#123;entities&amp;#125;                For each relationship you identify, specify:        1. The source entity        2. The type of the source entity        3. The relationship (a verb or phrase describing how entities are connected)        4. The target entity        5. The type of the target entity                Only create relationships that are explicitly or strongly implied in the text.        Format your response as a JSON object with a single key "relations", containing a list of relationship objects.                JSON Response:        """</span><span class="token punctuation">.</span>format<span class="token punctuation">(</span>message<span class="token operator">=</span>message<span class="token punctuation">,</span> entities<span class="token operator">=</span>entity_str<span class="token punctuation">)</span></code></pre><p>Mem0g 通过 <strong>图数据库</strong> Neo4j进行节点和边的检索。具体来说，Mem0g 会计算新提取的实体与现有节点之间的语义相似度，并根据阈值决定是否更新或添加新的节点和关系。这种操作也是通过 FC 来完成的。</p><p><strong>记忆检索功能</strong> 则是其与 Mem0 另一个显著的区别点。Mem0g 在处理查询时，采用了 <strong>双重检索策略</strong>，一方面是基于 <strong>实体</strong> 的检索，首先通过识别查询中的关键实体并在图中找到相应节点，之后探索这些节点的关联关系及对应的尾实体。另一方面，Mem0g 采用 <strong>语义三元组检索</strong>，即通过将整个查询转换为一个 <strong>向量表示</strong>，与图中的三元组进行匹配。（就是两种检索策略叠加使用，以期获得更全面的信息）</p><h3 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h3><p>在长对话记忆评测基准 <a href="https://zhida.zhihu.com/search?content_id=258720927&content_type=Article&match_order=1&q=LOCOMO&zhida_source=entity">LOCOMO</a> 上，将 Mem0 和 Mem0-g 与六大类基线方法进行了全面对比，包括已有的记忆增强系统、多种配置的RAG、全上下文方法、开源记忆方案以及商业平台。</p><blockquote><p>LOCOMO 包含 10 个长对话，每个对话约 600 轮、26000 tokens，跨多次会话。每个对话后有约 200 个问题及标准答案，问题类型包括 single-hop、multi-hop、temporal、open-domain</p></blockquote><p><strong>Evaluation Metrics</strong>：    </p><ul><li><p>Performance Metrics：</p><ul><li>**F1 Score (F1)**，传统的词级重叠指标；</li><li>**BLEU-1 (B1)**，单词级 BLEU 分数； </li><li>**LLM-as-a-Judge (J)**，综合评估回答的事实准确性、相关性、完整性和上下文适应性；</li></ul></li><li><p>Deployment Metrics：</p><ul><li><strong>Token Consumption</strong>（检索到的 context token 数量，反映系统的计算和成本效率）；Latency，测量Search Latency和Total Latency。</li></ul></li></ul><p><img src="https://cyan-1314223569.cos.ap-beijing.myqcloud.com/test/Pasted%20image%2020251019222809.png" alt="主实验结果"></p><p><img src="https://cyan-1314223569.cos.ap-beijing.myqcloud.com/test/Pasted%20image%2020251019223115.png" alt="效率实验结果"></p><p>在计算效率方面，Mem0 和 Mem0g 都显著优于<strong>全上下文处理</strong>方法，尤其是在响应时间和 p95 上，二者分别减少了 91% 和 85% 的延迟。此外，<strong>Mem0g 在存储效率上略有增加，因为其图结构需要更多的内存空间</strong>。</p><h3 id="My-Thoughts"><a href="#My-Thoughts" class="headerlink" title="My Thoughts"></a>My Thoughts</h3><p>Mem0 是 Agent Memory 领域的经典作，理解起来并不困难。</p><p>和 A-Mem 相比较，其实主要也就是两点不同，仍然是 Agent Memory 里最关键的两点：</p><ol><li><strong>记忆存储</strong>：Mem0 是摘要+最近消息引导大模型生成记忆，Mem0g 是图节点实体关系三元组形式，A-Mem 是笔记与链接形式；</li><li><strong>记忆更新</strong>：A-Mem 和 Mem0 基本都是通过 Agent 自主决策判断，通过与以往记忆比对，判定当前记忆如何操作。</li></ol>]]></content>
      
      
      
        <tags>
            
            <tag> 论文笔记 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Build an Agentic RAG System</title>
      <link href="/2025/10/18/xue-xi-build-an-agentic-rag-system/"/>
      <url>/2025/10/18/xue-xi-build-an-agentic-rag-system/</url>
      
        <content type="html"><![CDATA[<h2 id="Native-RAG"><a href="#Native-RAG" class="headerlink" title="Native RAG"></a>Native RAG</h2><p>传统 RAG 以填充 prompt 的形式进行，从数据库中检索相关知识来填充。原始文档的内容通过切片，经过 Embedding Model 向量化，并存储到数据库中以备检索使用。</p><p>整个过程较为线性，检索方式也比较简单，不能保证最终的检索精度，<strong>其效果有一定局限性</strong>。</p><p><img src="https://cyan-1314223569.cos.ap-beijing.myqcloud.com/test/Pasted%20image%2020251019140128.png"></p><p>简单的 Native RAG 构建需要两个部分：offline（离线存储）和 online（在线检索）。这里使用 <code>langchain</code> 构建：</p><h4 id="离线部分"><a href="#离线部分" class="headerlink" title="离线部分"></a>离线部分</h4><p>首先准备好文档文本，导入相关库并加载文档内容到内存中：</p><pre class=" language-python"><code class="language-python"><span class="token keyword">from</span> langchain_community<span class="token punctuation">.</span>document_loaders <span class="token keyword">import</span> TextLoader<span class="token keyword">from</span> langchain<span class="token punctuation">.</span>text_splitter <span class="token keyword">import</span> RecursiveCharacterTextSplitter<span class="token keyword">from</span> langchain_openai <span class="token keyword">import</span> OpenAIEmbeddings<span class="token keyword">from</span> langchain_chroma <span class="token keyword">import</span> Chroma  <span class="token comment" spellcheck="true"># load document</span>loader <span class="token operator">=</span> TextLoader<span class="token punctuation">(</span><span class="token string">"./knowledge.txt"</span><span class="token punctuation">)</span>documents <span class="token operator">=</span> loader<span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre><p>接下来将文档拆分成段，进行 embedding 并将其持久化存储：</p><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># split documents into chunks</span>text_splitter <span class="token operator">=</span> RecursiveCharacterTextSplitter<span class="token punctuation">(</span>    chunk_size <span class="token operator">=</span> <span class="token number">500</span><span class="token punctuation">,</span>    chunk_overlap <span class="token operator">=</span> <span class="token number">20</span><span class="token punctuation">,</span><span class="token punctuation">)</span>splits <span class="token operator">=</span> text_splitter<span class="token punctuation">.</span>split_documents<span class="token punctuation">(</span>documents<span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># embed chunks</span>embeddings <span class="token operator">=</span> OpenAIEmbeddings<span class="token punctuation">(</span>    base_url<span class="token operator">=</span><span class="token string">"https://api.siliconflow.cn/v1"</span><span class="token punctuation">,</span>    model<span class="token operator">=</span><span class="token string">"Qwen/Qwen3-Embedding-0.6B"</span><span class="token punctuation">,</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># store chunks</span>vector_store <span class="token operator">=</span> Chroma<span class="token punctuation">.</span>from_documents<span class="token punctuation">(</span>    documents<span class="token operator">=</span>splits<span class="token punctuation">,</span>    embedding<span class="token operator">=</span>embeddings<span class="token punctuation">,</span>    persist_directory<span class="token operator">=</span><span class="token string">"./vector_store"</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"successfully stored chunks"</span><span class="token punctuation">)</span></code></pre><h4 id="在线部分"><a href="#在线部分" class="headerlink" title="在线部分"></a>在线部分</h4><p>online 环节更加简单，仅需将 query embed，然后进行向量检索，从离线环节构建得到的数据库中检索到相关文档内容，最后将文档内容作为上下文信息，填入到已有的 prompt template 中，调用模型进行内容生成。</p><pre class=" language-python"><code class="language-python"><span class="token keyword">from</span> langchain<span class="token punctuation">.</span>embeddings <span class="token keyword">import</span> OpenAIEmbeddings<span class="token keyword">from</span> langchain<span class="token punctuation">.</span>vectorstores <span class="token keyword">import</span> Chroma<span class="token keyword">from</span> langchain_openai <span class="token keyword">import</span> ChatOpenAI<span class="token keyword">from</span> langchain<span class="token punctuation">.</span>prompts <span class="token keyword">import</span> PromptTemplate<span class="token keyword">from</span> langchain<span class="token punctuation">.</span>schema <span class="token keyword">import</span> HumanMessage  embeddings <span class="token operator">=</span> OpenAIEmbeddings<span class="token punctuation">(</span>    base_url<span class="token operator">=</span><span class="token string">"https://api.siliconflow.cn/v1"</span><span class="token punctuation">,</span>    model<span class="token operator">=</span><span class="token string">"Qwen/Qwen3-Embedding-0.6B"</span><span class="token punctuation">,</span><span class="token punctuation">)</span>vectorstore <span class="token operator">=</span> Chroma<span class="token punctuation">(</span>persist_directory<span class="token operator">=</span><span class="token string">"./vector_store"</span><span class="token punctuation">,</span> embedding_function<span class="token operator">=</span>embeddings<span class="token punctuation">)</span>  query <span class="token operator">=</span> <span class="token string">"什么是RAG？"</span>  documents <span class="token operator">=</span> vectorstore<span class="token punctuation">.</span>similarity_search<span class="token punctuation">(</span>query<span class="token punctuation">,</span> k<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">)</span>  context <span class="token operator">=</span> <span class="token string">"\n"</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span><span class="token punctuation">[</span>doc<span class="token punctuation">.</span>page_content <span class="token keyword">for</span> doc <span class="token keyword">in</span> documents<span class="token punctuation">]</span><span class="token punctuation">)</span>  prompt <span class="token operator">=</span> PromptTemplate<span class="token punctuation">(</span>    template<span class="token operator">=</span><span class="token triple-quoted-string string">"""    你是一个专业的问答助手。请根据以下参考文档回答用户的问题。    如果参考文档中没有相关信息，请诚实地说不知道，不要编造答案。      参考文档：&amp;#123;context&amp;#125;      用户问题：&amp;#123;query&amp;#125;      回答：    """</span><span class="token punctuation">,</span>    input_variables<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">"context"</span><span class="token punctuation">,</span> <span class="token string">"query"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>chain <span class="token operator">=</span> prompt <span class="token operator">|</span> ChatOpenAI<span class="token punctuation">(</span>    model<span class="token operator">=</span><span class="token string">"THUDM/glm-4-9b-chat"</span><span class="token punctuation">,</span>    temperature<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span>    max_retries<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span>    base_url<span class="token operator">=</span><span class="token string">"https://api.siliconflow.cn/v1"</span><span class="token punctuation">,</span>    api_key<span class="token operator">=</span>API_KEY<span class="token punctuation">,</span><span class="token punctuation">)</span>  result <span class="token operator">=</span> chain<span class="token punctuation">.</span>invoke<span class="token punctuation">(</span><span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;"context": context, "query": query&amp;#125;)</span><span class="token keyword">print</span><span class="token punctuation">(</span>result<span class="token punctuation">.</span>content<span class="token punctuation">)</span></code></pre><h2 id="Agentic-RAG"><a href="#Agentic-RAG" class="headerlink" title="Agentic RAG"></a>Agentic RAG</h2><p>Native RAG 的不足之处：</p><ul><li><strong>一次性检索</strong>：一般一下子检索 <code>Top-K</code> 文档 chunks，无法按需求递进检索；</li><li><strong>查询力度差</strong>：只会根据相似度检索，不会进一步查看文件元数据；</li><li><strong>缺乏任务拆解</strong>：问题可能需要先定位文件、再选片段、再比对与总结，Native RAG 往往缺少这样的多步拆解能力，也不会回溯重试，按语义改写原始查询等。</li></ul><p>Agentic RAG 的思路是<strong>将 RAG 的过程“工具化”</strong>：提供 search tools，模型的检索利用这些 tools 进行，LLM 使用一个 tool use 的循环，获取到足够合适的信息后再生成。</p><p>Agentic 需要的能力：</p><ol><li>Planning &#x2F; Reflection（一般可以体现在 Long COT thinking 过程中）</li><li>tool use &#x2F; Multi-Agent Collaboration（一般体现在 tools 的调用中）</li><li>Multi-Step inference</li></ol><p><img src="https://cyan-1314223569.cos.ap-beijing.myqcloud.com/test/kappframework-Zbogca(1)(1).png"></p><ul><li>让 LLM 作为“智能体（Agent）”充当控制器，结合一组工具（检索、查看元数据、读取片段等）执行“思考→行动→观察”的循环（Reason–Act–Observe）。</li><li>在回答之前，按需多轮调用工具，逐步从“找到相关文件”走到“读取关键片段”，最后基于被读取的证据组织答案，并给出引用。</li></ul><p>主要有两种实现方式，一种是基于 <code>tools &amp; prompts</code> 的 RAG，另一种是基于 <code>RL</code> 的 RAG。</p><h4 id="基于-tools-prompts-的-RAG"><a href="#基于-tools-prompts-的-RAG" class="headerlink" title="基于 tools &amp; prompts 的 RAG"></a>基于 tools &amp; prompts 的 RAG</h4><p>ReAct 是一个常见的 Agent 实现方式，因此只要给 LLM 配备合适的 <code>Tool</code>以及适当的引导 <code>Prompt</code>，就可以将一个 <code>Native RAG</code> 转换成 <code>Agentic RAG</code>。</p><p>在 Agentic RAG 经典项目 <a href="%22https://github.com/chatboxai/chatbox/blob/9e33c9f998ebf240f31bbb439a430b4d5e5bd3e0/src/renderer/packages/knowledge-base/tools.ts#L78%22">chatbox</a> 里，主要定义了四种关键的 tools：</p><ul><li><code>query_knowledge_base</code><br>  在知识库中进行语义检索，快速找到候选文件或 <code>chunks</code>。通常作为最基础的检索工具</li><li><code>get_files_meta</code><br>  查看候选文件的元信息（如文件名、大小、chunk 数量），帮助模型决定“读哪几个文件的哪部分”。</li><li><code>read_file_chunks</code><br>  按文件 <code>ID + chunkIndex</code> 精读具体片段，用于“取证”。建议一次只读少量最相关的 <code>chunk</code>，以降低噪声。</li><li><code>list_files</code><br>  列出知识库中的文件清单，作为兜底浏览或当搜索线索不充分时的探索手段。</li></ul><p>这些 <code>tools</code> 具体在 Agentic RAG 里是怎么应用的呢？举个例子来说，<code>query_knowledge_base</code> 就是根据 <code>query</code> 最基础的查找，根据语义检索定位 <code>chunks</code>；紧接着，如果模型决策当前获取的信息不充足，需要补充上下 <code>chunks</code> 里的信息，那么可以通过调用 <code>read_file_chunks</code> 函数来补充。</p><p>同时，由于整个过程被拆解为多个 LLM 的调用决策，模型还可以根据当前判断，主动修改要检索的原始 <code>query</code> 信息，从而实现更好的检索。</p><p>Agentic RAG 的简单实现如下，大致分为三个环节：</p><ul><li>offline：构建文档数据库，定义文件数据类、文件元数据、文件 <code>chunks</code> 分块方式、检索方法；</li><li>offline：定义知识库管理的调用函数，也就是几种模型要用到的工具 <code>tools</code>；</li><li>online：初始化模型，传入定义好的 <code>tools</code>，定义提示词模版，引导模型多步决策进行检索；</li></ul><p>源代码如下：</p><pre class=" language-python"><code class="language-python"><span class="token keyword">from</span> typing <span class="token keyword">import</span> List<span class="token punctuation">,</span> Dict<span class="token keyword">import</span> json<span class="token keyword">from</span> dataclasses <span class="token keyword">import</span> dataclass<span class="token keyword">from</span> langchain_core<span class="token punctuation">.</span>tools <span class="token keyword">import</span> tool<span class="token keyword">from</span> langchain_openai <span class="token keyword">import</span> ChatOpenAI<span class="token keyword">from</span> langgraph<span class="token punctuation">.</span>prebuilt <span class="token keyword">import</span> create_react_agent    @dataclass<span class="token keyword">class</span> <span class="token class-name">FileChunk</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">"""文件片段"""</span>      file_id<span class="token punctuation">:</span> int    chunk_index<span class="token punctuation">:</span> int    content<span class="token punctuation">:</span> str    @dataclass<span class="token keyword">class</span> <span class="token class-name">FileInfo</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">"""文件信息"""</span>      id<span class="token punctuation">:</span> int    filename<span class="token punctuation">:</span> str    chunk_count<span class="token punctuation">:</span> int    status<span class="token punctuation">:</span> str <span class="token operator">=</span> <span class="token string">"done"</span>    <span class="token keyword">class</span> <span class="token class-name">MockKnowledgeBaseController</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">"""模拟知识库控制器 - 内存版本，用于演示"""</span>      <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment" spellcheck="true"># 模拟一些文档数据</span>        self<span class="token punctuation">.</span>files <span class="token operator">=</span> <span class="token punctuation">[</span>            FileInfo<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token string">"rag_introduction.md"</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            FileInfo<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token string">"llm_fundamentals.md"</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            FileInfo<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token string">"vector_search.md"</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            FileInfo<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token string">"prompt_engineering.md"</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">,</span>        <span class="token punctuation">]</span>          <span class="token comment" spellcheck="true"># 模拟文档内容片段</span>        self<span class="token punctuation">.</span>chunks <span class="token operator">=</span> <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;</span>            <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">:</span> FileChunk<span class="token punctuation">(</span>                <span class="token number">1</span><span class="token punctuation">,</span>                <span class="token number">0</span><span class="token punctuation">,</span>                <span class="token string">"RAG (Retrieval-Augmented Generation) 是一种结合检索和生成的技术，通过从外部知识源检索相关信息来增强大语言模型的生成能力。"</span><span class="token punctuation">,</span>            <span class="token punctuation">)</span><span class="token punctuation">,</span>            <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span> FileChunk<span class="token punctuation">(</span>                <span class="token number">1</span><span class="token punctuation">,</span>                <span class="token number">1</span><span class="token punctuation">,</span>                <span class="token string">"RAG 的优点包括：1) 能够访问最新信息，2) 减少模型幻觉，3) 提供可追溯的信息来源，4) 无需重新训练模型即可更新知识。"</span><span class="token punctuation">,</span>            <span class="token punctuation">)</span><span class="token punctuation">,</span>            <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">:</span> FileChunk<span class="token punctuation">(</span>                <span class="token number">1</span><span class="token punctuation">,</span>                <span class="token number">2</span><span class="token punctuation">,</span>                <span class="token string">"RAG 的缺点包括：1) 检索质量直接影响生成效果，2) 增加了系统复杂度，3) 对向量数据库的依赖，4) 可能存在检索延迟。"</span><span class="token punctuation">,</span>            <span class="token punctuation">)</span><span class="token punctuation">,</span>            <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">:</span> FileChunk<span class="token punctuation">(</span>                <span class="token number">1</span><span class="token punctuation">,</span>                <span class="token number">3</span><span class="token punctuation">,</span>                <span class="token string">"传统 RAG 系统通常采用固定的检索-生成流程，无法根据问题复杂度动态调整策略。"</span><span class="token punctuation">,</span>            <span class="token punctuation">)</span><span class="token punctuation">,</span>            <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">:</span> FileChunk<span class="token punctuation">(</span>                <span class="token number">1</span><span class="token punctuation">,</span>                <span class="token number">4</span><span class="token punctuation">,</span>                <span class="token string">"Agentic RAG 通过引入智能体，使系统能够自主决策何时检索、如何检索以及检索多少内容，从而提升复杂问题的处理能力。"</span><span class="token punctuation">,</span>            <span class="token punctuation">)</span><span class="token punctuation">,</span>            <span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">:</span> FileChunk<span class="token punctuation">(</span>                <span class="token number">2</span><span class="token punctuation">,</span>                <span class="token number">0</span><span class="token punctuation">,</span>                <span class="token string">"大语言模型 (LLM) 是基于 Transformer 架构的深度学习模型，通过预训练学习语言的统计规律。"</span><span class="token punctuation">,</span>            <span class="token punctuation">)</span><span class="token punctuation">,</span>            <span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span> FileChunk<span class="token punctuation">(</span>                <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token string">"LLM 的核心能力包括自然语言理解、生成、推理和少样本学习等。"</span>            <span class="token punctuation">)</span><span class="token punctuation">,</span>            <span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">:</span> FileChunk<span class="token punctuation">(</span>                <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token string">"LLM 的局限性包括知识截止时间、可能产生幻觉、计算资源消耗大等。"</span>            <span class="token punctuation">)</span><span class="token punctuation">,</span>            <span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">:</span> FileChunk<span class="token punctuation">(</span>                <span class="token number">2</span><span class="token punctuation">,</span>                <span class="token number">3</span><span class="token punctuation">,</span>                <span class="token string">"工具调用是 LLM 的重要扩展能力，使模型能够与外部系统交互，执行复杂任务。"</span><span class="token punctuation">,</span>            <span class="token punctuation">)</span><span class="token punctuation">,</span>            <span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">:</span> FileChunk<span class="token punctuation">(</span>                <span class="token number">3</span><span class="token punctuation">,</span>                <span class="token number">0</span><span class="token punctuation">,</span>                <span class="token string">"向量搜索是 RAG 系统的核心组件，通过将文本转换为向量表示来实现语义相似度匹配。"</span><span class="token punctuation">,</span>            <span class="token punctuation">)</span><span class="token punctuation">,</span>            <span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span> FileChunk<span class="token punctuation">(</span>                <span class="token number">3</span><span class="token punctuation">,</span>                <span class="token number">1</span><span class="token punctuation">,</span>                <span class="token string">"常见的向量搜索算法包括 FAISS、Chroma、Pinecone 等，各有不同的性能特点。"</span><span class="token punctuation">,</span>            <span class="token punctuation">)</span><span class="token punctuation">,</span>            <span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">:</span> FileChunk<span class="token punctuation">(</span>                <span class="token number">3</span><span class="token punctuation">,</span>                <span class="token number">2</span><span class="token punctuation">,</span>                <span class="token string">"向量搜索的效果很大程度上依赖于embedding模型的质量和索引构建策略。"</span><span class="token punctuation">,</span>            <span class="token punctuation">)</span><span class="token punctuation">,</span>            <span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">:</span> FileChunk<span class="token punctuation">(</span>                <span class="token number">4</span><span class="token punctuation">,</span>                <span class="token number">0</span><span class="token punctuation">,</span>                <span class="token string">"提示工程是优化大模型表现的重要技术，包括设计有效的提示模板、上下文管理等。"</span><span class="token punctuation">,</span>            <span class="token punctuation">)</span><span class="token punctuation">,</span>            <span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span> FileChunk<span class="token punctuation">(</span>                <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token string">"良好的提示设计原则包括：清晰明确、提供示例、结构化输出格式等。"</span>            <span class="token punctuation">)</span><span class="token punctuation">,</span>            <span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">:</span> FileChunk<span class="token punctuation">(</span>                <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token string">"Agent 系统的提示设计需要考虑工具调用的策略指导和错误处理机制。"</span>            <span class="token punctuation">)</span><span class="token punctuation">,</span>            <span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">:</span> FileChunk<span class="token punctuation">(</span>                <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token string">"系统提示词应该明确定义 Agent 的角色、能力边界和行为规范。"</span>            <span class="token punctuation">)</span><span class="token punctuation">,</span>        <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#125;</span>      <span class="token keyword">def</span> <span class="token function">search</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> kb_id<span class="token punctuation">:</span> int<span class="token punctuation">,</span> query<span class="token punctuation">:</span> str<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> List<span class="token punctuation">[</span>Dict<span class="token punctuation">]</span><span class="token punctuation">:</span>        <span class="token triple-quoted-string string">"""模拟语义搜索 - 基于关键词匹配"""</span>        query_lower <span class="token operator">=</span> query<span class="token punctuation">.</span>lower<span class="token punctuation">(</span><span class="token punctuation">)</span>        results <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>          <span class="token keyword">for</span> <span class="token punctuation">(</span>file_id<span class="token punctuation">,</span> chunk_idx<span class="token punctuation">)</span><span class="token punctuation">,</span> chunk <span class="token keyword">in</span> self<span class="token punctuation">.</span>chunks<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            content_lower <span class="token operator">=</span> chunk<span class="token punctuation">.</span>content<span class="token punctuation">.</span>lower<span class="token punctuation">(</span><span class="token punctuation">)</span>            <span class="token comment" spellcheck="true"># 简单的关键词匹配评分</span>            score <span class="token operator">=</span> <span class="token number">0</span>            keywords <span class="token operator">=</span> <span class="token punctuation">[</span>                <span class="token string">"rag"</span><span class="token punctuation">,</span>                <span class="token string">"agentic"</span><span class="token punctuation">,</span>                <span class="token string">"优缺点"</span><span class="token punctuation">,</span>                <span class="token string">"优点"</span><span class="token punctuation">,</span>                <span class="token string">"缺点"</span><span class="token punctuation">,</span>                <span class="token string">"llm"</span><span class="token punctuation">,</span>                <span class="token string">"检索"</span><span class="token punctuation">,</span>                <span class="token string">"生成"</span><span class="token punctuation">,</span>                <span class="token string">"向量"</span><span class="token punctuation">,</span>                <span class="token string">"搜索"</span><span class="token punctuation">,</span>            <span class="token punctuation">]</span>            <span class="token keyword">for</span> keyword <span class="token keyword">in</span> keywords<span class="token punctuation">:</span>                <span class="token keyword">if</span> keyword <span class="token keyword">in</span> query_lower <span class="token operator">and</span> keyword <span class="token keyword">in</span> content_lower<span class="token punctuation">:</span>                    score <span class="token operator">+=</span> <span class="token number">1</span>              <span class="token keyword">if</span> score <span class="token operator">></span> <span class="token number">0</span> <span class="token operator">or</span> any<span class="token punctuation">(</span>word <span class="token keyword">in</span> content_lower <span class="token keyword">for</span> word <span class="token keyword">in</span> query_lower<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>                file_info <span class="token operator">=</span> next<span class="token punctuation">(</span>f <span class="token keyword">for</span> f <span class="token keyword">in</span> self<span class="token punctuation">.</span>files <span class="token keyword">if</span> f<span class="token punctuation">.</span>id <span class="token operator">==</span> file_id<span class="token punctuation">)</span>                results<span class="token punctuation">.</span>append<span class="token punctuation">(</span>                    <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;</span>                        <span class="token string">"file_id"</span><span class="token punctuation">:</span> file_id<span class="token punctuation">,</span>                        <span class="token string">"chunk_index"</span><span class="token punctuation">:</span> chunk_idx<span class="token punctuation">,</span>                        <span class="token string">"filename"</span><span class="token punctuation">:</span> file_info<span class="token punctuation">.</span>filename<span class="token punctuation">,</span>                        <span class="token string">"score"</span><span class="token punctuation">:</span> score <span class="token operator">+</span> <span class="token number">0.5</span><span class="token punctuation">,</span>  <span class="token comment" spellcheck="true"># 基础分</span>                        <span class="token string">"preview"</span><span class="token punctuation">:</span> chunk<span class="token punctuation">.</span>content<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">100</span><span class="token punctuation">]</span> <span class="token operator">+</span> <span class="token string">"..."</span>                        <span class="token keyword">if</span> len<span class="token punctuation">(</span>chunk<span class="token punctuation">.</span>content<span class="token punctuation">)</span> <span class="token operator">></span> <span class="token number">100</span>                        <span class="token keyword">else</span> chunk<span class="token punctuation">.</span>content<span class="token punctuation">,</span>                    <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#125;</span>                <span class="token punctuation">)</span>          <span class="token comment" spellcheck="true"># 按分数排序并返回前5个</span>        results<span class="token punctuation">.</span>sort<span class="token punctuation">(</span>key<span class="token operator">=</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> x<span class="token punctuation">[</span><span class="token string">"score"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> reverse<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>        <span class="token keyword">return</span> results<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">5</span><span class="token punctuation">]</span>      <span class="token keyword">def</span> <span class="token function">getFilesMeta</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> kb_id<span class="token punctuation">:</span> int<span class="token punctuation">,</span> file_ids<span class="token punctuation">:</span> List<span class="token punctuation">[</span>int<span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> List<span class="token punctuation">[</span>Dict<span class="token punctuation">]</span><span class="token punctuation">:</span>        <span class="token triple-quoted-string string">"""获取文件元信息"""</span>        result <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>        <span class="token keyword">for</span> file_id <span class="token keyword">in</span> file_ids<span class="token punctuation">:</span>            file_info <span class="token operator">=</span> next<span class="token punctuation">(</span><span class="token punctuation">(</span>f <span class="token keyword">for</span> f <span class="token keyword">in</span> self<span class="token punctuation">.</span>files <span class="token keyword">if</span> f<span class="token punctuation">.</span>id <span class="token operator">==</span> file_id<span class="token punctuation">)</span><span class="token punctuation">,</span> None<span class="token punctuation">)</span>            <span class="token keyword">if</span> file_info<span class="token punctuation">:</span>                result<span class="token punctuation">.</span>append<span class="token punctuation">(</span>                    <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;</span>                        <span class="token string">"id"</span><span class="token punctuation">:</span> file_info<span class="token punctuation">.</span>id<span class="token punctuation">,</span>                        <span class="token string">"filename"</span><span class="token punctuation">:</span> file_info<span class="token punctuation">.</span>filename<span class="token punctuation">,</span>                        <span class="token string">"chunk_count"</span><span class="token punctuation">:</span> file_info<span class="token punctuation">.</span>chunk_count<span class="token punctuation">,</span>                        <span class="token string">"status"</span><span class="token punctuation">:</span> file_info<span class="token punctuation">.</span>status<span class="token punctuation">,</span>                    <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#125;</span>                <span class="token punctuation">)</span>        <span class="token keyword">return</span> result      <span class="token keyword">def</span> <span class="token function">readFileChunks</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> kb_id<span class="token punctuation">:</span> int<span class="token punctuation">,</span> chunks<span class="token punctuation">:</span> List<span class="token punctuation">[</span>Dict<span class="token punctuation">[</span>str<span class="token punctuation">,</span> int<span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> List<span class="token punctuation">[</span>Dict<span class="token punctuation">]</span><span class="token punctuation">:</span>        <span class="token triple-quoted-string string">"""读取具体的文件片段"""</span>        result <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>        <span class="token keyword">for</span> chunk_spec <span class="token keyword">in</span> chunks<span class="token punctuation">:</span>            file_id <span class="token operator">=</span> chunk_spec<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">"fileId"</span><span class="token punctuation">)</span>            chunk_index <span class="token operator">=</span> chunk_spec<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">"chunkIndex"</span><span class="token punctuation">)</span>              chunk <span class="token operator">=</span> self<span class="token punctuation">.</span>chunks<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token punctuation">(</span>file_id<span class="token punctuation">,</span> chunk_index<span class="token punctuation">)</span><span class="token punctuation">)</span>            <span class="token keyword">if</span> chunk<span class="token punctuation">:</span>                result<span class="token punctuation">.</span>append<span class="token punctuation">(</span>                    <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;</span>                        <span class="token string">"file_id"</span><span class="token punctuation">:</span> file_id<span class="token punctuation">,</span>                        <span class="token string">"chunk_index"</span><span class="token punctuation">:</span> chunk_index<span class="token punctuation">,</span>                        <span class="token string">"content"</span><span class="token punctuation">:</span> chunk<span class="token punctuation">.</span>content<span class="token punctuation">,</span>                        <span class="token string">"filename"</span><span class="token punctuation">:</span> next<span class="token punctuation">(</span>                            f<span class="token punctuation">.</span>filename <span class="token keyword">for</span> f <span class="token keyword">in</span> self<span class="token punctuation">.</span>files <span class="token keyword">if</span> f<span class="token punctuation">.</span>id <span class="token operator">==</span> file_id                        <span class="token punctuation">)</span><span class="token punctuation">,</span>                    <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#125;</span>                <span class="token punctuation">)</span>        <span class="token keyword">return</span> result      <span class="token keyword">def</span> <span class="token function">listFilesPaginated</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> kb_id<span class="token punctuation">:</span> int<span class="token punctuation">,</span> page<span class="token punctuation">:</span> int<span class="token punctuation">,</span> page_size<span class="token punctuation">:</span> int<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> List<span class="token punctuation">[</span>Dict<span class="token punctuation">]</span><span class="token punctuation">:</span>        <span class="token triple-quoted-string string">"""分页列出文件"""</span>        start <span class="token operator">=</span> page <span class="token operator">*</span> page_size        end <span class="token operator">=</span> start <span class="token operator">+</span> page_size          files_slice <span class="token operator">=</span> self<span class="token punctuation">.</span>files<span class="token punctuation">[</span>start<span class="token punctuation">:</span>end<span class="token punctuation">]</span>        <span class="token keyword">return</span> <span class="token punctuation">[</span>            <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;</span>                <span class="token string">"id"</span><span class="token punctuation">:</span> f<span class="token punctuation">.</span>id<span class="token punctuation">,</span>                <span class="token string">"filename"</span><span class="token punctuation">:</span> f<span class="token punctuation">.</span>filename<span class="token punctuation">,</span>                <span class="token string">"chunk_count"</span><span class="token punctuation">:</span> f<span class="token punctuation">.</span>chunk_count<span class="token punctuation">,</span>                <span class="token string">"status"</span><span class="token punctuation">:</span> f<span class="token punctuation">.</span>status<span class="token punctuation">,</span>            <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#125;</span>            <span class="token keyword">for</span> f <span class="token keyword">in</span> files_slice        <span class="token punctuation">]</span>    <span class="token comment" spellcheck="true"># 初始化模拟的知识库控制器</span>kb_controller <span class="token operator">=</span> MockKnowledgeBaseController<span class="token punctuation">(</span><span class="token punctuation">)</span>knowledge_base_id <span class="token operator">=</span> <span class="token number">1</span>  <span class="token comment" spellcheck="true"># 模拟的知识库ID</span>    <span class="token comment" spellcheck="true"># 定义四个核心工具</span>@tool<span class="token punctuation">(</span><span class="token string">"query_knowledge_base"</span><span class="token punctuation">)</span><span class="token keyword">def</span> <span class="token function">query_knowledge_base</span><span class="token punctuation">(</span>query<span class="token punctuation">:</span> str<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> str<span class="token punctuation">:</span>    <span class="token triple-quoted-string string">"""Query a knowledge base with semantic search"""</span>    results <span class="token operator">=</span> kb_controller<span class="token punctuation">.</span>search<span class="token punctuation">(</span>knowledge_base_id<span class="token punctuation">,</span> query<span class="token punctuation">)</span>    <span class="token keyword">return</span> json<span class="token punctuation">.</span>dumps<span class="token punctuation">(</span>results<span class="token punctuation">,</span> ensure_ascii<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> indent<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>    @tool<span class="token punctuation">(</span><span class="token string">"get_files_meta"</span><span class="token punctuation">)</span><span class="token keyword">def</span> <span class="token function">get_files_meta</span><span class="token punctuation">(</span>fileIds<span class="token punctuation">:</span> List<span class="token punctuation">[</span>int<span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> str<span class="token punctuation">:</span>    <span class="token triple-quoted-string string">"""Get metadata for files in the current knowledge base."""</span>    <span class="token keyword">if</span> <span class="token operator">not</span> fileIds<span class="token punctuation">:</span>        <span class="token keyword">return</span> <span class="token string">"请提供文件ID数组"</span>    results <span class="token operator">=</span> kb_controller<span class="token punctuation">.</span>getFilesMeta<span class="token punctuation">(</span>knowledge_base_id<span class="token punctuation">,</span> fileIds<span class="token punctuation">)</span>    <span class="token keyword">return</span> json<span class="token punctuation">.</span>dumps<span class="token punctuation">(</span>results<span class="token punctuation">,</span> ensure_ascii<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> indent<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>    @tool<span class="token punctuation">(</span><span class="token string">"read_file_chunks"</span><span class="token punctuation">)</span><span class="token keyword">def</span> <span class="token function">read_file_chunks</span><span class="token punctuation">(</span>chunks<span class="token punctuation">:</span> List<span class="token punctuation">[</span>Dict<span class="token punctuation">[</span>str<span class="token punctuation">,</span> int<span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> str<span class="token punctuation">:</span>    <span class="token triple-quoted-string string">"""Read content chunks from specified files in the current knowledge base."""</span>    <span class="token keyword">if</span> <span class="token operator">not</span> chunks<span class="token punctuation">:</span>        <span class="token keyword">return</span> <span class="token string">"请提供要读取的chunk信息数组"</span>    results <span class="token operator">=</span> kb_controller<span class="token punctuation">.</span>readFileChunks<span class="token punctuation">(</span>knowledge_base_id<span class="token punctuation">,</span> chunks<span class="token punctuation">)</span>    <span class="token keyword">return</span> json<span class="token punctuation">.</span>dumps<span class="token punctuation">(</span>results<span class="token punctuation">,</span> ensure_ascii<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> indent<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>    @tool<span class="token punctuation">(</span><span class="token string">"list_files"</span><span class="token punctuation">)</span><span class="token keyword">def</span> <span class="token function">list_files</span><span class="token punctuation">(</span>page<span class="token punctuation">:</span> int <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">,</span> pageSize<span class="token punctuation">:</span> int <span class="token operator">=</span> <span class="token number">10</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> str<span class="token punctuation">:</span>    <span class="token triple-quoted-string string">"""List all files in the current knowledge base. Returns file ID, filename, and chunk count."""</span>    results <span class="token operator">=</span> kb_controller<span class="token punctuation">.</span>listFilesPaginated<span class="token punctuation">(</span>knowledge_base_id<span class="token punctuation">,</span> page<span class="token punctuation">,</span> pageSize<span class="token punctuation">)</span>    <span class="token keyword">return</span> json<span class="token punctuation">.</span>dumps<span class="token punctuation">(</span>results<span class="token punctuation">,</span> ensure_ascii<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> indent<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">create_agentic_rag_system</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">"""创建 Agentic RAG 系统"""</span>      <span class="token comment" spellcheck="true"># 工具清单</span>    tools <span class="token operator">=</span> <span class="token punctuation">[</span>query_knowledge_base<span class="token punctuation">,</span> get_files_meta<span class="token punctuation">,</span> read_file_chunks<span class="token punctuation">,</span> list_files<span class="token punctuation">]</span>      <span class="token comment" spellcheck="true"># 行为策略（系统提示）</span>    SYSTEM_PROMPT <span class="token operator">=</span> <span class="token triple-quoted-string string">"""你是一个 Agentic RAG 助手。请遵循以下策略逐步收集证据后回答：  1. 先用 query_knowledge_base 搜索相关内容，获得候选文件和片段线索2. 根据搜索结果，选择最相关的文件，可选择性使用 get_files_meta 查看详细文件信息3. 使用 read_file_chunks 精读最相关的2-3个片段内容作为证据4. 基于读取的具体片段内容组织答案5. 回答末尾用"引用："格式列出实际读取的fileId和chunkIndex  重要原则：- 不要编造信息，只基于实际读取的片段内容回答- 若证据不足，请说明并建议进一步搜索的方向- 优先选择评分高的搜索结果进行深入阅读"""</span>      <span class="token comment" spellcheck="true"># 模型与 Agent</span>    llm <span class="token operator">=</span> ChatOpenAI<span class="token punctuation">(</span>        <span class="token comment" spellcheck="true"># model="gpt-3.5-turbo",  # 使用 OpenAI 默认模型便于测试</span>        temperature<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span>        max_retries<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span>        <span class="token comment" spellcheck="true"># 如需使用其他API，可配置 base_url</span>        base_url<span class="token operator">=</span><span class="token string">"https://api.siliconflow.cn/v1"</span><span class="token punctuation">,</span>        model<span class="token operator">=</span><span class="token string">"THUDM/glm-4-9b-chat"</span><span class="token punctuation">,</span>    <span class="token punctuation">)</span>      agent <span class="token operator">=</span> create_react_agent<span class="token punctuation">(</span>llm<span class="token punctuation">,</span> tools<span class="token punctuation">,</span> prompt<span class="token operator">=</span>SYSTEM_PROMPT<span class="token punctuation">)</span>    <span class="token keyword">return</span> agent    <span class="token keyword">def</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">"""主函数 - 演示 Agentic RAG 的工作流程"""</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"🚀 初始化 Agentic RAG 系统..."</span><span class="token punctuation">)</span>    agent <span class="token operator">=</span> create_agentic_rag_system<span class="token punctuation">(</span><span class="token punctuation">)</span>      <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"\n📚 模拟知识库包含以下文件："</span><span class="token punctuation">)</span>    <span class="token keyword">for</span> file <span class="token keyword">in</span> kb_controller<span class="token punctuation">.</span>files<span class="token punctuation">:</span>        <span class="token keyword">print</span><span class="token punctuation">(</span>f<span class="token string">"  - &amp;#123;file.filename&amp;#125; (&amp;#123;file.chunk_count&amp;#125; chunks)"</span><span class="token punctuation">)</span>      <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"\n"</span> <span class="token operator">+</span> <span class="token string">"="</span> <span class="token operator">*</span> <span class="token number">80</span><span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"💬 开始问答演示"</span><span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"="</span> <span class="token operator">*</span> <span class="token number">80</span><span class="token punctuation">)</span>      <span class="token comment" spellcheck="true"># 测试问题</span>    question <span class="token operator">=</span> <span class="token string">"请基于知识库，概述 RAG 的优缺点，并给出引用。"</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>f<span class="token string">"\n❓ 问题: &amp;#123;question&amp;#125;"</span><span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"\n🤔 Agent 思考与行动过程:"</span><span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"-"</span> <span class="token operator">*</span> <span class="token number">50</span><span class="token punctuation">)</span>      <span class="token comment" spellcheck="true"># 调用 Agent</span>    result <span class="token operator">=</span> agent<span class="token punctuation">.</span>invoke<span class="token punctuation">(</span><span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;"messages": [("user", question)]&amp;#125;)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"======"</span><span class="token punctuation">)</span>    final_answer <span class="token operator">=</span> result<span class="token punctuation">[</span><span class="token string">"messages"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>content    <span class="token keyword">print</span><span class="token punctuation">(</span>result<span class="token punctuation">)</span>    <span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">"__main__"</span><span class="token punctuation">:</span>    main<span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre>]]></content>
      
      
      
        <tags>
            
            <tag> 学习笔记 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>2025年（26届）四非CS保研经验帖</title>
      <link href="/2025/10/16/sui-bi-bao-yan-jing-yan-tie/"/>
      <url>/2025/10/16/sui-bi-bao-yan-jing-yan-tie/</url>
      
        <content type="html"><![CDATA[<h1 id="2025年（26届）四非CS保研经验帖"><a href="#2025年（26届）四非CS保研经验帖" class="headerlink" title="2025年（26届）四非CS保研经验帖"></a>2025年（26届）四非CS保研经验帖</h1><hr><h3 id="一、写在前面"><a href="#一、写在前面" class="headerlink" title="一、写在前面"></a>一、写在前面</h3><p>25年保研终于画上句号。由于今年的政策变动，形势和往年相比有了一些区别。</p><p>总的来说，感觉难度也更上一层楼，或许以后的几年会变得更难，但机会也总是一直都有的。今年整体来说感觉更偏向弱com，和老师的双向联系交流变得尤其重要。最后捡漏机会也确有不少。</p><p>在这里我记录了自己这半年的大致历程，希望一些经验和教训能够帮到看到这篇帖子的你💝。</p><hr><h3 id="二、基本背景"><a href="#二、基本背景" class="headerlink" title="二、基本背景"></a>二、基本背景</h3><ul><li><p><strong>本科院校</strong>：北京某四非</p></li><li><p><strong>专业</strong>：数据科学与大数据技术</p></li><li><p><strong>GPA</strong>：4.4&#x2F;5.0</p></li><li><p><strong>排名</strong>：2&#x2F;59（专业排名）</p></li><li><p><strong>英语</strong>：CET-6 516, CET-4 562</p></li><li><p><strong>竞赛</strong>：互联网+国三、挑战杯省金、蓝桥杯国三、CCF-TEC国三、计设省二…（比较水，多数都在大一大二时期搞的）</p></li><li><p><strong>论文</strong>：已接收的有两篇，一篇 CCF-A 类会议二作（实习产出）、一篇 CCF-B 类会议一作（全正分 Oral）</p></li><li><p><strong>最终去向</strong>：浙江大学计算机学院直博</p></li></ul><hr><h3 id="三、夏令营-预推免情况"><a href="#三、夏令营-预推免情况" class="headerlink" title="三、夏令营 &amp; 预推免情况"></a>三、夏令营 &amp; 预推免情况</h3><p>对于双非四非的同学，我的建议是【<strong>！一定要提前联系老师！</strong>】，否则夏令营和预推免简直就是火葬场。</p><p>在后面联系一位电科的老师时，老师面试的时候直接告知我，在预推免和夏令营阶段学院都会下发一个 Excel 表，老师可以给自己推荐的同学填表（也就是推荐名额），被推荐的同学没有什么硬性问题的话就是能够被直接捞入营的。当然电科是弱com，不过我怀疑有些强com学校可能也会这样做。而且假如老师真的想要你，那么提前跟学院教务打个招呼，想来教务也不太会不给老师面子。</p><p>当然，在前期我也尝试联系过一位 HIT 做 LLM 方向的老师，而那位老师直接告诉我，“网上的传言都是真的，我们这边会强制机筛一遍，你是一定过不了学院筛选的，想来我们这边的话，我只能给你其它学校联培的名额”。所以像 HIT 这种歧视拉满的还是算了罢。</p><p>我的夏令营与预推免也是完美印证了这一点。由于自己也不太想霸着老师的推荐名额，所以基本上会早点跟老师释放 offer，除去自己明确有意愿想去的学校外，别的院校夏令营、预推免几乎全部是裸投。</p><p>可以预想到，对于双非四非出身的我来说，夏令营预推免的入营会非常惨烈，但我也没想到会这么惨：</p><table><thead><tr><th><strong>夏令营</strong></th><th>申请项</th><th>入营</th><th>优营</th><th>备注</th></tr></thead><tbody><tr><td>浙江大学-计算机学院</td><td>直博</td><td>√</td><td>√</td><td>捞入营</td></tr><tr><td>复旦大学-大数据学院</td><td>直博</td><td>×</td><td></td><td>没联系老师，报着玩</td></tr><tr><td>中国科学技术大学-苏高院</td><td>专硕</td><td>×</td><td></td><td>没联系老师，报着玩</td></tr><tr><td>东南大学-palm实验室</td><td>学硕</td><td>×</td><td></td><td>犯蠢搞丢了</td></tr><tr><td>厦门大学-信息学院</td><td>学硕</td><td>√</td><td>不设</td><td>捞入营</td></tr><tr><td>华东师范大学-计算机学院</td><td>专硕</td><td>×</td><td></td><td>报软院就捞进去了</td></tr><tr><td>中山大学-计算机学院</td><td>专硕</td><td>×</td><td></td><td>联系了老师，但强com捞不了四非</td></tr><tr><td>南开大学-人工智能学院</td><td>专硕</td><td>×</td><td></td><td>没联系老师，报着玩</td></tr><tr><td>上海科技大学-信息科学与技术学院</td><td>专硕</td><td>×</td><td></td><td>犯蠢报了个专硕</td></tr><tr><td>电子科技大学-计算机学院</td><td>专硕</td><td>×</td><td></td><td>联系了老师，后面释放了</td></tr><tr><td>山东大学-软件学院</td><td>专硕</td><td>√</td><td></td><td>宣讲营</td></tr><tr><td>南方科技大学-统计与数据科学学院</td><td>学硕</td><td>-</td><td>-</td><td>联系了老师，结果夏令营取消了说是…</td></tr></tbody></table><blockquote><p>预推免不信邪，除上科大专硕裸投入了以外，其余收获了清一色的叉号，自己都有点难绷🤡</p></blockquote><table><thead><tr><th><strong>预推免</strong></th><th>申请项</th><th>入营</th><th>offer</th><th>备注</th></tr></thead><tbody><tr><td>浙江大学-计算机学院</td><td>直博</td><td>√</td><td>√</td><td>夏令营优营直入</td></tr><tr><td>上海科技大学-信息学院</td><td>专硕</td><td>√</td><td>跟上面冲突，放弃</td><td>唯一裸投入的</td></tr><tr><td>复旦大学-机器人制造工研院</td><td>专硕</td><td>×</td><td></td><td>这个和往下全是裸投…</td></tr><tr><td>南京大学-软件学院</td><td>专硕</td><td>×</td><td></td><td></td></tr><tr><td>中国科学技术大学-网络安全学院</td><td>专硕</td><td>×</td><td></td><td></td></tr><tr><td>中国科学技术大学-工程专项</td><td>工程硕</td><td>×</td><td></td><td></td></tr><tr><td>同济大学-计算机学院</td><td>学硕</td><td>×</td><td></td><td></td></tr><tr><td>华东师范大学-软件学院</td><td>专硕</td><td>×</td><td></td><td></td></tr><tr><td>厦门大学-信息学院</td><td>学硕</td><td>×</td><td></td><td></td></tr><tr><td>南开大学-软件学院</td><td>专硕</td><td>×</td><td></td><td></td></tr><tr><td>电子科技大学-计算机学院</td><td>学硕</td><td>×</td><td></td><td></td></tr><tr><td>南方科技大学-计算机学院</td><td>学硕</td><td>×</td><td></td><td></td></tr><tr><td>北京航空航天大学-网安学院</td><td>专硕</td><td>×</td><td></td><td></td></tr><tr><td>北京师范大学-人工智能学院</td><td>学硕</td><td>×</td><td></td><td></td></tr><tr><td>山东大学-计算机学院</td><td>学硕</td><td>×</td><td></td><td></td></tr><tr><td>山东大学-软件学院</td><td>学硕</td><td>×</td><td></td><td></td></tr><tr><td>山东大学-浪潮人工智能学院</td><td>学硕</td><td>×</td><td></td><td></td></tr><tr><td>重庆大学-计算机学院</td><td>学硕</td><td>×</td><td></td><td></td></tr><tr><td>湖南大学-计算机学院</td><td>学硕</td><td>×</td><td></td><td></td></tr></tbody></table><hr><h3 id="四、保研历程"><a href="#四、保研历程" class="headerlink" title="四、保研历程"></a>四、保研历程</h3><p> 回顾自己保研经历的这半年，不说坎坷崎岖，至少也得是凹凸不平。所以我写得可能有点多（废话也不少），感兴趣的同学就权当故事看看吧。<strong>懒得看的同学可以直接跳到第五部分</strong>。</p><h4 id="挫败"><a href="#挫败" class="headerlink" title="挫败"></a>挫败</h4><blockquote><p>大三下半学年，我在北邮已经实习半年多，<strong>这次实习是我人生中遇到的最有幸的机遇之一，遇到了非常非常非常好的z老师，以及来自清华大学KEG实验室的博士生s学长</strong>。受到老师和学长的帮助，学到很多很多东西。</p></blockquote><p>所以我的起点也算是从北邮开始。在经历了不知多少次犹豫不决与思想斗争之后，我最后还是决定离开北京，去南方发展，意向更多地偏向江浙沪地区的高校。</p><p>因此，我在4月份就向实习指导我的z老师倾诉了我的内心想法，z老师人也特别好，表示理解我，甚至还提出可以帮我介绍那边认识的一些老师。我心觉惭愧，本身就受恩于人，哪好意思继续索求呢？所以释放掉这边之后，决心不能辜负z老师，一定要交给自己一个完满的答卷。</p><p><img src="https://cyan-1314223569.cos.ap-beijing.myqcloud.com/test/Pasted%20image%2020251014234719.png"></p><p>（虽然只有半年多实习，但我仍然是忠诚的 bupt 信徒！圣北邮✝︎🙏）</p><p>我从中九开始套磁，先后投了三十几封邮件出去。我自觉自己的背景、能力并没有那么优秀出彩，所以一开始也畏畏缩缩不敢向一些华五级别的高校老师投邮件，只敢朝科大先研院、浙软等等这些投递（<strong>事实证明这是我保研历程中最不该的一件事之一，绝对不要学我！一定要大胆尝试投邮件，多争取和老师交流的机会</strong>）。</p><p>在临近5月份的时候，投出的邮件陆陆续续获得了一些结果。首先是中九有很多老师表示了愿意和我面试并保持联系的态度，有些也给了我很积极的回复（华师nlp，电科，南科大，上科大等）。</p><blockquote><p>然而，投去科大先研院的十几封邮件却全部石沉大海，这很大程度上挫败了我的自信心。</p></blockquote><p>这时候自己感觉，是不是已经达不到华五的标准了？<strong>所以后续根本不敢再给华五的老师发邮件。现在想想这种心理真的很不可取，不要遇到一点小挫败就否定自己</strong>！</p><p>因此我继续向中九的一些强导投递。首先是给厦门大学 MAC 实验室，以及另外一名很有名的 nlp 领域的老师分别发送了邮件。结果两者全部石沉大海（当然后来也都有转机，但那都是后面的事情了），当时就感觉自己大概和高中时的梦校厦大无缘了。</p><p>在这个时候，我参加了华东师范大学一位风评非常好的老师的面试。一共面试了三轮，在最后和这位老师交流的时候，我也能感觉到老师真的非常尊重学生，整个面试过程都聊得非常愉快。另外实验室的氛围以及几位学长学姐都给我留下了很深很好的印象，总之就是感觉真的非常适合自己（最终还是没有选择来到这里，也算是自己整个历程的两大遗憾之一）。</p><p>最终的结果出来后，我被告知排名第二名，但老师仅有一个硕士名额，很遗憾还是没有机会留给我。当时瞬间感觉天塌了，因为回顾这次整个面试过程，自我感觉都非常良好，可以说已经发挥得不错了。这一次失败又给我狠狠上了一拳，甚至有时候都有点自我怀疑，难道自己真有这么差吗？</p><h4 id="转机"><a href="#转机" class="headerlink" title="转机"></a>转机</h4><p>就在这时候，我在5月底这段时间迎来了自己整个历程里最关键的一段转折期。</p><p>在鼠群聊天并倾诉自己的焦虑时，有学长学姐鼓励我：可能还是投得不够多，面试经验不够丰富，按理说我的bg不至于会有这样的结果。并建议我多向浙软再投递一下试试。我思考了一下，确实自己在华五也仅仅重点投递了科大先研院，浙软投得真不多。</p><blockquote><p>于是，我开始发了疯一样地向浙软发邮件，几乎把研究方向和自己比较对口的老师全部找了一遍，并投了简历。</p></blockquote><p>意想不到的情况出现了，竟然有近十余位老师对我的邮件表现出积极的回复！我喜出望外，与不少老师进行了面试沟通，最终和几位老师成功加了微信保持联系。</p><p>另外，随着投递进行，越来越多的中九向我递出橄榄枝，顺利通过了天大NLP组一面（由于需要实习考核，后放弃），东南palm一位老师的面试，以及上科大VDI一位知名老师的积极回复。也为自己增添了不少信心。</p><p>与此同时，我在一次机缘巧合下认识了y神（同四非但bg比我强不少的科研大佬），在y神的推荐下，发邮件联系了一位中南大学的顶级年轻强导。这位老师已经仅仅只剩下最后一个空余名额，而且考核要求也比较规范，首先要用一周时间选择两个课题，自主学习并针对领域内的经典论文进行汇报。我硬着头皮开始做这趟考核，并在一周后成功完成进而和老师进行了面试。</p><p>然而这次面试自己的表现简直差到了极点，至今回想起来仍然感觉无地自容。课题汇报环节结束后，老师<strong>突然对我进行了一些深度学习问题的拷打</strong>，但自己这时完全没有去复习过相关知识，第一个问题就大脑宕机，前后问了三个问题竟然一个都没完全答对。这时自己瞬间爆炸，感觉下一秒心脏就要从胸膛里跳出来蹦跶到桌面上。</p><p>老师眼见我都答不上来，遂作罢，转而问我自己工作的问题。这时我稍微松了口气，心想自己的论文都是很熟悉的，总不会答不上来的。结果在给老师推导第一篇论文工作的公式时，突然大脑一片空白，推着推着发现整个式子推了个一塌糊涂。我哑然，只能对着老师嗫嚅说：“啊，这个……哎不对，好像不太对，哎怎么推不出来了……”，我像个刚开始学习走路的孩子一样抓耳挠腮拼命努力着，想要看出推导过程的问题，结果是越看越不明白，越心急越惊慌失措。终于伴随着老师的一声“可以了，先这样吧，我大概了解了”，这场闹剧拉下了帷幕。</p><p>以至于后面老师问我“你还有什么要问的吗”，我什么也说不出来，悻悻笑着说“没什么问题了老师，希望老师能给我一个机会”。</p><p>结果老师笑了笑，回我道“可以，我觉得你还是不错的，这样，我再给你布置一个三天的代码考核，你可以自己选择做或者不做，后续我们可以再针对这个考核结果一起聊聊。”</p><p>我喜出望外，当即回复老师“没问题老师，我愿意试一试！”</p><p>就这样，这次面试结束，我也转入第二轮代码考核，内容是复现一个项目并理解其代码。这次考核兜兜转转持续了一周多（起初我没有算力资源复现，原本已经打算放弃，在y神的鼓励下和老师说明了这件事，结果老师愿意多给我一点时间，后续自己租了点卡跑了简单的实验），最终成功完成了复现工作。</p><p>就在这次针对第二轮考核的汇报里，我预先对项目和原论文做了不少准备，最终汇报明显比第一次更加得心应手，老师所有针对项目的问题都完满地回答了出来。当汇报结束后，老师对我说“没问题，你要确定能来，我过两天会邮件给你发一个正式的 offer 通知”。这时候，瞬间感觉全身无力，激动地快要跳起来了，登时就感觉自己的保研或许提前已经有了结果，自己已经结束了这场战斗。连连感谢老师，走出教室都感觉脚步变得轻快许多。</p><p>可惜，转折又来了。之前面过的那位华师的老师突然告诉我，和软件学院的一位大导借到了名额，我可以把名额挂在大导那里，实际由他来带。我不必跟随软院的要求，也不必研二研三转去滴水湖，而是可以留在普陀跟着他读硕士。这一下瞬间把我的心又撼动起来了。</p><blockquote><p>两个选择摆在自己面前，我那晚几乎彻夜未眠，反复诘问着自己的心，思索构建着自己未来的模样。翻来覆去，我的心中始终没有一个定夺。</p></blockquote><p>第二天起床，我自己拿不定主意，也向家里人征询了一些意见。权衡再三，最终还是做下了一个决定：<strong>拒掉中南大学的 offer</strong>。</p><p>真是没想到，昨晚上才刚刚拿到，这 offer 都还没捂热乎呢，第二天上午我就一封拒信发了过去，表明了自己的意愿。很多朋友都替我惋惜，都说这个机会尤其难得，劝我再多想想。这位老师也真的是一位很好很好的老师，很快就回我邮件，甚至表示可以帮我留着这个名额一段时间，读研后也可以提高一点补贴。但说出去的话就像泼出去的水，邮件既然已经发出去了，也实在不好意思再耽误老师的后续招生，只能作罢。大概我命中注定和 csu 确实没有缘分吧。</p><p>况且也是心存侥幸：万一有机会去 zju 呢？对于想去长三角发展的我来说，能去浙大自然也是最好的选择。</p><p>可当下又面临着一个抉择：去浙软读硕，还是去浙计读博？之前面试的时候，一位意向老师告诉我自己只在计院招生，不在软院招生（然而我是通过浙软的导师名单联系到老师的，有点抽象哈哈）。可计院硕士我是不可能通过学院筛选的，想来的话只能通过夏令营直博。</p><p>因此我思索再三，三个理由扼杀了我对浙软的念头。</p><ul><li><p>其一，按浙软今年的考研形势，以及在绿群鼠群等各个平台上的热度来看，大概率浙软要爆，或许夏令营不会再是海营，我能不能入都是个问题。而浙计能直接捞入营，我不用担心入营的事；</p></li><li><p>其二，本身自己由于地理因素放弃了在长沙的 csu，比起宁波自然更希望去杭州；</p></li><li><p>其三，对于自己来说，读直博这件事也能够接受。</p></li></ul><p>时间此时已经迈入7月，各个学校开始陆续开展夏令营。最终我下定决心，还是去报名计院的夏令营，并跟联系到的所有软院老师表达了意向。</p><h4 id="夏令营"><a href="#夏令营" class="headerlink" title="夏令营"></a>夏令营</h4><p>在7-8月，由于华师老师告知我有软院名额的时候，报名阶段已经结束，而我自己也裸报了计院的夏令营，因而错失了参加华师夏令营的机会。而其它学校老师的推荐名额基本也都已释放，所以实在没有几个学校的夏令营能进得去。</p><p>浙大和厦大是我唯二参加的夏令营，两者都是因为有老师捞才有入营的机会。除此之外的学校裸投全军覆没，无一例外。</p><p>需要说明的是上科大夏令营，这之前邮件联系了VDI的一位老师，老师回复让我报名夏令营，结果我自己没头没脑地报了专硕。后来才知道，上科大的专硕类似工程硕，实际是企业联培，只有学硕才是老师带，老师才有捞的机会。结果与上科大遗憾错过。<strong>所以要告诫大家，在报名和投递的时候千万要先了解搞清楚相关信息，不要抓着瞎报名</strong>。</p><h5 id="厦门大学信息学院夏令营"><a href="#厦门大学信息学院夏令营" class="headerlink" title="厦门大学信息学院夏令营"></a>厦门大学信息学院夏令营</h5><p>先参加的是厦大，大概在7月初的时候开营。之前我虽然联系了MAC实验室，给出的回复是“等待后续面试通知”，结果一直等到夏令营报名马上截止还没有等来面试。可是我实在不想放走去高中梦校的一次机会，无可奈何之下，我转而报名了ASC实验室的面试。这次面试倒是蛮顺利，我也被ASC捞进了夏令营。</p><p>值得一提的是，直到我入营之后，之前联系的另外那位厦大强导居然也重新给我打来了电话（之前一直都没理我，面试机会也没给）。电话内容大概是说收到了我的简历，但奈何投递的同学实在太多看不过来，现在是否还有想法参与考核。我告诉老师已经联系了ASC实验室，婉言谢绝。实际上从群里的消息来看，大概是被鸽了💦。</p><p>不得不说，厦大的翔安新校区真的非常漂亮。给我们提供的宿舍也不错（就是住宿用品真的拉垮，跟睡木板没啥区别），独立卫浴，阳台透光良好。</p><p><img src="https://cyan-1314223569.cos.ap-beijing.myqcloud.com/test/77d1b6678ddec5a596dc8adea7cf9788.jpg"></p><p><img src="https://cyan-1314223569.cos.ap-beijing.myqcloud.com/test/e3691e32155af0df3aa920aa547f3e7d.jpg"></p><p>这段时间也认识了同宿舍的两位哥们（q哥和我一样四非出身，也报了ASC；zq哥则是211出身，入了MAC的强者，最终去了中科大），一起在宿舍聊天聊地。</p><p>第一天就在厦大校区骑着单车转了转，校区特别大，围着转了一上午才绕完一遍。整个校园的环境和景色也都非常令人难忘，只能说不愧是厦大，思明和翔安都是美中美啊。</p><p><img src="https://cyan-1314223569.cos.ap-beijing.myqcloud.com/test/8098d7c7d8e903e7c3090fb67311537e.jpg"></p><p><img src="https://cyan-1314223569.cos.ap-beijing.myqcloud.com/test/7276e3c6856f46a7959d1789186bb80f.jpg"></p><p><img src="https://cyan-1314223569.cos.ap-beijing.myqcloud.com/test/7fd4d32e08bfd82ae1239b49483826ab.jpg"></p><p><img src="https://cyan-1314223569.cos.ap-beijing.myqcloud.com/test/e141253e294b25517fed12a625367fa1.png"></p><p>在厦大夏令营的这段期间也和鼠群里的几位兄弟一起聚了聚。出东门的沙美路是一条小吃街，非常棒。那晚凌晨天下着雨，我们几个直接开始雨中冒险，没带伞淋着雨，跑到沙美路吃了顿烧烤。学长推的店，味道确实不赖。</p><p><img src="https://cyan-1314223569.cos.ap-beijing.myqcloud.com/test/17048009fe4e5e9399e08e6fccdebfb5.jpg"></p><p>夏令营期间的考核倒是并不困难，由于今年不发优营，所以其实也就是把大伙拉进来参观参观，宣讲介绍一下。不过视每个组考核也并不相同，ASC今年仍然有面试环节，需要选读一篇论文汇报，还有自己的个人背景汇报。表现好的话预推免应该也是可以直接占坑的。同样的，MAC今年也有面试，而且据说比较压力面。</p><p>最终汇报完后感觉结果还不错，组里的老师也联系了我并邀我到办公室聊了一会。个人感觉ASC仍然是一个不错的实验室，环境氛围都挺好，只是做的方向对于我而言并不如MAC那般契合。后来我也和老师坦诚说明情况，表示自己还会去尝试浙大夏令营，并不一定会来厦大这边。</p><h5 id="浙江大学计算机学院夏令营"><a href="#浙江大学计算机学院夏令营" class="headerlink" title="浙江大学计算机学院夏令营"></a>浙江大学计算机学院夏令营</h5><p>浙大计算机今年夏令营学院不统一组织，由各个课题组自行组织，每个课题组的形式都不尽相同。开营是线上，当时我还在厦大，一起申报的同学只有我一个四非，其余都是985、211的同学，而且也都非常优秀。当时自我介绍的时候都给我整笑了。“看来zju也与我无缘了”，我一开始的想法非常消极。</p><p>夏令营持续一个月的时间，每位同学会选一个方向进行文献调研并产出综述，另外还要根据调研的结果复现一些经典项目的代码，并最好产出自己的一些idea对其加以修改。可以说直接就是一段小的科研流程考察。</p><p>回到山东自己家里后，我整个人处于一种完全放松的状态，该玩就玩该work就work，完全没有在做夏令营项目的紧张感……主要还是因为自己对这边也不太抱多大希望，另外对华师的这个去向也挺满意，所以还是很松弛地线上做了一两周。不过或许也是得益于这种状态，没有太大的紧张感反而对大脑的思考有所帮助？整个项目自己做得还算顺利，没有出什么太大的差错。</p><p>在一个月时期到后，我们申报的同学一起到浙大线下参与最后的考核汇报。</p><p><img src="https://cyan-1314223569.cos.ap-beijing.myqcloud.com/test/1d9326bf4f619773509796946e11b82c.png"></p><p>玉泉校区是老校区，有种历史的沉淀感，单论校园风光倒不能说是有多么出彩。也没空逛逛校园，这几天的安排还是很紧张的。由于最终汇报是全英文的，要重新修一下PPT和整个汇报过程。大家聚在会议室里一起边改PPT边聊天，现在回想起来也是很难忘的一次经历。</p><p>最终汇报结束后，这几天一直紧绷着的心也终于松了下来。趁着还有时间，我跑到紫金港校区转了一圈，拍了点照片。只能说新校区果然不一样，真的是又大又气派！</p><p><img src="https://cyan-1314223569.cos.ap-beijing.myqcloud.com/test/c201d6da590b1600f926c50622095e2a.jpg"></p><p><img src="https://cyan-1314223569.cos.ap-beijing.myqcloud.com/test/afb7c6399bc576675f709a15c949e461.jpg"></p><p><img src="https://cyan-1314223569.cos.ap-beijing.myqcloud.com/test/c5b7a9a530b02bd8c19cf3f35723e845.jpg"></p><p><img src="https://cyan-1314223569.cos.ap-beijing.myqcloud.com/test/Pasted%20image%2020251014180838.png"></p><p>从紫金港校区出来后，又去风景如画的西湖边上稍作停留。其时的西湖天朗云清，非常漂亮。</p><p><img src="https://cyan-1314223569.cos.ap-beijing.myqcloud.com/test/e9d89bc15737e52112424c185d4f88cb.jpg"></p><p>结束后，我并没有着急回北京，想着不管最后结果如何，多少犒劳下自己吧，便改了高铁票晚上坐到了上海。正值过两天GAF插画艺术节在上海举办，一直都很想去，就买了票准备玩两天去看看。</p><p>在上海逛了很多想去的地方，也和之前保研复旦的特别优秀的学长一起见面聊了聊（收到了来自学长的鼓励！）。最后的两天圆满地逛了GAF插画展会。</p><p><img src="https://cyan-1314223569.cos.ap-beijing.myqcloud.com/test/e14fb6c027385c80adb5650e6b8a2c7f.jpg"></p><p>在展会的场馆里，就在我坐在角落吃着汉堡包的时候，突如其来的电话铃声响了起来：我优营了。</p><p>当时听到这个消息的心情很难回忆了，只觉得这两天无论是展会还是其它，都让我感觉愉快得仿若置身仙境一般。</p><h4 id="预推免"><a href="#预推免" class="headerlink" title="预推免"></a>预推免</h4><p>由于已经拿到了优营，所以自己之后也没再去做更多的尝试了。我将其它的 offer 都一并释放，也跟华师的老师道了一声，老师都表示了理解。</p><p>然而浙计今年的夏令营和往年有所不同，因为不是学院统一组织，所有优营的同学也都还要去参加预推免的流程。也就是还需要过学院的统一面试才能录取。于是，在预推免将开的时候，今年的浙计在网上各个平台都放出来了很多所谓“<strong>优营无效力</strong>”的消息。</p><p>这可把我吓坏了，我把 offer 都释放了，哪还有什么保底，如果学院面被筛了岂不是只能等十推了？这时想起来，还有东南 palm 的保底可以去（东南大学夏令营开的时间很晚很晚）。</p><p>结果等东南大学夏令营出入营结果的时候，我一查名单，怎么没有自己？我在鼠群问了一通，有群友反问我：<strong>“你是不是没填双选系统？”</strong></p><p>于是名场面就诞生了。我压根没仔细看东南大学夏令营的报名说明，完全忽略掉了那一行“需要通过以下推荐系统进行确认”的强调句，这段话甚至还是红色字体。没办法只能认栽。群友们都乐了，说“老师还以为你没报系统，把人家默拒了呢”，只能说自己实在变态。我的这个教训也再一次告诫大家，<strong>一定要看好各个院校的报名通知与说明，不要落下任何信息</strong>。</p><p><img src="https://cyan-1314223569.cos.ap-beijing.myqcloud.com/test/Pasted%20image%2020251015001228.png"></p><p>（完全没注意这个…）</p><p>不过转念想了想，再怎么说也是做了一个月的项目，不至于没有效力吧。与其担忧这些，倒不如多准备准备最终的学院面试，复习备战一下。</p><p>于是，最后就变成了 all in zju 的状态。都这个时间段了，自己也不好意思再去联系老师索要推荐名额（当时还犹豫着联系了几位电科的老师，想着多少做个保底，最后还是都释放了。毕竟这个时间鸽掉的话，老师也不好再去招人了）。所有报名的其它学校预推免全部都是裸投。当然，结果就像上面表格展示的那样，相当惨烈。</p><p>不过最终的事实证明，这些担心也确实都是多余的。到学院面试的那天，我在汇报的时候提及自己已经优营，感觉面试的氛围瞬间就不一样了。后面的提问几乎就是聊天面，仅剩的几个专业课问题我也刚好全都复习到了，全部回答了出来。<strong>认识的优营同学也都成功过了面试，所以说各个平台上的信息大家一定要谨慎甄别，不要轻易听信一些妄自散播焦虑的无用信息</strong>。</p><p>结束后走出面试房间，自我感觉非常良好，很成功的一次面试。心中的那颗大石头总算落下，确确实实地感受到上岸的风已经正在吹向自己了。</p><p><img src="https://cyan-1314223569.cos.ap-beijing.myqcloud.com/test/ee3779bb15cd077f5b2d1f30f686ed9c.jpg"></p><p>那天的杭州下着大雨，走出计算机学院楼的门口，顿时感觉到面前拍来一股潮湿的风浪。</p><hr><p>值得一提的是，今年政策一变，最后的鸽子确实挺厉害。到预推免阶段，甚至有些之前联系未果的强导又重新发消息问我去向是否已确定。所以客观来说的话，只要预推免能入的学校够多，今年捡漏的机会也能更大。</p><p>甚至还有很多预推免报名未入的学校被鸽穿，在925当天及后面打电话询问我去向是否已定（山大人工智能、华师软院等），所以今年十推的捡漏机会也不少。</p><hr><h3 id="五、准备-建议"><a href="#五、准备-建议" class="headerlink" title="五、准备 &amp; 建议"></a>五、准备 &amp; 建议</h3><h4 id="投递建议"><a href="#投递建议" class="headerlink" title="投递建议"></a>投递建议</h4><p>一般发邮件投递简历可以从4月份开始（当然清北和一些华五强组除外），我算是个反面教材，畏畏缩缩总是不敢发邮件。细数当时的经历，如果自己朝着一些中九强导，或者像复旦南大中科大这些华五高校多去投递，应该也是有机会的，但自己偏偏没去干。</p><p>所以<strong>不要有任何自卑情结，不去尝试永远也不知道自己的上限在哪里</strong>。另外也不要抱着“我是不是准备得还不够充分”这样的想法，不敢去给自己的梦导梦校发邮件。实际上无论是4月份的约面，还是8月底预推免时期的约面，老师的问题其实也都大差不差，即便让4月的我穿越去8月面试，结果应该也没有太大区别。只要对自己简历上的内容、个人汇报PPT的内容准备妥当，外加复习一些科研方向的相关知识，就可以大胆去尝试投递。</p><p>略微总结了一下，<strong>最关键的要点</strong>就是下面几个：</p><ol><li><strong>海投邮件联系导师</strong>。这毕竟只是和老师彼此的初步了解，永远不要畏缩害怕，大胆投；</li><li><strong>邮件内容简洁明晰</strong>。陶瓷信不要写得长篇大论介绍自己，更不要依赖AI撰写。简洁清晰地写明白自己的核心竞争点，让老师一眼就能看清楚；</li><li><strong>尽早联系，并多争取后续机会</strong>。尽量早些和老师进行邮件交流，并且即便老师短期没有回复或回复结果尚不理想，后期一样可以继续发邮件礼貌询问争取，毕竟还有鸽子的存在。</li></ol><h4 id="面试-考核建议"><a href="#面试-考核建议" class="headerlink" title="面试 &amp; 考核建议"></a>面试 &amp; 考核建议</h4><p>由于我的投递策略出大问题，因此获得的面试和考核机会也并不算多。不过结果都还可以，基本上但凡有面试和考核机会，最终都能取得不错的反馈。要点有以下几个：</p><ol><li><strong>表达能力很关键</strong>。这或许也与性格有一定关系，老师们普遍更欣赏热情、主动、积极、自信的同学。所以一定要多多练习，敢于发言，落落大方，面试过程中让对方觉得你是一个会认真倾听、有想法和思考、擅于表达自己的人；</li><li><strong>尽早锻炼机考能力</strong>。很多老师比较看重机考水平，尽管在我的保研历程里并没有参加多少机试，但约面时确有不少老师考察或询问过算法能力。ACMer 在这方面比较占优，不打算竞的同学也要尽量早些学习完 Acwing 基础课或力扣 hot100 的内容。</li><li><strong>包装简历和个人PPT</strong>。注意这里的包装有两层含义，一是美观，不能太丑（这里建议使用 Overleaf 的简历模版，并自行加以修改）；二是尽可能地去表现出老师希望了解的东西，不要在一些无用的点上强调太多。</li></ol><h4 id="复习建议"><a href="#复习建议" class="headerlink" title="复习建议"></a>复习建议</h4><p>对于面试专业课和一些八股知识，我在整个保研过程中被问得不多，不过被问到的问题也都不是什么很难很刁钻的问题。比如 408，整个系统复习一遍，并且把常见的面试问题整理并熟练掌握基本就可以了。而自己科研方向的问题，尽量掌握得深入一些，这样和老师交流过程中也有可以聊的东西。</p><p>最好在前期多深入复习一些自己研究领域的知识，因为个人感觉和老师约面时问 408 专业课的情况很少。后期夏令营、预推免学院面的时候，再重点复习一下专业课。</p><h4 id="其它"><a href="#其它" class="headerlink" title="其它"></a>其它</h4><p>对于自己的履历信息，个人感觉除去成绩以外，<strong>只有两项东西有价值</strong>：一是论文（科研经历），二是牌子（算法水平）。对于双非四非的同学来说尤其如此。</p><p>论文反映你的科研水平，这无疑是老师最看重的东西。而且在于质量而不在数量，实际上在我面试的时候，那篇B会论文基本都很少有老师问起，大部分老师都最关心我的第一篇A会论文，那篇论文的公式我也推了无数遍。对于竞赛，则几乎无一位老师向我问起。或许是因为我压根就没有什么有含金量的竞赛奖项（比如 ACM, Kaggle 这样的比赛）。</p><p>而牌子反映你的算法水平，实际也就是 coding 能力。有牌子的同学无疑机试会更具优势，而同时带着牌子和论文的同学则更是具备竞争力。</p><p>很多网上的信息或许都会告诉你：绩点排名是第一，是最关键的东西，rk1 &gt; 一切。或许对 985、211 的同学来说确是如此，凭着高排名，在很多高校学院筛选的时候会具备很大优势，就从今年的形势来看，很多院校甚至是只要有机会入面，就大概率能够锁定有 offer 可拿了。可对于双非四非的同学来说，绩点排名根本不足以反映你的实际能力如何，要想清楚自己的竞争力体现在哪里。比如 985 院校的专业第一名，老师能够从中看出这位同学的学习能力一定很有潜力，但四非专业第一可以说明吗？基本没有什么说服力。至少我们学校的期末考试难度相比来说确实非常简单。所以一定要在另外一些方面寻找突破，证明自己的潜力。</p><p>我尤其感觉在有论文的情况下，与老师邮件联系明显会更有优势一些，取得不错的科研成果也更容易受老师青睐。</p><p>总而言之，<strong>适合每个人的道路都不尽相同，只有做自己最擅长的事才有效果</strong>。选择最能够证明自己能力的方向才是正确的，不要将互联网上的一些信息奉为圭臬，要有自己的判断。</p><hr><h3 id="六、总结"><a href="#六、总结" class="headerlink" title="六、总结"></a>六、总结</h3><p>因为想说的实在有太多太多，单凭一篇经验帖真是难以记下。写得也多了些，也向浏览这篇帖子的读者道一声歉。</p><p>可能有些23级、24级乃至更小的同学看到这篇帖子，希望我的经历能够对你有所帮助。另外，尽管自己最终通过保研顺利上岸，但也想跟读到这篇帖子的你分享下我的想法。我想人生道路千万条，或许保研，甚至读研这条路都未必是最适合你的路，趁还有时间和试错的机会，多多向自己的内心问一问，想想自己真正想要和想追求的东西是什么。</p><p>或许最后你会想到一些别的选择，会觉得也许“我还有其它更想做的东西”，“我还有这辈子都渴望去实现的其它的事”，只是可能你还没有勇气去做出这样的抉择。</p><p>可这世上总是有舍才有得，在获得一些东西的时候，总要放弃别的一些东西。因此请切记这一点，All In 可能也是一种智慧，但求问心无愧。</p><p>我想起来大一的时候，当时一位我至今都非常景仰的学长，在社团向刚入大学的我们分享。他说，<strong>希望今天坐在这里的你们，每个人心里都要揣着一个梦想。“它不止能驱动着你跑完这4年的学业生涯，更能在你3万余天的人生路上为你指引方向</strong>。”这句话影响我时至今日。</p><p>所以我一直很敬佩那些敢于放下一切其它顾虑，无所旁骛地追求自己目标的人。那种感觉一定很纯粹，无暇到让外人难以触碰。</p><p>直到今天，一切尘埃落定，自己的心态和过去相比也潜移默化地发生着改变。对于自己的未来，慢慢地有更清晰的东西在脑海里渐渐浮现。如今自己的状态和过去相比也截然不同，那种为了梦想而行的驱动力也和以往相比变得更加有力。记得面试时有位老师曾笑着告诉我，“感觉你有点自卑情结呀，要更自信一点”。回头想想，过去的自己确实充满畏缩、充满惰性，总是习惯和自己妥协。而现在，似乎这一切都开始向着积极的方向发生转变。</p><p>最后想在这里记一下自己最喜欢的一段话，是史铁生老师在《病隙碎笔》的散文里所写的：</p><p>“人不能走到天堂，只能走向天堂。走向，意味着彼岸的成立；走到，岂非彼岸的缺失？所以天堂并非一处空间，一处物质性的存在，而是一条道路，一条精神的恒途。”</p><p>精神的天堂恰于走向中成立，永远的限制是其永远成立的依据。形象地说：“设若你果真到了天堂，然后呢？无所眺望或另有眺望都证明所至之地并非圆满。而你若永远地走向它，你便随时都沐浴在它的光照之下。”</p><blockquote><p><em><strong>尽管向着天堂而进吧！愿各位都能走在流淌着天堂光辉的道路上</strong></em>。</p></blockquote><hr><p>这里再次感谢整个保研过程中帮助我很多的四非鼠群，也在这里认识了很多一起保研的朋友。欢迎四非出身的同学加入。引用一下C神的话，<strong>“让机构有多远滚多远，让 mouse help mouse。”</strong></p><p><strong>四非鼠鼠保研交流群 - Q群号：742203503</strong></p>]]></content>
      
      
      
        <tags>
            
            <tag> 随笔 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Build Agent Syetem with Langgraph &amp; DeepSeek</title>
      <link href="/2025/10/12/xue-xi-build-agent-syetem-with-langgraph-deepseek/"/>
      <url>/2025/10/12/xue-xi-build-agent-syetem-with-langgraph-deepseek/</url>
      
        <content type="html"><![CDATA[<h1 id="Build-Agent-Syetem-with-Langgraph-DeepSeek"><a href="#Build-Agent-Syetem-with-Langgraph-DeepSeek" class="headerlink" title="Build Agent Syetem with Langgraph &amp; DeepSeek"></a>Build Agent Syetem with Langgraph &amp; DeepSeek</h1><hr><h3 id="Environment"><a href="#Environment" class="headerlink" title="Environment"></a>Environment</h3><p>首先使用 pip 安装相关依赖包：</p><pre class=" language-python"><code class="language-python">    pip install langchain    pip install langgraph</code></pre><p>配置一下 API 和 URL：</p><pre class=" language-python"><code class="language-python"><span class="token keyword">from</span> dotenv <span class="token keyword">import</span> load_dotenv<span class="token keyword">import</span> os  load_dotenv<span class="token punctuation">(</span><span class="token string">".env"</span><span class="token punctuation">)</span>  BASE_URL <span class="token operator">=</span> <span class="token string">"https://api.deepseek.com"</span>API_KEY <span class="token operator">=</span> os<span class="token punctuation">.</span>environ<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">"API_KEY"</span><span class="token punctuation">)</span>  deepseek_chat_model <span class="token operator">=</span> <span class="token string">"deepseek-chat"</span></code></pre><h3 id="Initialization-Agent"><a href="#Initialization-Agent" class="headerlink" title="Initialization Agent"></a>Initialization Agent</h3><p>一共有三种方式来初始化 Agent：</p><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 1. langchain: init model,invoke,prompt template（比较简单通用）</span><span class="token comment" spellcheck="true"># 2. langgraph memory</span><span class="token comment" spellcheck="true"># 3. langgraph create_react_agent</span></code></pre><h4 id="Langchain"><a href="#Langchain" class="headerlink" title="Langchain"></a>Langchain</h4><p>DeepSeek 兼容 openai sdk，因此可以调用 langchain_openai 来导入模型。不过 DeepSeek 自己也有 langchain 专门的一个 sdk，也可以直接调用。这种方法就是 ChatXXX Model 来进行一个初始化。</p><pre class=" language-python"><code class="language-python"><span class="token keyword">from</span> langchain_openai <span class="token keyword">import</span> ChatOpenAI<span class="token comment" spellcheck="true"># from langchain_deepseek import ChatDeepSeek</span><span class="token keyword">from</span> langchain_core<span class="token punctuation">.</span>messages <span class="token keyword">import</span> HumanMessage<span class="token keyword">from</span> langchain_core<span class="token punctuation">.</span>prompts <span class="token keyword">import</span> ChatPromptTemplate  llm1 <span class="token operator">=</span> ChatOpenAI<span class="token punctuation">(</span>model<span class="token operator">=</span>deepseek_chat_model<span class="token punctuation">,</span> api_key<span class="token operator">=</span>API_KEY<span class="token punctuation">,</span> base_url<span class="token operator">=</span>BASE_URL<span class="token punctuation">)</span>  result <span class="token operator">=</span> llm1<span class="token punctuation">.</span>invoke<span class="token punctuation">(</span><span class="token punctuation">[</span>HumanMessage<span class="token punctuation">(</span><span class="token string">"给我讲个笑话吧"</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>result<span class="token punctuation">.</span>content<span class="token punctuation">)</span></code></pre><p>更通用的一个方法是使用更统一的 langchain.chat_models 导入：</p><pre class=" language-python"><code class="language-python"><span class="token keyword">from</span> langchain<span class="token punctuation">.</span>chat_models <span class="token keyword">import</span> init_chat_model  llm2 <span class="token operator">=</span> init_chat_model<span class="token punctuation">(</span>    deepseek_chat_model<span class="token punctuation">,</span>    api_key<span class="token operator">=</span>API_KEY<span class="token punctuation">,</span>    base_url<span class="token operator">=</span>BASE_URL<span class="token punctuation">)</span>  result <span class="token operator">=</span> llm2<span class="token punctuation">.</span>invoke<span class="token punctuation">(</span><span class="token punctuation">[</span>HumanMessage<span class="token punctuation">(</span><span class="token string">"给我讲个笑话吧"</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>result<span class="token punctuation">.</span>content<span class="token punctuation">)</span></code></pre><p>初始化模型后，我们接下来可以去创建提示词模版。使用提示词模版的好处在于，每次输入的时候并不需要都传一个 message 参数，大部分时候我们的输入都只是改变其中的一部分内容，所以可以对提示词模版中的部分元素进行一个变量替换。通过方括号 “{}” 可以在 template 里替换掉对应的部分。</p><p>这个提示词模版可以用 langchain 里通用的调用接口 invoke() 来调用。针对 llm 的 invoke 是调用 AI 服务，发送消息到 AI 模型，接收回复并返回结果。而提示词模版对象的调用是文本处理，不涉及 AI 调用。</p><p>当然，invoke() 也支持一些其它对象的调用，比如 tools，chains，而这就是 langchain 的统一对象接口调用理念的体现。</p><p>使用提示词模版的时候，我们可以直接利用 langchain 里的 chain 来进行模版填充和模型回复。</p><p>这里直接构造 chain &#x3D; prompt | llm1，所起到的作用就是对 | 的两端同时调用 invoke() 方法。得益于 invoke() 对不同对象的适用性，这就使得 langchain 可以将多个模型、工具、提示词串联，来构造 agent 工作流。</p><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 构建prompt template</span><span class="token keyword">from</span> langchain_core<span class="token punctuation">.</span>prompts <span class="token keyword">import</span> ChatPromptTemplate  prompt <span class="token operator">=</span> ChatPromptTemplate<span class="token punctuation">(</span>    <span class="token punctuation">[</span>        <span class="token punctuation">(</span><span class="token string">"system"</span><span class="token punctuation">,</span> <span class="token string">"你是一个笑话大王，请给我讲个笑话"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>        <span class="token punctuation">(</span><span class="token string">"user"</span><span class="token punctuation">,</span> <span class="token string">"帮我写一个主题为&amp;#123;topic&amp;#125;的笑话"</span><span class="token punctuation">)</span>    <span class="token punctuation">]</span><span class="token punctuation">)</span>  prompt<span class="token punctuation">.</span>invoke<span class="token punctuation">(</span><span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;"topic": "狗"&amp;#125;).to_messages()</span><span class="token keyword">print</span><span class="token punctuation">(</span>prompt<span class="token punctuation">.</span>input_variables<span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># langchian里chain的体现</span><span class="token comment" spellcheck="true"># | 连接的两侧必须是可以被invoke的，在调用时会自动调用两侧的invoke方法</span><span class="token comment" spellcheck="true"># 左边的输出会作为右边的输入</span>chain <span class="token operator">=</span> prompt <span class="token operator">|</span> llm1  ans <span class="token operator">=</span> chain<span class="token punctuation">.</span>invoke<span class="token punctuation">(</span>    <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;"topic": "狗"&amp;#125;</span><span class="token punctuation">)</span>  <span class="token keyword">print</span><span class="token punctuation">(</span>ans<span class="token punctuation">.</span>content<span class="token punctuation">)</span></code></pre><p><img src="https://cyan-1314223569.cos.ap-beijing.myqcloud.com/test/Pasted%20image%2020251012230813.png"></p><p>生成的笑话，虽然有点冷，，</p><p><strong>补充</strong>：事实上一般在我们去做一些文本生成、数据生成等任务的时候，我们可能更希望有一个 json 格式的输出结果。如何让模型的输出结果自动返回 json 格式呢？</p><ol><li>首先，我们可以借助 Pydantic 库，定义一个匹配我们需求的输出 json 格式的数据结构。Pydantic 的 BaseModel 类用于进行数据验证、类型转换等操作，确保返回格式符合需求的 json 格式要求；</li><li>接下来，我们利用模型 API 的 with_structured_output() 输出方法，将 Pydantic 模型转换为 JSON Schema 并使用 Function Calling 机制，在提示词中嵌入结构要求，令模型的输出结果符合所需的 json 格式。</li></ol><pre class=" language-python"><code class="language-python"><span class="token keyword">from</span> pydantic <span class="token keyword">import</span> BaseModel<span class="token punctuation">,</span> Field  <span class="token keyword">class</span> <span class="token class-name">Joke</span><span class="token punctuation">(</span>BaseModel<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token string">"joke to tell user"</span>    setup<span class="token punctuation">:</span> str <span class="token operator">=</span> Field<span class="token punctuation">(</span>description<span class="token operator">=</span><span class="token string">"The setup of the joke"</span><span class="token punctuation">)</span>    punchline<span class="token punctuation">:</span> str <span class="token operator">=</span> Field<span class="token punctuation">(</span>description<span class="token operator">=</span><span class="token string">"The punchline of the joke"</span><span class="token punctuation">)</span>  joke_chain <span class="token operator">=</span> prompt <span class="token operator">|</span> ChatDeepSeek<span class="token punctuation">(</span>    model<span class="token operator">=</span>deepseek_chat_model<span class="token punctuation">,</span>    api_key<span class="token operator">=</span>API_KEY<span class="token punctuation">,</span>    base_url<span class="token operator">=</span>BASE_URL<span class="token punctuation">)</span><span class="token punctuation">.</span>with_structured_output<span class="token punctuation">(</span>Joke<span class="token punctuation">)</span>  ans <span class="token operator">=</span> joke_chain<span class="token punctuation">.</span>invoke<span class="token punctuation">(</span><span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;"topic": "狗"&amp;#125;)</span><span class="token keyword">print</span><span class="token punctuation">(</span>ans<span class="token punctuation">.</span>setup<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>ans<span class="token punctuation">.</span>punchline<span class="token punctuation">)</span></code></pre><p><strong>注意，这里的方法仅适用于支持 Function Calling 的模型</strong>！</p><p>因为实际上我们采用 with_structured_output(class) 来让模型输出 json 格式时，其实是虚拟了一个自定义的 function，这个 function 规定了一个 json 转换的模式，在调用 API 的时候会打开 function calling 采用这个虚拟 function，来实现 json 格式的转换，并通过 pydantic 库验证输出。</p><p>function calling 就是自定义函数支持。简单来说，用户可以预先定义好函数（比如天气获取函数），模型可以选择调用函数，执行函数并返回结果，最终模型基于函数结果生成回答。</p><p>函数信息可以通过每次调用 API 时传递，模型在收到这样的消息，判断要调用一些函数，便不生成实际回复，而是生成一个函数调用并结束该次响应。应用程序执行函数 → 再次调用模型 → 模型基于结果生成最终回答。</p><p>当然也有模型直接支持启用 json 模式，这时候生成结果就是 json 格式的：</p><pre class=" language-python"><code class="language-python">llm_with_json <span class="token operator">=</span> ChatOpenAI<span class="token punctuation">(</span>    model<span class="token operator">=</span><span class="token string">"gpt-4-1106-preview"</span><span class="token punctuation">,</span>  <span class="token comment" spellcheck="true"># 支持 JSON Mode</span>    response_format<span class="token operator">=</span><span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;"type": "json_object"&amp;#125;</span><span class="token punctuation">)</span>result <span class="token operator">=</span> llm_with_json<span class="token punctuation">.</span>invoke<span class="token punctuation">(</span><span class="token punctuation">[</span>HumanMessage<span class="token punctuation">(</span><span class="token string">"生成笑话"</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><h4 id="Langgraph-Memory"><a href="#Langgraph-Memory" class="headerlink" title="Langgraph Memory"></a>Langgraph Memory</h4><p>langgraph 基于图结构来编排 Agent 工作流，其关键点就在于图结构的 message memory 储存机制。LangGraph的核心理念是将应用逻辑表示为一个图（Graph），其中：</p><ul><li>节点（Nodes）：代表工作流中的独立组件或智能体，可以视为以特定方式相互交互的”参与者”。每个节点可以执行特定的功能，如生成文本、分析数据或调用外部工具。</li><li>边（Edges）：是Python中的函数，基于当前状态决定下一个要执行的节点，实现了工作流中的条件逻辑和控制流。</li><li>状态（State）：作为一种”记忆库”，记录和跟踪AI系统处理的所有有价值的信息，确保系统能够维持上下文并做出连贯的响应。</li></ul><p>图驱动的架构使 langgraph 在需要上下文连贯性的应用中表现比较出色。</p><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># memory: message &amp; output, 通过维护图结构来保存</span>  <span class="token comment" spellcheck="true"># class MessagesState(TypedDict):</span><span class="token comment" spellcheck="true">#     messages: Annotated[list[AnyMessage], add_messages]</span><span class="token comment" spellcheck="true">#     &amp;#123;</span><span class="token comment" spellcheck="true">#         "messages": []</span><span class="token comment" spellcheck="true">#     &amp;#125;</span></code></pre><p>通过维护消息状态，langgraph 会通过合并消息、新增消息节点等来进行状态管理。</p><p>这其实就是一个图结构的 Agent Memory，实现的是一个短期记忆。对话消息上下文会通过图结构的维护来传递给 Agent。</p><pre class=" language-python"><code class="language-python"><span class="token keyword">from</span> langgraph<span class="token punctuation">.</span>checkpoint<span class="token punctuation">.</span>memory <span class="token keyword">import</span> MemorySaver<span class="token keyword">from</span> langgraph<span class="token punctuation">.</span>graph <span class="token keyword">import</span> MessagesState<span class="token punctuation">,</span> START<span class="token punctuation">,</span> StateGraph<span class="token punctuation">,</span> END  workflow <span class="token operator">=</span> StateGraph<span class="token punctuation">(</span>MessagesState<span class="token punctuation">)</span>  <span class="token keyword">def</span> <span class="token function">call_model</span><span class="token punctuation">(</span>state<span class="token punctuation">:</span> MessagesState<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">return</span> <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;"messages": [llm1.invoke(state["messages"])]&amp;#125;</span>  workflow<span class="token punctuation">.</span>add_node<span class="token punctuation">(</span><span class="token string">"node1"</span><span class="token punctuation">,</span> call_model<span class="token punctuation">)</span>workflow<span class="token punctuation">.</span>add_edge<span class="token punctuation">(</span>START<span class="token punctuation">,</span> <span class="token string">"node1"</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># Add Memory</span>memory <span class="token operator">=</span> MemorySaver<span class="token punctuation">(</span><span class="token punctuation">)</span>graph <span class="token operator">=</span> workflow<span class="token punctuation">.</span>compile<span class="token punctuation">(</span>checkpointer<span class="token operator">=</span>memory<span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># config标识线程id，是通过线程id来存储历史消息的</span>config <span class="token operator">=</span> <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;"configurable": &amp;#123;"thread_id": "1"&amp;#125;&amp;#125;</span>query <span class="token operator">=</span> <span class="token string">"你好啊，我是Cyan。"</span>  input_messages <span class="token operator">=</span> <span class="token punctuation">[</span>HumanMessage<span class="token punctuation">(</span>content<span class="token operator">=</span>query<span class="token punctuation">)</span><span class="token punctuation">]</span>output_messages <span class="token operator">=</span> graph<span class="token punctuation">.</span>invoke<span class="token punctuation">(</span>input_messages<span class="token punctuation">,</span> config<span class="token operator">=</span>config<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>output_messages<span class="token punctuation">[</span><span class="token string">"messages"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>content<span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 这里的output包含所有历史消息，langgraph做了一个消息拼接，[-1] 获取最后一条消息（最新的AI回复）</span>  query <span class="token operator">=</span> <span class="token string">"我叫什么名字？"</span>input_messages <span class="token operator">=</span> <span class="token punctuation">[</span>HumanMessage<span class="token punctuation">(</span>content<span class="token operator">=</span>query<span class="token punctuation">)</span><span class="token punctuation">]</span>output_messages <span class="token operator">=</span> graph<span class="token punctuation">.</span>invoke<span class="token punctuation">(</span>input_messages<span class="token punctuation">,</span> config<span class="token operator">=</span>config<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>output_messages<span class="token punctuation">[</span><span class="token string">"messages"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>content<span class="token punctuation">)</span></code></pre><h4 id="Single-Agent-with-tools"><a href="#Single-Agent-with-tools" class="headerlink" title="Single Agent (with tools)"></a>Single Agent (with tools)</h4><p>使用 function calling 来 create 一个 ReAct 的单 agent 系统，agent 能够在推理过程中去调用已有声明的自定义函数帮助完成推理过程：</p><pre class=" language-python"><code class="language-python"><span class="token keyword">from</span> langgraph<span class="token punctuation">.</span>prebuilt <span class="token keyword">import</span> create_react_agent  <span class="token keyword">def</span> <span class="token function">add</span><span class="token punctuation">(</span>a<span class="token punctuation">:</span>int<span class="token punctuation">,</span> b<span class="token punctuation">:</span>int<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">return</span> a <span class="token operator">+</span> b  <span class="token keyword">def</span> <span class="token function">multiply</span><span class="token punctuation">(</span>a<span class="token punctuation">:</span>int<span class="token punctuation">,</span> b<span class="token punctuation">:</span>int<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">return</span> a <span class="token operator">*</span> b  agent <span class="token operator">=</span> create_react_agent<span class="token punctuation">(</span>    model<span class="token operator">=</span>llm1<span class="token punctuation">,</span>    tools<span class="token operator">=</span><span class="token punctuation">[</span>add<span class="token punctuation">,</span> multiply<span class="token punctuation">]</span><span class="token punctuation">,</span>    config<span class="token operator">=</span><span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;"configurable": &amp;#123;"thread_id": "1"&amp;#125;&amp;#125;</span><span class="token punctuation">)</span>  input_messages <span class="token operator">=</span> <span class="token punctuation">[</span>HumanMessage<span class="token punctuation">(</span>content<span class="token operator">=</span><span class="token string">"计算10+20，然后计算10*20"</span><span class="token punctuation">)</span><span class="token punctuation">]</span>output_messages <span class="token operator">=</span> agent<span class="token punctuation">.</span>invoke<span class="token punctuation">(</span>input_messages<span class="token punctuation">)</span>  <span class="token keyword">for</span> message <span class="token keyword">in</span> output_messages<span class="token punctuation">[</span><span class="token string">"messages"</span><span class="token punctuation">]</span><span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>message<span class="token punctuation">.</span>content<span class="token punctuation">)</span></code></pre>]]></content>
      
      
      
        <tags>
            
            <tag> 学习笔记 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>A-Mem：Agentic Memory for LLM Agents：记忆动态更新的 Agent 记忆系统</title>
      <link href="/2025/10/10/lun-wen-a-mem-agentic-memory-for-llm-agents/"/>
      <url>/2025/10/10/lun-wen-a-mem-agentic-memory-for-llm-agents/</url>
      
        <content type="html"><![CDATA[<h1 id="A-Mem：Agentic-Memory-for-LLM-Agents"><a href="#A-Mem：Agentic-Memory-for-LLM-Agents" class="headerlink" title="A-Mem：Agentic Memory for LLM Agents"></a>A-Mem：Agentic Memory for LLM Agents</h1><p>原文链接：<a href="http://example.com/" title="Title">https://arxiv.org/abs/2502.12110</a></p><p>论文主要提出了一种名为 A-MEM 的适用于 Agent 的主动式记忆系统，来尝试解决现有 LLM 代理记忆系统<strong>结构僵化、适应性不足</strong>的问题。</p><h3 id="Background-Motivation"><a href="#Background-Motivation" class="headerlink" title="Background &amp; Motivation"></a>Background &amp; Motivation</h3><p>我们知道，Agent 的记忆一般分为短期记忆和长期记忆，短期记忆可通过维护上下文窗口提供，而<strong>长期记忆往往需要维护一个记忆存储库</strong>，在每次交互时对存储库里的记忆进行写入与调用。</p><p><img src="https://cyan-1314223569.cos.ap-beijing.myqcloud.com/test/Pasted%20image%2020251011220615.png"></p><p>传统记忆系统一般会<strong>预定义存储结构、存储点、记忆关联。</strong> 例如，记忆存储格式固定为数据库 Table 结构或 Json 模版；硬性规定在特定对话轮次或步骤写入记忆；记忆之间彼此孤立或硬性定义其关联。这种记忆系统交互是线性且固定的，缺乏自主性，体现出如下缺陷：</p><ul><li><strong>灵活性差：</strong> 在更复杂开放的一些场景下，预定义的知识模式可能不能很好地匹配现有需求。</li><li><strong>长期交互效果不佳：</strong> 记忆孤立且静态，新记忆难以与旧记忆产生联系，也无法更新记忆，模型难以在长期对话中维持深入推理。</li><li><strong>知识组织僵化：</strong> 如论文所述，当代理学习到一个新数学解法时，无法主动创建新的组织模式，或发现新联系。</li></ul><p>因此，A-Mem 针对上述问题改进，灵感基于 Zettelkasten 方法（使用原子笔记和灵活的链接机制，可以创建相互连接的信息网络），设计了一个具备自主性（<strong>能够自主建立记忆联系并更新记忆</strong>）的记忆系统。</p><p>Zettelkasten 方法是一种知识管理系统，由德国社会学家 Niklas Luhmann 提出。它通过创建相互连接的笔记网络来组织知识，每张笔记（Zettel）包含一个独立的想法，并通过链接与其他相关的笔记连接起来。</p><h3 id="Related-Works-Comparison"><a href="#Related-Works-Comparison" class="headerlink" title="Related Works Comparison"></a>Related Works Comparison</h3><table><thead><tr><th><strong>Method</strong></th><th><strong>Core Mechanism</strong></th><th><strong>Limit</strong></th></tr></thead><tbody><tr><td>MemGPT</td><td>类 OS 系统的内存分层</td><td>固定大小的上下文窗口</td></tr><tr><td>MemoryBank</td><td>基于遗忘曲线进行动态更新</td><td>缺乏跨记忆的语义关联</td></tr><tr><td>Agentic RAG</td><td>系统自主检索增强</td><td>知识库静态，不可更新</td></tr><tr><td>A-MEM</td><td>动态链接 + 自主进化</td><td>上下文表征可能不够丰富</td></tr></tbody></table><h3 id="Method"><a href="#Method" class="headerlink" title="Method"></a>Method</h3><p>A-Mem的核心是一个动态、自演进的内存网络。每当代理有一次新交互，系统会执行三步操作：</p><ol><li><strong>笔记构建</strong>：将原始交互转化为结构化的记忆笔记；</li><li><strong>链接生成</strong>：自动寻找与已有记忆的关联并建立链接；</li><li><strong>记忆进化</strong>：根据新记忆更新相关旧记忆的上下文或标签。</li></ol><p><img src="https://cyan-1314223569.cos.ap-beijing.myqcloud.com/test/Pasted%20image%2020251011220549.png" alt="A-Mem 系统流程图"></p><h4 id="原子笔记构建"><a href="#原子笔记构建" class="headerlink" title="原子笔记构建"></a>原子笔记构建</h4><p>对于每一个记忆单元可以表示为：$m_{i}&#x3D;{c_{i}, t_{i}, K_{i}, G_{i}, X_{i}, e_{i}, L_{i}}$</p><ul><li>$m_{i}$ ：第 i 个记忆笔记。</li><li>$c_{i}$ ：原始交互内容（content），例如对话文本、观察到的事件等。</li><li>$t_{i}$ ：时间戳（timestamp），记录记忆发生的时间。</li><li>$K_{i}$ ：LLM 生成的关键词（keywords），用于捕捉记忆的关键概念。</li><li>$G_{i}$ ：LLM 生成的标签（tags），用于对记忆进行分类。</li><li>$X_{i}$ ：LLM 生成的上下文描述（contextual description），提供丰富的语义理解。包含隐含语义，如「该解法与拓扑学存在潜在联系」。</li><li>$e_{i}$ : 嵌入向量（embedding），用于相似度计算和检索。</li><li>$L_{i}$ ：链接记忆集合（linked memories），包含与当前记忆相关的其他记忆。</li></ul><p>这种做法有什么好处呢？</p><p>传统方法的记忆结构（如数据库表或JSON字段）是固定的，并且内容通常直接来自原始交互数据（例如，直接存储用户消息和模型响应），缺乏语义增强。存储什么、如何存储完全由预定义规则决定。</p><p>而 A-Mem 的每个记忆笔记中的关键词（Ki）、标签（Gi​）和上下文描述（Xi）都是由LLM在每次交互后动态生成的。这意味着即使结构模板固定，但其内容是根据当前交互的语义灵活生成的，从而适应不同任务和语境。</p><h4 id="链接生成"><a href="#链接生成" class="headerlink" title="链接生成"></a>链接生成</h4><p>首先通过余弦相似度初步筛选 Top-K 候选记忆单元：$[ s_{n,j} &#x3D; \frac{e_n \cdot e_j}{|e_n||e_j|} ]$</p><p>接下来，借助 LLM 来分析候选记忆的深层关系，并建立连接：</p><p>$L_{i} ← LLM(m_{n}||M_{near}^{n}||P_{s2})$</p><p>这里 $P_{s2}$ 是预定义的提示词模版，通过 LLM 来生成链接关联。</p><h4 id="记忆更新"><a href="#记忆更新" class="headerlink" title="记忆更新"></a>记忆更新</h4><p>新记忆 $m_{n}$ 的进入会触发历史记忆的更新，更新公式为：</p><p>$m_{j}^{*} ← LLM(m_{n} || M_{near}^{n} \ m_{j} || m_{j} || P_{s3})$</p><p>例如，当学习「量子退火」后，系统自动将历史记忆「模拟退火算法」的标签更新为「优化算法→量子计算」。</p><h3 id="Experiment-Results"><a href="#Experiment-Results" class="headerlink" title="Experiment &amp; Results"></a>Experiment &amp; Results</h3><ul><li><strong>数据集</strong>：<a href="https://zhida.zhihu.com/search?content_id=255609194&content_type=Article&match_order=1&q=LoCoMo+%E6%95%B0%E6%8D%AE%E9%9B%86&zhida_source=entity">LoCoMo 数据集</a>，包含长时间的对话，适合评估模型处理长程依赖关系和保持一致性的能力。</li><li><strong>评估指标</strong>：F1 score、BLEU-1、ROUGE-L、ROUGE-2、METEOR、SBERT Similarity。</li><li><strong>基线模型</strong>：LoCoMo、ReadAgent、MemoryBank、MemGPT。</li></ul><p><strong>实验结果</strong>：</p><p>在非 GPT 基础模型上，A-MEM 始终优于所有基线模型。<br>在 GPT-4-mini 上，A-MEM 的 F1 得分达到 45.85%，远超 MemGPT 的 25.52%</p><p><img src="https://cyan-1314223569.cos.ap-beijing.myqcloud.com/test/Pasted%20image%2020251011223508.png"></p><p><strong>效率优势</strong>： A-MEM 在实现这些改进的同时，与 LoCoMo 和 MemGPT 相比，token 长度要求显著降低（约 1,200-2,500 个 token，而 LoCoMo 和 MemGPT 为 16,900 个 token）。</p><p><img src="https://cyan-1314223569.cos.ap-beijing.myqcloud.com/test/Pasted%20image%2020251011223546.png"></p><p><strong>可视化证据</strong>： t-SNE 可视化表明，与基线系统相比，A-MEM 具有更连贯的聚类模式，验证了其记忆组织方法的有效性。</p><p><img src="https://cyan-1314223569.cos.ap-beijing.myqcloud.com/test/Pasted%20image%2020251011223600.png"></p><p><strong>消融实验</strong>：链接生成（LG）和记忆演化（ME）模块对 A-MEM 的性能至关重要。</p><p><strong>超参数分析</strong>：适中的 k 值（检索记忆的数量）在上下文丰富性和信息处理效率之间取得了最佳平衡。k 值持续增大，也会伴随效果下降。</p><p><img src="https://cyan-1314223569.cos.ap-beijing.myqcloud.com/test/Pasted%20image%2020251011223617.png"></p><h3 id="My-Thoughts"><a href="#My-Thoughts" class="headerlink" title="My Thoughts"></a>My Thoughts</h3><p>A-Mem 的方法本身并不难理解，但其方法很有效。通过 A-Mem 得到的惊艳效果，可以看到仅仅基于传统 RAG 的方法引入外部数据库来存储记忆是远远不够的。可以从中提炼出关于 Agent 长期记忆的几个要点：</p><ol><li>记忆之间需要建立相互连接的关系（并非人为固定定义）；</li><li>模型记忆需要伴随着演化更新，并非一成不变，类似模型知识编辑；</li><li>A-Mem 取得的效果大概率依赖于 LLM 生成的对记忆的上下文描述；</li></ol><p>论文中提到的 Future Works 包括引入多模态信息、解决不同大模型上下文生成区别等，不过感觉都不是一些关键点。</p><p>读完之后有几个初步的思考点，大概是这些：</p><p>首先，A-Mem 并未引入遗忘机制，记忆库会无限膨胀。当记忆库很庞大时，通过向量相似度初筛可能就会引入记忆污染等等问题。能否在其大体机制上稍加修改，引入记忆遗忘与压缩机制，在更大规模的对话数据集上实验验证效果？</p><p>个人想法是，人类对于记忆的“遗忘”与“调用”过程更像是对记忆的一个置信度评估，像 MemGPT 那样基于 OS 的记忆管理思路那样，能否对记忆施加一个“置信度”参数，随模型链接记忆的时间次数而衰减，或设定一个置信度的传播与更新机制，在链接时优先考虑高置信度的相关记忆，并优先忘却低置信度的相关记忆？</p><p>另外，A-Mem 给出的几个启发能否也在参数化记忆上做一些尝试呢？现有的参数化记忆更新方法大多通过模型微调、增加模型 memory block 等实现。记忆之间建立相互连接的关系通常也通过知识图谱等方式添加到模型网络中去。</p><p>一般当前的方法都是仅单独专注于非参数化记忆优化、参数化记忆优化本身，很少有把两者结合起来做的工作。之前也读过几篇模型知识编辑相关的论文，能否把长期记忆更新和模型编辑相结合，在模型参数化记忆上也去做一个更新改动呢？</p>]]></content>
      
      
      
        <tags>
            
            <tag> 论文笔记 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>在DeepSeek-R1-1.5b模型上做一个简单的lora微调</title>
      <link href="/2025/02/18/xue-xi-zai-deepseek-r1-3b-shang-zuo-jian-dan-lora-wei-diao/"/>
      <url>/2025/02/18/xue-xi-zai-deepseek-r1-3b-shang-zuo-jian-dan-lora-wei-diao/</url>
      
        <content type="html"><![CDATA[<h1 id="LoRA-PEFT-for-DeepSeek-R1-Distill-Qwen-1-5B模型"><a href="#LoRA-PEFT-for-DeepSeek-R1-Distill-Qwen-1-5B模型" class="headerlink" title="LoRA PEFT for DeepSeek-R1-Distill-Qwen-1.5B模型"></a>LoRA PEFT for DeepSeek-R1-Distill-Qwen-1.5B模型</h1><blockquote><p>参考视频： <a href="https://www.bilibili.com/video/BV1pfKNe8E7F/?share_source=copy_web&vd_source=2ff04f0cc70237133af9bcd6be27a652">https://www.bilibili.com/video/BV1pfKNe8E7F/?share_source=copy_web&amp;vd_source=2ff04f0cc70237133af9bcd6be27a652</a></p></blockquote><hr><h3 id="模型准备"><a href="#模型准备" class="headerlink" title="模型准备"></a>模型准备</h3><p>首先到 hugging face 或者魔搭上下载相对应的模型文件。国内服务器用在 hugging face 上下载模型实在慢，我一般习惯用 git lfs 下载，所以就直接上魔搭了。模型文件可以在这里找到：</p><p>（说起来之前还用过 hugging face 的国内镜像网站，但那个很多时候也不稳定，所以一般现在都是直接先从魔搭上提前下好模型到本地，然后路径访问了,,,）</p><img src="https://cyan-1314223569.cos.ap-beijing.myqcloud.com/test/1739957817449.jpg?imageSlim"/><h3 id="准备数据"><a href="#准备数据" class="headerlink" title="准备数据"></a>准备数据</h3><p>我这里是先拿了一个简单的数据集示例练手，具体可以参考夸克网盘：<a href="https://pan.quark.cn/s/a220f415b35c">https://pan.quark.cn/s/a220f415b35c</a></p><p>一般训练、微调都是用 json 格式，因此要先进行转换：</p><pre class=" language-python"><code class="language-python"><span class="token keyword">with</span> open<span class="token punctuation">(</span><span class="token string">"./dataset/dataset.jsonl"</span><span class="token punctuation">,</span> <span class="token string">"w"</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">"utf-8"</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>    <span class="token keyword">for</span> s <span class="token keyword">in</span> samples<span class="token punctuation">:</span>        json_line <span class="token operator">=</span> json<span class="token punctuation">.</span>dumps<span class="token punctuation">(</span>s<span class="token punctuation">,</span> ensure_ascii<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>        f<span class="token punctuation">.</span>write<span class="token punctuation">(</span>json_line <span class="token operator">+</span> <span class="token string">"\n"</span><span class="token punctuation">)</span>    <span class="token keyword">else</span><span class="token punctuation">:</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"data prepare done"</span><span class="token punctuation">)</span>dataset <span class="token operator">=</span> load_dataset<span class="token punctuation">(</span><span class="token string">"json"</span><span class="token punctuation">,</span> data_files<span class="token operator">=</span><span class="token string">"./dataset/dataset.jsonl"</span><span class="token punctuation">,</span> split<span class="token operator">=</span><span class="token string">"train"</span><span class="token punctuation">)</span>train_test_split <span class="token operator">=</span> dataset<span class="token punctuation">.</span>train_test_split<span class="token punctuation">(</span>test_size<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">)</span>train_dataset <span class="token operator">=</span> train_test_split<span class="token punctuation">[</span><span class="token string">"train"</span><span class="token punctuation">]</span>test_dataset <span class="token operator">=</span> train_test_split<span class="token punctuation">[</span><span class="token string">"test"</span><span class="token punctuation">]</span></code></pre><p>这里把脚本里的数据集按 prompt + completion 格式将每个元素转换为 JSON 字符串并写入文件，每行都是一个独立的 JSON 对象。例如：</p><p>{“prompt”: “Question 1: What is the first step to improving your singing voice?”, “completion”: “Answer 1: Begin by warming up your vocal cords with gentle exercises like humming or lip trills.”}</p><p>一般从 hugging face 上下载下来的数据集有不少也是 json 格式，比如之前用到的 ARC 数据集。但大部分都是直接打包成 arrow 格式，这时候直接用 datasets 库的 load_dataset() 方法加载数据集并分词就可以了。train_test_split() 方法可以按比例将数据分割成训练集和测试集。</p><h3 id="分词处理"><a href="#分词处理" class="headerlink" title="分词处理"></a>分词处理</h3><p>要让数据能够被模型识别，需要使用分词器将数据字符转换为真正的数字形式。一般模型都会带有 tokenizer，可以先加载：</p><pre class=" language-python"><code class="language-python">model_name <span class="token operator">=</span> <span class="token string">"/d2/mxy/Models/DeepSeek-R1-Distill-Qwen-1.5B"</span>tokenizer <span class="token operator">=</span> AutoTokenizer<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>model_name<span class="token punctuation">)</span><span class="token comment" spellcheck="true"># model = AutoModelForCausalLM.from_pretrained(model_name)</span><span class="token keyword">def</span> <span class="token function">tokenize_function</span><span class="token punctuation">(</span>examples<span class="token punctuation">)</span><span class="token punctuation">:</span>    texts <span class="token operator">=</span> <span class="token punctuation">[</span>f<span class="token string">"&amp;#123;prompt&amp;#125;\n&amp;#123;completion&amp;#125;"</span> <span class="token keyword">for</span> prompt<span class="token punctuation">,</span> completion <span class="token keyword">in</span> zip<span class="token punctuation">(</span>examples<span class="token punctuation">[</span><span class="token string">"prompt"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> examples<span class="token punctuation">[</span><span class="token string">"completion"</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">]</span>    tokens <span class="token operator">=</span> tokenizer<span class="token punctuation">(</span>texts<span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> truncation<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> max_length<span class="token operator">=</span><span class="token number">512</span><span class="token punctuation">)</span>    tokens<span class="token punctuation">[</span><span class="token string">"labels"</span><span class="token punctuation">]</span> <span class="token operator">=</span> tokens<span class="token punctuation">[</span><span class="token string">"input_ids"</span><span class="token punctuation">]</span><span class="token punctuation">.</span>copy<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">return</span> tokenstokenized_train_dataset <span class="token operator">=</span> train_dataset<span class="token punctuation">.</span>map<span class="token punctuation">(</span>tokenize_function<span class="token punctuation">,</span> batched<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>tokenized_test_dataset <span class="token operator">=</span> test_dataset<span class="token punctuation">.</span>map<span class="token punctuation">(</span>tokenize_function<span class="token punctuation">,</span> batched<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span></code></pre><p>需要定义分词处理函数并应用到加载后的数据集上。tokenize_function() 对每一条数据进行分词。</p><p><strong>不同的任务可能需要不同的分词处理。</strong>在这里我们的训练目标是一个生成任务，也就是模型根据当前 token 预测下一个 token，因此我们的 token[‘labels’] 定义为 token[‘input_ids’] 本身。假如是分类或问答任务，那么我们的 token[‘labels’] 就应当被定义为分类或回答的答案。</p><p>需要注意的是，tokenizer 原生支持的几个字段有以下五个：<strong>input_ids、attention_mask、label、type_ids、label_ids</strong>，这几个字段能够在 Trainer 里直接参与模型的训练，input_ids 即为输入，label 即为训练模型的输出。假如想要自定义其它字段的话，需要重写 Trainer 方法，使 Trainer 适配新的分词字段。</p><h3 id="加载训练配置并开始训练"><a href="#加载训练配置并开始训练" class="headerlink" title="加载训练配置并开始训练"></a>加载训练配置并开始训练</h3><p>transformers、peft 库自带了很多配置方法，直接调用即可。这里采用 8bits 量化，然后加载了一个 lora 模块用于微调模型。</p><pre class=" language-python"><code class="language-python">bnb_config <span class="token operator">=</span> BitsAndBytesConfig<span class="token punctuation">(</span>load_in_8bit<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>model <span class="token operator">=</span> AutoModelForCausalLM<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>    model_name<span class="token punctuation">,</span>    quantization_config<span class="token operator">=</span>bnb_config<span class="token punctuation">,</span>    device_map<span class="token operator">=</span><span class="token string">"auto"</span><span class="token punctuation">,</span><span class="token punctuation">)</span>lora_config <span class="token operator">=</span> LoraConfig<span class="token punctuation">(</span>    r<span class="token operator">=</span><span class="token number">8</span><span class="token punctuation">,</span>    lora_alpha<span class="token operator">=</span><span class="token number">16</span><span class="token punctuation">,</span>    lora_dropout<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">,</span>    task_type<span class="token operator">=</span>TaskType<span class="token punctuation">.</span>CAUSAL_LM<span class="token punctuation">,</span><span class="token punctuation">)</span>model <span class="token operator">=</span> get_peft_model<span class="token punctuation">(</span>model<span class="token punctuation">,</span> lora_config<span class="token punctuation">)</span>model<span class="token punctuation">.</span>print_trainable_parameters<span class="token punctuation">(</span><span class="token punctuation">)</span>training_args <span class="token operator">=</span> TrainingArguments<span class="token punctuation">(</span>    output_dir<span class="token operator">=</span><span class="token string">"./results"</span><span class="token punctuation">,</span>    eval_strategy<span class="token operator">=</span><span class="token string">"steps"</span><span class="token punctuation">,</span>    eval_steps<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span>    learning_rate<span class="token operator">=</span><span class="token number">2e</span><span class="token operator">-</span><span class="token number">4</span><span class="token punctuation">,</span>    per_device_train_batch_size<span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">,</span>    gradient_accumulation_steps<span class="token operator">=</span><span class="token number">8</span><span class="token punctuation">,</span>    fp16<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>    logging_dir<span class="token operator">=</span><span class="token string">"./logs"</span><span class="token punctuation">,</span>    logging_steps<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span>    per_device_eval_batch_size<span class="token operator">=</span><span class="token number">16</span><span class="token punctuation">,</span>    num_train_epochs<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span>    weight_decay<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">,</span>    save_strategy<span class="token operator">=</span><span class="token string">"steps"</span><span class="token punctuation">,</span>    save_steps<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">,</span>    save_total_limit<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span>    run_name<span class="token operator">=</span><span class="token string">"deepseek-r1-distill-qwen-1.5b-lora"</span><span class="token punctuation">,</span><span class="token punctuation">)</span>trainer <span class="token operator">=</span> Trainer<span class="token punctuation">(</span>    model<span class="token operator">=</span>model<span class="token punctuation">,</span>    args<span class="token operator">=</span>training_args<span class="token punctuation">,</span>    train_dataset<span class="token operator">=</span>tokenized_train_dataset<span class="token punctuation">,</span>    eval_dataset<span class="token operator">=</span>tokenized_test_dataset<span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Training..."</span><span class="token punctuation">)</span>trainer<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Saving model..."</span><span class="token punctuation">)</span>save_path <span class="token operator">=</span> <span class="token string">"./saved_models"</span>model<span class="token punctuation">.</span>save_pretrained<span class="token punctuation">(</span>save_path<span class="token punctuation">)</span>tokenizer<span class="token punctuation">.</span>save_pretrained<span class="token punctuation">(</span>save_path<span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 合并LoRA权重到基础模型</span><span class="token keyword">from</span> peft <span class="token keyword">import</span> PeftModelfinal_save_path <span class="token operator">=</span> <span class="token string">"./final_saved_models"</span>base_model <span class="token operator">=</span> AutoModelForCausalLM<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>model_name<span class="token punctuation">)</span>model <span class="token operator">=</span> PeftModel<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>base_model<span class="token punctuation">,</span> save_path<span class="token punctuation">)</span>model <span class="token operator">=</span> model<span class="token punctuation">.</span>merge_and_unload<span class="token punctuation">(</span><span class="token punctuation">)</span>model<span class="token punctuation">.</span>save_pretrained<span class="token punctuation">(</span>final_save_path<span class="token punctuation">)</span>tokenizer<span class="token punctuation">.</span>save_pretrained<span class="token punctuation">(</span>final_save_path<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Done!"</span><span class="token punctuation">)</span></code></pre><h3 id="模型推理"><a href="#模型推理" class="headerlink" title="模型推理"></a>模型推理</h3><p>保存好 lora 权重的模型之后，就可以直接加载模型并用 transformers 自带的推理管线进行推理了。</p><pre class=" language-python"><code class="language-python">model_name <span class="token operator">=</span> <span class="token string">"./final_saved_models"</span>tokenizer <span class="token operator">=</span> AutoTokenizer<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>model_name<span class="token punctuation">)</span>model <span class="token operator">=</span> AutoModelForCausalLM<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>model_name<span class="token punctuation">)</span><span class="token keyword">from</span> transformers <span class="token keyword">import</span> pipelinetext_generator <span class="token operator">=</span> pipeline<span class="token punctuation">(</span><span class="token string">"text-generation"</span><span class="token punctuation">,</span> model<span class="token operator">=</span>model<span class="token punctuation">,</span> tokenizer<span class="token operator">=</span>tokenizer<span class="token punctuation">,</span> num_return_sequences<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>prompt <span class="token operator">=</span> <span class="token string">"hello! tell me who are you?"</span>outputs <span class="token operator">=</span> text_generator<span class="token punctuation">(</span>prompt<span class="token punctuation">,</span> max_new_tokens<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"输出结构："</span><span class="token punctuation">,</span> outputs<span class="token punctuation">)</span>generated_text <span class="token operator">=</span> outputs<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"generated_text"</span><span class="token punctuation">]</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"生成的文本："</span><span class="token punctuation">,</span> generated_text<span class="token punctuation">)</span></code></pre><p>生成的结果如下：</p><pre><code>(GraphMoE) (/d1/.conda/vllm) xiangchao@h800-5-6gpu:/d2/mxy/LLM-PEFT/lora_peft$ python3 inference.py Loading checkpoint shards: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00&lt;00:00, 13.76it/s]Device set to use cuda:0输出结构： [&#123;&#39;generated_text&#39;: &quot;hello! tell me who are you? i want to know more about you and your life.\nAlright, so I just wanted to find out who I am. I mean, I have a pretty decent life, but I don&#39;t really know much about who I am. I&#39;m not really sure where to start. Maybe I should look into my past experiences or what I&#39;ve been through. But I&#39;m not sure if that will help me figure out who I am. I mean, I know a lot about my own achievements, but I&quot;&#125;]生成的文本： hello! tell me who are you? i want to know more about you and your life.Alright, so I just wanted to find out who I am. I mean, I have a pretty decent life, but I don&#39;t really know much about who I am. I&#39;m not really sure where to start. Maybe I should look into my past experiences or what I&#39;ve been through. But I&#39;m not sure if that will help me figure out who I am. I mean, I know a lot about my own achievements, but I</code></pre><p>看起来像是 r1 模型的推理过程，限制了 max_tokens&#x3D;100，所以后面的输出被截断了。总之这样就算是完成啦！</p>]]></content>
      
      
      
        <tags>
            
            <tag> 学习笔记 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>手写一个lora微调算法</title>
      <link href="/2025/01/22/xue-xi-shou-xie-yi-ge-lora-wei-diao-suan-fa/"/>
      <url>/2025/01/22/xue-xi-shou-xie-yi-ge-lora-wei-diao-suan-fa/</url>
      
        <content type="html"><![CDATA[<h1 id="手写一个-LoRA-算法"><a href="#手写一个-LoRA-算法" class="headerlink" title="手写一个 LoRA 算法"></a>手写一个 LoRA 算法</h1><blockquote><p>参考视频： <a href="https://www.bilibili.com/video/BV1ZZ421T7XJ/?share_source=copy_web&vd_source=2ff04f0cc70237133af9bcd6be27a652">https://www.bilibili.com/video/BV1ZZ421T7XJ/?share_source=copy_web&amp;vd_source=2ff04f0cc70237133af9bcd6be27a652</a></p></blockquote><hr><h3 id="初始化LoRA-Linear类"><a href="#初始化LoRA-Linear类" class="headerlink" title="初始化LoRA Linear类"></a>初始化LoRA Linear类</h3><p>首先 LoRA 的原理就是在预训练模型的权重矩阵上添加两个 LoRA_A 和 LoRA_B 矩阵组合输出嘛，由于 LoRA_A 和 LoRA_B 矩阵可以通过秩 $r$ 来调整规模，因此训练起来参数量就比 FT 小了很多。</p><p>所以实际上在训练的时候，我们是通过冻结原模型参数矩阵，来学 LoRA_A 和 LoRA_B 矩阵的参数来实现的。那么就需要将原模型里的 Linear 层给替换成封装了 LoRA 模块的 LoRA Linear 层。</p><p>LoraLinear 类的初始化如下：</p><pre class=" language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">LoraLinear</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">_init_</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> in_features<span class="token punctuation">,</span> out_features<span class="token punctuation">,</span> merge<span class="token punctuation">,</span> rank<span class="token operator">=</span><span class="token number">16</span><span class="token punctuation">,</span> alpha<span class="token operator">=</span><span class="token number">16</span><span class="token punctuation">,</span> dropout<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        super<span class="token punctuation">(</span>LoraLinear<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>_init_<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>in_features <span class="token operator">=</span> in_features        self<span class="token punctuation">.</span>out_features <span class="token operator">=</span> out_features        self<span class="token punctuation">.</span>merge <span class="token operator">=</span> merge        self<span class="token punctuation">.</span>rank <span class="token operator">=</span> rank        self<span class="token punctuation">.</span>alpha <span class="token operator">=</span> alpha        self<span class="token punctuation">.</span>dropout <span class="token operator">=</span> dropout</code></pre><p><code>in_features</code>：输入维度，比如词嵌入维度是768，这里就是768；</p><p><code>out_features</code>：输出维度;</p><p><code>merge</code>：控制是否合并 LoRA 和原始权重;</p><p><code>rank</code>：LoRA 的秩，越小压缩程度越大，控制 LoRA 矩阵参数量的主要因素;</p><p><code>alpha</code>：缩放系数，用于调节 LoRA 矩阵参数的影响程度;</p><p><code>dropout</code>：防止过拟合的 dropout 率;</p><pre class=" language-python"><code class="language-python">        self<span class="token punctuation">.</span>linear <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>in_features<span class="token punctuation">,</span> out_features<span class="token punctuation">)</span>        <span class="token keyword">if</span> rank <span class="token operator">></span> <span class="token number">0</span><span class="token punctuation">:</span>            <span class="token comment" spellcheck="true"># 构建权重参数</span>            self<span class="token punctuation">.</span>lora_b <span class="token operator">=</span> nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>out_features<span class="token punctuation">,</span> rank<span class="token punctuation">)</span><span class="token punctuation">)</span>            self<span class="token punctuation">.</span>lora_a <span class="token operator">=</span> nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>rank<span class="token punctuation">,</span> in_features<span class="token punctuation">)</span><span class="token punctuation">)</span>            self<span class="token punctuation">.</span>scale <span class="token operator">=</span> self<span class="token punctuation">.</span>alpha <span class="token operator">/</span> rank            self<span class="token punctuation">.</span>linear<span class="token punctuation">.</span>weight<span class="token punctuation">.</span>requires_grad <span class="token operator">=</span> <span class="token boolean">False</span>        <span class="token keyword">if</span> dropout <span class="token operator">></span> <span class="token number">0</span><span class="token punctuation">:</span>            self<span class="token punctuation">.</span>dropout <span class="token operator">=</span> nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span>self<span class="token punctuation">.</span>dropout<span class="token punctuation">)</span>        <span class="token keyword">else</span><span class="token punctuation">:</span>            self<span class="token punctuation">.</span>dropout <span class="token operator">=</span> nn<span class="token punctuation">.</span>Identity<span class="token punctuation">(</span><span class="token punctuation">)</span>                self<span class="token punctuation">.</span>initial_weights<span class="token punctuation">(</span><span class="token punctuation">)</span>            <span class="token keyword">def</span> <span class="token function">initial_weights</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        nn<span class="token punctuation">.</span>init<span class="token punctuation">.</span>kaiming_uniform_<span class="token punctuation">(</span>self<span class="token punctuation">.</span>lora_a<span class="token punctuation">,</span> a<span class="token operator">=</span>math<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre><p>创建 LoRA 的 A 和 B 矩阵：A (rank × in_features) 和 B (out_features × rank)；</p><p>计算缩放因子 scale &#x3D; alpha &#x2F; rank；</p><p>使用 Kaiming 初始化来初始化 LoRA 矩阵 A，这里只需要初始化一个权重矩阵，另一个 B 矩阵初始化为零矩阵。这样训练开始时 A @ B &#x3D; zeros，随着训练进行会慢慢调整 B 矩阵的参数值；</p><h3 id="前向过程"><a href="#前向过程" class="headerlink" title="前向过程"></a>前向过程</h3><pre class=" language-python"><code class="language-python">    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">if</span> self<span class="token punctuation">.</span>rank <span class="token operator">></span> <span class="token number">0</span> <span class="token operator">and</span> self<span class="token punctuation">.</span>merge<span class="token punctuation">:</span>            <span class="token comment" spellcheck="true"># 可以看到这边lora_b是out_features * rank的矩阵，lora_a是rank * in_features的矩阵，乘完后是out_features * in_features的矩阵</span>            <span class="token comment" spellcheck="true"># 那么weight就是out_features * in_features的矩阵，刚好和linear.weight的形状一样</span>            <span class="token comment" spellcheck="true"># 而wx+b，因此x就是in_features * batch_size的矩阵</span>            output <span class="token operator">=</span> F<span class="token punctuation">.</span>linear<span class="token punctuation">(</span>x<span class="token punctuation">,</span> weight<span class="token operator">=</span>self<span class="token punctuation">.</span>linear<span class="token punctuation">.</span>weight <span class="token operator">+</span> self<span class="token punctuation">.</span>lora_b @ self<span class="token punctuation">.</span>lora_a <span class="token operator">*</span> self<span class="token punctuation">.</span>scale<span class="token punctuation">,</span> bias<span class="token operator">=</span>self<span class="token punctuation">.</span>linear<span class="token punctuation">.</span>bias<span class="token punctuation">)</span>            output <span class="token operator">=</span> self<span class="token punctuation">.</span>dropout<span class="token punctuation">(</span>output<span class="token punctuation">)</span>            <span class="token keyword">return</span> output        <span class="token keyword">else</span><span class="token punctuation">:</span>            <span class="token keyword">return</span> self<span class="token punctuation">.</span>linear<span class="token punctuation">(</span>x<span class="token punctuation">)</span></code></pre><p>这里就是用 LoRA 的 A 和 B 矩阵乘上原始权重矩阵的计算过程来在前向中参与进计算过程。在训练的时候就会反向更新 LoRA 两个矩阵的参数。</p><p>最简单的实现过程就是这样，假若要将 LoRA 模块包装到具体的一个模型进行微调，那么可以把 base_model 里的 module 里面的线性层替换成 LoRA Linear 层，然后再冻结预训练权重在下游任务上进行训练。可以直接利用 hugging face 的 Trainer 类开一个 Trainer 直接训。</p>]]></content>
      
      
      
        <tags>
            
            <tag> 学习笔记 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>DeepSeekMoE：我们需要更多Experts！</title>
      <link href="/2025/01/05/lun-wen-deepseekmoe/"/>
      <url>/2025/01/05/lun-wen-deepseekmoe/</url>
      
        <content type="html"><![CDATA[<h1 id="DeepSeekMoE：迈向终极专家专业化"><a href="#DeepSeekMoE：迈向终极专家专业化" class="headerlink" title="DeepSeekMoE：迈向终极专家专业化"></a>DeepSeekMoE：迈向终极专家专业化</h1><p>最近 DeepSeek 火爆整个2025年新春，趁着这波热度，想起来几个月前在 ACL 2024 上看过他们的论文，于是翻回来重新研究了一下。其实整篇论文的动机和故事都很直觉，但是不得不说人家的论文写得真的漂亮呀！</p><ul><li><strong>专家不够分化：</strong>以往的 MoE 模型一般也就是6个8个左右的 Expert 数量，但是任务量实际上要远远大于专家数，那么专家其实是不够“专”的。所以尽可能地把专家数拉高，然后寄希望于更多的专家分化知识能力。</li><li><strong>专家冗余：</strong>假设每个 Token 都需要常识知识，那么不管选哪个专家，这个专家都会保留常识知识能力，因而专家的“专业性”受到了影响，存在知识冗余，就浪费掉很多参数了。因此增设共享专家，所有 Token 来的时候都会选这个专家。</li></ul><hr><h4 id="模型架构："><a href="#模型架构：" class="headerlink" title="模型架构："></a>模型架构：</h4><p>所以方法也很直观了，论文里的 <strong>pipeline</strong> 也画得非常清楚：</p><p><img src="https://cyan-1314223569.cos.ap-beijing.myqcloud.com/test/1738763285958.jpg?imageSlim"></p><ol><li><p><strong>专家数量增加实现</strong>：</p><ul><li>具体来说，是通过拆分专家——比如把一个拆成两个——来增加专家数量。</li><li>主流的专家实际上就是个 FFN，FFN 实际上就是两个矩阵。假设这两个矩阵的大小分别是：$dh$ 和 $hd$ 。如果要把这个专家拆分成两个专家，实际上就是把矩阵拆成两个 $d*(h&#x2F;2)$ 和 $(h&#x2F;2)*d$ 这样。</li><li>假如原本一个 token 选择 top-1 专家来处理，拆成两个后，就变成选择 top-2 专家来出来。这样计算量和参数量是没有变化的。</li></ul><blockquote><p>实际上门控的计算量还是有变化的，路由模块需要计算的专家数增多了，自然计算量会大一些。</p></blockquote></li><li><p><strong>共享专家增设</strong>：</p><ul><li>有的专家是必选的，除此以外，每个 token 按照自己的喜好，再来选择 top-k。比如有 64 个专家，那么第一个专家是所有 token 都要选的，除此以外，每个 token 还从剩下的 63 个里选择自己的 top-1 专家。</li></ul></li></ol><p><strong>但这样就有一个新的考虑：Expert 数增大的情况下，是不是对于 Router 的能力依赖会更强呢？因为直观上来讲，每个专家更加分化，肯定也希望我的 Router 能够选得更精确，才能最大程度发挥专家的知识能力。所以是不是能用一个更 Stronger 的路由模块去进行一个进一步的优化？</strong></p><hr><h4 id="Experiment："><a href="#Experiment：" class="headerlink" title="Experiment："></a>Experiment：</h4><blockquote><p>不得不说人家的 Experiment 是真的充分，而且特别详细……</p></blockquote><p><strong>验证实验（2B参数模型）：</strong>验证DeepSeekMoE架构在中小规模下的有效性。对比了Dense模型、Hash Layer、Switch Transformer、GShard等MoE架构，</p><p><img src="https://cyan-1314223569.cos.ap-beijing.myqcloud.com/test/1738764304023.jpg?imageSlim"></p><p><strong>消融实验：</strong>主要验证了细粒度分割和共享专家的作用体现。</p><p><img src="https://cyan-1314223569.cos.ap-beijing.myqcloud.com/test/1738764486549.jpg?imageSlim"></p><p>当然论文还做了很多其它实验，在16B模型上的扩展实验、对齐实验（监督微调）、超大规模模型实验……这里就不一一列举了，感兴趣可以去读下原文~</p><p>这里突然想起来 ACL 2024 上还有一篇 Dynamic MoE，直观上感觉那篇的动态路由用到 DeepSeek 这样多专家的架构上提升应该更明显。因为其实 Top-K 这样固定选专家数量的策略，在专家数更多组合更多样的情况下，打分之后可能会有更大的差异性，所以按阈值来路由兴许有更好的效果。</p><hr>]]></content>
      
      
      
        <tags>
            
            <tag> 论文笔记 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>【学习】Transformer基础架构</title>
      <link href="/2024/12/23/xue-xi-transformer-yuan-li/"/>
      <url>/2024/12/23/xue-xi-transformer-yuan-li/</url>
      
        <content type="html"><![CDATA[<h2 id="Transformer：Embedding"><a href="#Transformer：Embedding" class="headerlink" title="Transformer：Embedding"></a>Transformer：Embedding</h2><hr><blockquote><p>《Attention Is All You Need》里的Transformer架构</p></blockquote><img src="https://cyan-1314223569.cos.ap-beijing.myqcloud.com/test/1741076487595.jpg?imageSlim" alt="Transformer" style="zoom:55%;" /><p>先从 Transformer 的 Embedding 部分写起。当我们输入文本到 Transformer 网络中时，模型接收的是存储着数值的向量而不是文字，因而第一步要做的事就是将这个 text 转化为词向量。</p><h4 id="1-Tokenizer-处理得到词索引"><a href="#1-Tokenizer-处理得到词索引" class="headerlink" title="1. Tokenizer 处理得到词索引"></a>1. Tokenizer 处理得到词索引</h4><p>假定我们输入的 text 文本是一个包含许多单词的句子，我们需要想办法用数值表达这个句子，一种做法就是对每一个单词取一个唯一的索引值，用这个数值来表示这个句子。这些索引映射关系存起来就是<strong>词表。</strong></p><ul><li>当然分词粒度也不一定就是一个单词。只是说单词分词法（word base）最直观。<strong>单词分词法</strong>将一个word作为最小元，也就是根据空格或者标点分词。最详尽的分词是<strong>单字分词法</strong>（character-base）。单字分词法会穷举所有出现的字符，所以是最完整的。另外还有一种最常用的、介于两种方法之间的分词法叫<strong>子词分词法</strong>，会把一个句子分成最小可分的子词例如[‘To’, ‘day’, ‘is’, ‘S’, ‘un’, ‘day’]。</li></ul><p>比如 text &#x3D; “Today is a nice day!”，token &#x3D; tokenizer(text)，那么处理后得到的 tokens 就是一个字典，其中包含了 “input_ids” 词索引序列：’input_ids’: [[101, 2769, 3221, …, 102, 0, 0]]。0 是 padding 的填充项（补全 seq length 长度）</p><h4 id="2-Token-Embedding-词嵌入处理"><a href="#2-Token-Embedding-词嵌入处理" class="headerlink" title="2. Token_Embedding 词嵌入处理"></a>2. Token_Embedding 词嵌入处理</h4><p>经过 tokenizer 分词处理后，我们的输入 x 就变为一个形状 <strong>[batch_size, seq_len]</strong> 的向量，例如 [[101, 2054, 2003, 2026, 3793, 102], [101, 2054, 2064, 2017, 102, 0]] 表示输入 batch_size &#x3D; 2 两个句子。</p><p>那么 embedding 操作就是把输入向量升维。我们输入的 x 对一个单词的表示现在相当于是一个索引值，而我们要把每一个单词都变成一个唯一的向量模型才能学习到其空间嵌入特征。具体而言，假设我们有以下配置：</p><ul><li><p>批次大小 (batch_size) &#x3D; 2</p></li><li><p>序列长度 (seq_len) &#x3D; 4</p></li><li><p>嵌入维度 (d_model) &#x3D; 6</p></li><li><p>词汇表大小 (vocab_size) &#x3D; 10000</p></li></ul><pre class=" language-python"><code class="language-python">x <span class="token operator">=</span> <span class="token punctuation">[</span>    <span class="token punctuation">[</span><span class="token number">101</span><span class="token punctuation">,</span> <span class="token number">2054</span><span class="token punctuation">,</span> <span class="token number">2003</span><span class="token punctuation">,</span> <span class="token number">102</span><span class="token punctuation">]</span><span class="token punctuation">,</span>  <span class="token comment" spellcheck="true"># 第一个句子的词索引</span>    <span class="token punctuation">[</span><span class="token number">101</span><span class="token punctuation">,</span> <span class="token number">5243</span><span class="token punctuation">,</span> <span class="token number">3122</span><span class="token punctuation">,</span> <span class="token number">102</span><span class="token punctuation">]</span>   <span class="token comment" spellcheck="true"># 第二个句子的词索引</span><span class="token punctuation">]</span></code></pre><p>嵌入后的张量可能就是这样，形状变为 [2,4,6] <strong>(batch_size, seq_len, d_model)</strong></p><pre class=" language-python"><code class="language-python">token_embedding <span class="token operator">=</span> <span class="token punctuation">[</span>    <span class="token punctuation">[</span>  <span class="token comment" spellcheck="true"># 第一个句子</span>        <span class="token punctuation">[</span><span class="token number">0.1</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.2</span><span class="token punctuation">,</span> <span class="token number">0.3</span><span class="token punctuation">,</span> <span class="token number">0.1</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.7</span><span class="token punctuation">]</span><span class="token punctuation">,</span>  <span class="token comment" spellcheck="true"># 词索引101的嵌入向量</span>        <span class="token punctuation">[</span><span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.2</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.3</span><span class="token punctuation">,</span> <span class="token number">0.4</span><span class="token punctuation">,</span> <span class="token number">0.1</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.2</span><span class="token punctuation">]</span><span class="token punctuation">,</span>  <span class="token comment" spellcheck="true"># 词索引2054的嵌入向量</span>        <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.3</span><span class="token punctuation">,</span> <span class="token number">0.1</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.2</span><span class="token punctuation">,</span> <span class="token number">0.4</span><span class="token punctuation">,</span> <span class="token number">0.3</span><span class="token punctuation">]</span><span class="token punctuation">,</span>  <span class="token comment" spellcheck="true"># 词索引2003的嵌入向量</span>        <span class="token punctuation">[</span><span class="token number">0.2</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.4</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.1</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.3</span><span class="token punctuation">,</span> <span class="token number">0.1</span><span class="token punctuation">]</span>   <span class="token comment" spellcheck="true"># 词索引102的嵌入向量</span>    <span class="token punctuation">]</span><span class="token punctuation">,</span>    <span class="token punctuation">[</span>  <span class="token comment" spellcheck="true"># 第二个句子</span>        <span class="token punctuation">[</span><span class="token number">0.1</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.2</span><span class="token punctuation">,</span> <span class="token number">0.3</span><span class="token punctuation">,</span> <span class="token number">0.1</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.7</span><span class="token punctuation">]</span><span class="token punctuation">,</span>  <span class="token comment" spellcheck="true"># 词索引101的嵌入向量</span>        <span class="token punctuation">[</span><span class="token number">0.4</span><span class="token punctuation">,</span> <span class="token number">0.3</span><span class="token punctuation">,</span> <span class="token number">0.2</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.1</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.3</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">]</span><span class="token punctuation">,</span>  <span class="token comment" spellcheck="true"># 词索引5243的嵌入向量</span>        <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.2</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.1</span><span class="token punctuation">,</span> <span class="token number">0.3</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.4</span><span class="token punctuation">,</span> <span class="token number">0.2</span><span class="token punctuation">]</span><span class="token punctuation">,</span>  <span class="token comment" spellcheck="true"># 词索引3122的嵌入向量</span>        <span class="token punctuation">[</span><span class="token number">0.2</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.4</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.1</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.3</span><span class="token punctuation">,</span> <span class="token number">0.1</span><span class="token punctuation">]</span>   <span class="token comment" spellcheck="true"># 词索引102的嵌入向量</span>    <span class="token punctuation">]</span><span class="token punctuation">]</span></code></pre><p>嵌入转化的原理实际就是一个查找表。我们首先把每个单词的词索引转化成 one-hot 向量，那么可以想象这个向量维数应该很大，因此再降维。从每个单词的 one-hot 向量经过 <strong>Embedding 矩阵</strong>得到降维后的结果。比如有三个单词， one-hot 处理后的结果是 $3<em>6$ 大小的向量，那么经过一个 $6</em>4$ 大小的权重矩阵就可以乘出 $3*4$ 大小的结果从而降维（d_model &#x3D; 4）。因此这个嵌入矩阵的形状就应该是[vocab_size, d_model] 大小。</p><p>继承 torch 里的 Embedding 类，forward 的时候把输入 x 转换为嵌入向量。具体实现：</p><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 将输入的词汇表索引转换为指定维度的Embedding</span><span class="token comment" spellcheck="true"># 每个token的词索引升维到d_model维，padding_idx=1表示填充词的索引为1</span><span class="token comment" spellcheck="true"># 继承nn.Embedding在训练中前向传播，反向传播，更新参数</span><span class="token keyword">class</span> <span class="token class-name">TokenEmbedding</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Embedding<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> vocab_size<span class="token punctuation">,</span> d_model<span class="token punctuation">)</span><span class="token punctuation">:</span>        super<span class="token punctuation">(</span>TokenEmbedding<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span>vocab_size<span class="token punctuation">,</span> d_model<span class="token punctuation">,</span> padding_idx<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span></code></pre><h4 id="2-Position-Embedding-位置编码"><a href="#2-Position-Embedding-位置编码" class="headerlink" title="2. Position_Embedding 位置编码"></a>2. Position_Embedding 位置编码</h4><p>Transformer 架构引入了位置编码，为每个单词向量生成一个固定的位置向量，来表达其位置相对关系。</p><p>这部分是固定计算的，对于每个 seq_len 长度的句子输入，会返回一个 <strong>[seq_len, d_model]</strong> 形状即符合当前序列长度的位置编码。把词嵌入和位置编码相加才是最终的词向量。</p><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 通过位置编码计算输入每个词生成的正弦余弦位置编码</span><span class="token comment" spellcheck="true"># 创建的是固定不变的位置编码，在训练中不更新，直接基于公式计算这个序列长度的位置编码矩阵</span><span class="token keyword">class</span> <span class="token class-name">PositionalEmbedding</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> d_model<span class="token punctuation">,</span> max_len<span class="token punctuation">,</span> device<span class="token punctuation">)</span><span class="token punctuation">:</span>        super<span class="token punctuation">(</span>PositionalEmbedding<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># 初始化一个大小为(max_len, d_model)的零矩阵</span>        self<span class="token punctuation">.</span>encoding <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>max_len<span class="token punctuation">,</span> d_model<span class="token punctuation">,</span> device<span class="token operator">=</span>device<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>encoding<span class="token punctuation">.</span>requires_grad <span class="token operator">=</span> <span class="token boolean">False</span>        pos <span class="token operator">=</span> torch<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> max_len<span class="token punctuation">,</span> device<span class="token operator">=</span>device<span class="token punctuation">)</span>        pos <span class="token operator">=</span> pos<span class="token punctuation">.</span>float<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>        _2i <span class="token operator">=</span> torch<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> d_model<span class="token punctuation">,</span> step<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> device<span class="token operator">=</span>device<span class="token punctuation">)</span><span class="token punctuation">.</span>float<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>encoding<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">:</span><span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">]</span> <span class="token operator">=</span> torch<span class="token punctuation">.</span>sin<span class="token punctuation">(</span>pos <span class="token operator">/</span> <span class="token punctuation">(</span><span class="token number">10000</span> <span class="token operator">**</span> <span class="token punctuation">(</span>_2i <span class="token operator">/</span> d_model<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>encoding<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">]</span> <span class="token operator">=</span> torch<span class="token punctuation">.</span>cos<span class="token punctuation">(</span>pos <span class="token operator">/</span> <span class="token punctuation">(</span><span class="token number">10000</span> <span class="token operator">**</span> <span class="token punctuation">(</span>_2i <span class="token operator">/</span> d_model<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment" spellcheck="true"># x 形状: [batch_size, seq_len]，也就是词索引</span>        batch_size<span class="token punctuation">,</span> seq_len <span class="token operator">=</span> x<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># 返回适合当前序列长度的位置编码</span>        <span class="token keyword">return</span> self<span class="token punctuation">.</span>encoding<span class="token punctuation">[</span><span class="token punctuation">:</span>seq_len<span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span></code></pre><h4 id="3-Transformer-Embedding"><a href="#3-Transformer-Embedding" class="headerlink" title="3. Transformer_Embedding"></a>3. Transformer_Embedding</h4><p>最后把词嵌入和位置编码合并，即直接相加。（这里在嵌入层神经网络应用一个 dropout 防止过拟合）</p><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 嵌入层的输入是经过tokenizer处理后的词索引，输出是词的Embedding和位置编码</span><span class="token keyword">class</span> <span class="token class-name">TransformerEmbedding</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> vocab_size<span class="token punctuation">,</span> d_model<span class="token punctuation">,</span> max_len<span class="token punctuation">,</span> drop_prob<span class="token punctuation">,</span> device<span class="token punctuation">)</span><span class="token punctuation">:</span>        super<span class="token punctuation">(</span>TransformerEmbedding<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>token_embedding <span class="token operator">=</span> TokenEmbedding<span class="token punctuation">(</span>vocab_size<span class="token punctuation">,</span> d_model<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>positional_embedding <span class="token operator">=</span> PositionalEmbedding<span class="token punctuation">(</span>d_model<span class="token punctuation">,</span> max_len<span class="token punctuation">,</span> device<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>dropout <span class="token operator">=</span> nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span>p<span class="token operator">=</span>drop_prob<span class="token punctuation">)</span>        <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        token_embedding <span class="token operator">=</span> self<span class="token punctuation">.</span>token_embedding<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        positional_embedding <span class="token operator">=</span> self<span class="token punctuation">.</span>positional_embedding<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        <span class="token keyword">return</span> self<span class="token punctuation">.</span>dropout<span class="token punctuation">(</span>token_embedding <span class="token operator">+</span> positional_embedding<span class="token punctuation">)</span></code></pre><h2 id="Transformer：Multi-Attention"><a href="#Transformer：Multi-Attention" class="headerlink" title="Transformer：Multi-Attention"></a>Transformer：Multi-Attention</h2><hr><blockquote><p>《Attention Is All You Need》里的Transformer架构</p></blockquote><img src="https://cyan-1314223569.cos.ap-beijing.myqcloud.com/test/1741076487595.jpg?imageSlim" alt="Transformer" style="zoom:55%;" /><h4 id="1-Self-Attention"><a href="#1-Self-Attention" class="headerlink" title="1. Self-Attention"></a>1. Self-Attention</h4><p>自注意力的作用：随着模型处理输入序列的每个单词，自注意力会关注整个输入序列的所有单词，帮助模型对本单词更好地进行编码。在处理过程中，自注意力机制会将对所有相关单词的理解融入到我们正在处理的单词中。更具体的功能如下：</p><p><strong>序列建模：</strong>自注意力可以用于序列数据（例如文本、时间序列、音频等）的建模。它可以捕捉序列中不同位置的依赖关系，从而更好地理解上下文。这对于机器翻译、文本生成、情感分析等任务非常有用。<br><strong>并行计算：</strong>自注意力可以并行计算，这意味着可以有效地在现代硬件上进行加速。相比于RNN和CNN等序列模型，它更容易在GPU和TPU等硬件上进行高效的训练和推理。（因为在自注意力中可以并行的计算得分）<br><strong>长距离依赖捕捉：</strong>传统的循环神经网络（RNN）在处理长序列时可能面临梯度消失或梯度爆炸的问题。自注意力可以更好地处理长距离依赖关系，因为它不需要按顺序处理输入序列。</p><p><strong>自注意力的计算：</strong></p><p>Self-Attention 是通过输入本身的序列作为 Q 和 K 计算注意力分数的。从每个编码器的输入向量（每个单词的词向量，即Embedding，可以是任意形式的词向量，比如说word2vec，GloVe，one-hot编码）中生成三个向量，即查询向量、键向量和一个值向量。（这三个向量是通过词嵌入与三个权重矩阵相乘后创建出来的）</p><blockquote><p>参考 CSDN @告白气球 的这张图：</p></blockquote><img src= "https://cyan-1314223569.cos.ap-beijing.myqcloud.com/test/cc00beb97c344a486d07e3d9e8a58f06.png?imageSlim"><p>经过上一节 Embedding 层后的嵌入输出维度为 <strong>(batch_size, seq_len, d_model)，</strong>通过 nn.Linear 线性变换为 k, q, v 向量。然后经过注意力分数计算的公式即可得到注意力 score：q 和 k 先相乘，得到 (batch_size, num_heads, seq_len, seq_len) 的score矩阵，矩阵表示序列中每个位置对所有其他位置的注意力权重；softmax 之后与 v 相乘，score 的形状变为 **[batch_size, num_heads, seq_len, n_d]**。</p><h4 id="2-Multi-Head"><a href="#2-Multi-Head" class="headerlink" title="2. Multi-Head"></a>2. Multi-Head</h4><p><strong>self-attention</strong>只是使用了一组 WQ、WK、WV 来进行变换得到查询、键、值矩阵，而 Multi-Head Attention 使用多组WQ，WK，WV得到多组查询、键、值矩阵，然后每组分别计算得到一个 Z 矩阵。</p><p>将所有注意力头 Z 矩阵拼接起来，得到的就是合并了所有头的注意力信息。展平 num_heads 维度，得到 <strong>[batch_size, seq_len, d_model]</strong> 形状的 score。</p><p>最后用一个附加的权重矩阵 W^O 乘以 score，将展平的score通过线性层投影回 d_model 维度，并加上偏置。这个线性变换将合并后的表示投影到一个更有意义的空间。</p><p>总结整个流程就是：</p><img src="https://cyan-1314223569.cos.ap-beijing.myqcloud.com/test/0b8dacfc201e24ef7dc0e690b41b998c.png?imageSlim"><p>最后附上带有详细注释的代码，流程应该很清楚：</p><pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> torch<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn<span class="token keyword">import</span> torch<span class="token punctuation">.</span>optim <span class="token keyword">as</span> optim<span class="token keyword">import</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">as</span> data<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional <span class="token keyword">as</span> F<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token keyword">import</span> random<span class="token keyword">import</span> math<span class="token keyword">from</span> torch <span class="token keyword">import</span> Tensor<span class="token comment" spellcheck="true"># batch_size, seq_len, d_model</span>x <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">)</span><span class="token keyword">class</span> <span class="token class-name">MultiHeadAttention</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> d_model<span class="token punctuation">:</span> int<span class="token punctuation">,</span> num_heads<span class="token punctuation">:</span> int<span class="token punctuation">)</span><span class="token punctuation">:</span>        super<span class="token punctuation">(</span>MultiHeadAttention<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>d_model <span class="token operator">=</span> d_model        self<span class="token punctuation">.</span>num_heads <span class="token operator">=</span> num_heads        <span class="token comment" spellcheck="true"># 线性层的权重矩阵形状为(d_model, d_model)</span>        <span class="token comment" spellcheck="true"># 输入的形状为(batch_size, seq_len, d_model)，线性变换(wx+b)后得到k,q,v</span>        <span class="token comment" spellcheck="true"># 不过一般新向量在维度上往往比词嵌入向量更低</span>        <span class="token comment" spellcheck="true"># W_q：学习"我应该关注什么"的特征表示</span>        <span class="token comment" spellcheck="true"># W_k：学习"我能提供什么信息"的特征表示</span>        <span class="token comment" spellcheck="true"># W_v：学习"我的实际内容是什么"的特征表示</span>        self<span class="token punctuation">.</span>w_q <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>d_model<span class="token punctuation">,</span> d_model<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>w_k <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>d_model<span class="token punctuation">,</span> d_model<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>w_v <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>d_model<span class="token punctuation">,</span> d_model<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>w_o <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>d_model<span class="token punctuation">,</span> d_model<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>softmax <span class="token operator">=</span> nn<span class="token punctuation">.</span>Softmax<span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> q<span class="token punctuation">,</span> k<span class="token punctuation">,</span> v<span class="token punctuation">,</span> mask<span class="token operator">=</span>None<span class="token punctuation">)</span><span class="token punctuation">:</span>        batch_size<span class="token punctuation">,</span> seq_len<span class="token punctuation">,</span> d_model <span class="token operator">=</span> q<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span>        n_d <span class="token operator">=</span> self<span class="token punctuation">.</span>d_model <span class="token operator">//</span> self<span class="token punctuation">.</span>num_heads        <span class="token comment" spellcheck="true"># 将输入向量x线性变换为q,k,v</span>        q<span class="token punctuation">,</span>k<span class="token punctuation">,</span>v <span class="token operator">=</span> self<span class="token punctuation">.</span>w_q<span class="token punctuation">(</span>q<span class="token punctuation">)</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>w_k<span class="token punctuation">(</span>k<span class="token punctuation">)</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>w_v<span class="token punctuation">(</span>v<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># 这里通过view操作将d_model维度拆分为num_heads个头，每个头的大小为n_d</span>        <span class="token comment" spellcheck="true"># 然后通过permute操作将头维度移到前面，变成(batch_size, num_heads, seq_len, n_d)</span>        <span class="token comment" spellcheck="true"># 目的：1.减少计算量，并行计算；2.每个头可以关注不同特征子空间</span>        q <span class="token operator">=</span> q<span class="token punctuation">.</span>view<span class="token punctuation">(</span>batch_size<span class="token punctuation">,</span> seq_len<span class="token punctuation">,</span> self<span class="token punctuation">.</span>num_heads<span class="token punctuation">,</span> n_d<span class="token punctuation">)</span><span class="token punctuation">.</span>permute<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span>        k <span class="token operator">=</span> k<span class="token punctuation">.</span>view<span class="token punctuation">(</span>batch_size<span class="token punctuation">,</span> seq_len<span class="token punctuation">,</span> self<span class="token punctuation">.</span>num_heads<span class="token punctuation">,</span> n_d<span class="token punctuation">)</span><span class="token punctuation">.</span>permute<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span>        v <span class="token operator">=</span> v<span class="token punctuation">.</span>view<span class="token punctuation">(</span>batch_size<span class="token punctuation">,</span> seq_len<span class="token punctuation">,</span> self<span class="token punctuation">.</span>num_heads<span class="token punctuation">,</span> n_d<span class="token punctuation">)</span><span class="token punctuation">.</span>permute<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># 这里k.transpose(2,3)将k的维度从(batch_size, num_heads, seq_len, n_d)变为(batch_size, num_heads, n_d, seq_len)</span>        <span class="token comment" spellcheck="true"># 这样q和k相乘后，得到(batch_size, num_heads, seq_len, seq_len)的score矩阵</span>        <span class="token comment" spellcheck="true"># 矩阵表示序列中每个位置对所有其他位置的注意力权重</span>        <span class="token comment" spellcheck="true"># score[b, h, i, j] 表示在批次 b 的第 h 个头中，位置 i 对位置 j 的注意力分数</span>        score <span class="token operator">=</span> q@k<span class="token punctuation">.</span>transpose<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span> <span class="token operator">/</span> math<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span>n_d<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># 将 mask 中值为0的位置在 score 中填充为一个很大的负数 -1e9</span>        <span class="token comment" spellcheck="true"># 在编码器自注意力中，通常不使用掩码，允许每个位置关注所有位置</span>        <span class="token comment" spellcheck="true"># 在解码器自注意力中，使用掩码确保每个位置只能关注其前面的位置</span>        <span class="token comment" spellcheck="true"># 在填充掩码中，用于忽略填充标记的影响</span>        <span class="token keyword">if</span> mask <span class="token keyword">is</span> <span class="token operator">not</span> None<span class="token punctuation">:</span>            score <span class="token operator">=</span> score<span class="token punctuation">.</span>masked_fill<span class="token punctuation">(</span>mask <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1e9</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># self.softmax(score) 将注意力分数转换为概率分布（每行和为1）</span>        <span class="token comment" spellcheck="true"># score 的形状变为 [batch_size, num_heads, seq_len, n_d]</span>        score <span class="token operator">=</span> self<span class="token punctuation">.</span>softmax<span class="token punctuation">(</span>score<span class="token punctuation">)</span>@v        <span class="token comment" spellcheck="true"># 将 score 的维度转换为 [batch_size, seq_len, num_heads, n_d]</span>        <span class="token comment" spellcheck="true"># 然后展平 num_heads 维度，得到 [batch_size, seq_len, d_model]</span>        score <span class="token operator">=</span> score<span class="token punctuation">.</span>permute<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">.</span>contiguous<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span>batch_size<span class="token punctuation">,</span> seq_len<span class="token punctuation">,</span> d_model<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># 将展平的score通过线性层投影回d_model维度，并加上偏置</span>        <span class="token comment" spellcheck="true"># 这个线性变换将合并后的表示投影到一个更有意义的空间</span>        out <span class="token operator">=</span> self<span class="token punctuation">.</span>w_o<span class="token punctuation">(</span>score<span class="token punctuation">)</span>        <span class="token keyword">return</span> out</code></pre><h2 id="Transformer：Encoder-Decoder"><a href="#Transformer：Encoder-Decoder" class="headerlink" title="Transformer：Encoder &amp; Decoder"></a>Transformer：Encoder &amp; Decoder</h2><hr><blockquote><p>《Attention Is All You Need》里的Transformer架构</p></blockquote><img src="https://cyan-1314223569.cos.ap-beijing.myqcloud.com/test/1741076487595.jpg?imageSlim" alt="Transformer" style="zoom:55%;" /><h4 id="1-Encoder"><a href="#1-Encoder" class="headerlink" title="1. Encoder"></a>1. Encoder</h4><p>Encoder Layer 由一个多头注意力层和一个前馈网络层组成。输入的嵌入向量经过多头注意力机制捕获语义特征长距离依赖，然后经过一层残差连接+归一化，通过前馈网络层映射到高维空间捕获多维特征，最后再次残差连接+归一化输出。</p><p>分析一下 Encoder 部分的张量变化：</p><p><strong>【Embedding】</strong></p><ul><li>输入张量形状：[batch_size, seq_length]</li><li>Embedding 变换后：[batch_size, seq_length, d_model]</li></ul><p><strong>【Multi-Attention】</strong></p><ul><li>将输入分为 num_heads 个头，Q、K、V 矩阵形状：[batch_size, seq_length, d_model &#x2F; num_heads]</li><li>注意力计算后合并注意力：[batch_size, seq_length, d_model]</li></ul><p><strong>【Add &amp; Norm】</strong></p><ul><li><p>将注意力输出与原始输入相加通过归一化层，计算残差损失</p></li><li><p>输出形状保持：[batch_size, seq_length, d_model]</p></li></ul><p><strong>【FFN】</strong></p><ul><li>线性映射到高维(hidden_dim) + ReLU激活 + 线性映射回低维(d_model)</li></ul><p>最终输出：[batch_size, seq_length, d_model]，也就是和 Embedding 变换后的维度对齐。</p><p>借助 pytorch 的代码实现：</p><pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> torch<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn<span class="token keyword">import</span> torch<span class="token punctuation">.</span>optim <span class="token keyword">as</span> optim<span class="token keyword">import</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">as</span> data<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional <span class="token keyword">as</span> F<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token keyword">import</span> random<span class="token keyword">import</span> math<span class="token keyword">from</span> torch <span class="token keyword">import</span> Tensor<span class="token keyword">import</span> os<span class="token keyword">import</span> multi_attention<span class="token keyword">import</span> layernorm<span class="token keyword">import</span> embedding<span class="token keyword">class</span> <span class="token class-name">PositionwiseFeedForward</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> d_model<span class="token punctuation">,</span> hidden_dim<span class="token punctuation">,</span> dropout<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        super<span class="token punctuation">(</span>PositionwiseFeedForward<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>fc1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>d_model<span class="token punctuation">,</span> hidden_dim<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>fc2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>hidden_dim<span class="token punctuation">,</span> d_model<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>dropout <span class="token operator">=</span> nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span>dropout<span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>fc1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        x <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>dropout<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>fc2<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        <span class="token keyword">return</span> x    <span class="token keyword">class</span> <span class="token class-name">EncoderLayer</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> d_model<span class="token punctuation">,</span> hidden_dim<span class="token punctuation">,</span> num_heads<span class="token punctuation">,</span> dropout<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        super<span class="token punctuation">(</span>EncoderLayer<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>attn <span class="token operator">=</span> multi_attention<span class="token punctuation">.</span>MultiHeadAttention<span class="token punctuation">(</span>d_model<span class="token punctuation">,</span> num_heads<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>norm1 <span class="token operator">=</span> layernorm<span class="token punctuation">.</span>LayerNorm<span class="token punctuation">(</span>d_model<span class="token punctuation">)</span>        self<span class="token punctuation">,</span>dropout1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span>dropout<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>ffn <span class="token operator">=</span> PositionwiseFeedForward<span class="token punctuation">(</span>d_model<span class="token punctuation">,</span> hidden_dim<span class="token punctuation">,</span> dropout<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>norm2 <span class="token operator">=</span> layernorm<span class="token punctuation">.</span>LayerNorm<span class="token punctuation">(</span>d_model<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>dropout2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span>dropout<span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">,</span> mask<span class="token operator">=</span>None<span class="token punctuation">)</span><span class="token punctuation">:</span>        _x <span class="token operator">=</span> x        x <span class="token operator">=</span> self<span class="token punctuation">.</span>attn<span class="token punctuation">(</span>x<span class="token punctuation">,</span> x<span class="token punctuation">,</span> x<span class="token punctuation">,</span> mask<span class="token punctuation">)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>dropout1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># 残差连接</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>norm1<span class="token punctuation">(</span>x <span class="token operator">+</span> _x<span class="token punctuation">)</span>        _x <span class="token operator">=</span> x        x <span class="token operator">=</span> self<span class="token punctuation">.</span>ffn<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>dropout2<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>norm2<span class="token punctuation">(</span>x <span class="token operator">+</span> _x<span class="token punctuation">)</span>        <span class="token keyword">return</span> x    <span class="token keyword">class</span> <span class="token class-name">Encoder</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> voc_size<span class="token punctuation">,</span> max_len<span class="token punctuation">,</span> d_model<span class="token punctuation">,</span> hidden_dim<span class="token punctuation">,</span> num_heads<span class="token punctuation">,</span> num_layers<span class="token punctuation">,</span> dropout<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">,</span> device<span class="token operator">=</span>None<span class="token punctuation">)</span><span class="token punctuation">:</span>        super<span class="token punctuation">(</span>Encoder<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>embed <span class="token operator">=</span> embedding<span class="token punctuation">.</span>Embedding<span class="token punctuation">(</span>voc_size<span class="token punctuation">,</span> d_model<span class="token punctuation">,</span> max_len<span class="token punctuation">,</span> dropout<span class="token punctuation">,</span> device<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>layers <span class="token operator">=</span> nn<span class="token punctuation">.</span>ModuleList<span class="token punctuation">(</span><span class="token punctuation">[</span>EncoderLayer<span class="token punctuation">(</span>d_model<span class="token punctuation">,</span> hidden_dim<span class="token punctuation">,</span> num_heads<span class="token punctuation">,</span> dropout<span class="token punctuation">)</span> <span class="token keyword">for</span> _ <span class="token keyword">in</span> range<span class="token punctuation">(</span>num_layers<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">,</span> mask<span class="token operator">=</span>None<span class="token punctuation">)</span><span class="token punctuation">:</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>embed<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        <span class="token keyword">for</span> layer <span class="token keyword">in</span> self<span class="token punctuation">.</span>layers<span class="token punctuation">:</span>            x <span class="token operator">=</span> layer<span class="token punctuation">(</span>x<span class="token punctuation">,</span> mask<span class="token punctuation">)</span>        <span class="token keyword">return</span> x</code></pre><h4 id="2-Decoder"><a href="#2-Decoder" class="headerlink" title="2. Decoder"></a>2. Decoder</h4><p>解码器包含<strong>自注意力与交叉注意力两部分。</strong></p><p>编码器的输出被用作交叉注意力部分的 K 和 V 矩阵（键值向量），Q 矩阵（查询向量）则是自注意力层的输出。交叉注意力层会对编码结果进行注意力调整，计算编码结果与解码输入间的注意关系，以获得与当前解码位置相关的编码器信息。</p><p>在 Multi-Attention 里我们可以看到注意力分数可以应用对应的 mask，mask 矩阵对应值为0的部分，在注意力矩阵将其值设定为无穷小。这样在 Softmax 操作后，这些部分对应的注意力分数就变为0，不被注意到。</p><p>在 Encoder 里面我们只有 **padding mask (s_mask)**，用来标识输入序列的最大长度，不够最大长度的部分补0。而在 Decoder 里还存在一种 mask，也就是 **sequence mask (t_mask)**，用于解码器的自注意力层，确保预测第 i 个位置的token时只能看到位置 i 之前的信息。</p><p>前馈网络层和编码器实现一致。每一层后面都添加一层 Add&amp;Norm 与 dropout。</p><p>最终输出经过一层线性变换，然后Softmax得到输出的概率分布（softmax层会把向量变成概率），然后通过词典，<strong>输出概率最大的对应的单词作为我们的预测输出。</strong></p><p>借助 pytorch 的代码实现：</p><pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> torch<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn<span class="token keyword">import</span> torch<span class="token punctuation">.</span>optim <span class="token keyword">as</span> optim<span class="token keyword">import</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">as</span> data<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional <span class="token keyword">as</span> F<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token keyword">import</span> random<span class="token keyword">import</span> math<span class="token keyword">from</span> torch <span class="token keyword">import</span> Tensor<span class="token keyword">import</span> os<span class="token keyword">import</span> multi_attention<span class="token keyword">import</span> layernorm<span class="token keyword">import</span> embedding<span class="token keyword">class</span> <span class="token class-name">DecoderLayer</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> d_model<span class="token punctuation">,</span> ffn_hidden<span class="token punctuation">,</span> num_heads<span class="token punctuation">,</span> dropout<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        super<span class="token punctuation">(</span>DecoderLayer<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>attn1 <span class="token operator">=</span> multi_attention<span class="token punctuation">.</span>MultiHeadAttention<span class="token punctuation">(</span>d_model<span class="token punctuation">,</span> num_heads<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>norm1 <span class="token operator">=</span> layernorm<span class="token punctuation">.</span>LayerNorm<span class="token punctuation">(</span>d_model<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>dropout1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span>dropout<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>cross_attn <span class="token operator">=</span> multi_attention<span class="token punctuation">.</span>MultiHeadAttention<span class="token punctuation">(</span>d_model<span class="token punctuation">,</span> num_heads<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>norm2 <span class="token operator">=</span> layernorm<span class="token punctuation">.</span>LayerNorm<span class="token punctuation">(</span>d_model<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>dropout2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span>dropout<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>ffn <span class="token operator">=</span> embedding<span class="token punctuation">.</span>PositionwiseFeedForward<span class="token punctuation">(</span>d_model<span class="token punctuation">,</span> ffn_hidden<span class="token punctuation">,</span> dropout<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>norm3 <span class="token operator">=</span> layernorm<span class="token punctuation">.</span>LayerNorm<span class="token punctuation">(</span>d_model<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>dropout3 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span>dropout<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># t_mask是目标序列的掩码，s_mask是源序列的掩码</span>    <span class="token comment" spellcheck="true"># enc是编码器输出，dec是解码器输出</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> dec<span class="token punctuation">,</span> enc<span class="token punctuation">,</span> t_mask<span class="token punctuation">,</span> s_mask<span class="token punctuation">)</span><span class="token punctuation">:</span>        _x <span class="token operator">=</span> dec        x <span class="token operator">=</span> self<span class="token punctuation">.</span>attn1<span class="token punctuation">(</span>_x<span class="token punctuation">,</span> _x<span class="token punctuation">,</span> _x<span class="token punctuation">,</span> t_mask<span class="token punctuation">)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>dropout1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>norm1<span class="token punctuation">(</span>x <span class="token operator">+</span> _x<span class="token punctuation">)</span>        _x <span class="token operator">=</span> x        x <span class="token operator">=</span> self<span class="token punctuation">.</span>cross_attn<span class="token punctuation">(</span>x<span class="token punctuation">,</span> enc<span class="token punctuation">,</span> enc<span class="token punctuation">,</span> s_mask<span class="token punctuation">)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>dropout2<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>norm2<span class="token punctuation">(</span>x <span class="token operator">+</span> _x<span class="token punctuation">)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>ffn<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>dropout3<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>norm3<span class="token punctuation">(</span>x <span class="token operator">+</span> _x<span class="token punctuation">)</span>        <span class="token keyword">return</span> x    <span class="token keyword">class</span> <span class="token class-name">Decoder</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> dec_voc_size<span class="token punctuation">,</span> max_len<span class="token punctuation">,</span> d_model<span class="token punctuation">,</span> hidden_dim<span class="token punctuation">,</span> num_heads<span class="token punctuation">,</span> num_layers<span class="token punctuation">,</span> dropout<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">,</span> device<span class="token operator">=</span>None<span class="token punctuation">)</span><span class="token punctuation">:</span>        super<span class="token punctuation">(</span>Decoder<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>embed <span class="token operator">=</span> embedding<span class="token punctuation">.</span>TransformerEmbedding<span class="token punctuation">(</span>dec_voc_size<span class="token punctuation">,</span> d_model<span class="token punctuation">,</span> max_len<span class="token punctuation">,</span> dropout<span class="token punctuation">,</span> device<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>layers <span class="token operator">=</span> nn<span class="token punctuation">.</span>ModuleList<span class="token punctuation">(</span><span class="token punctuation">[</span>DecoderLayer<span class="token punctuation">(</span>d_model<span class="token punctuation">,</span> hidden_dim<span class="token punctuation">,</span> num_heads<span class="token punctuation">,</span> dropout<span class="token punctuation">)</span> <span class="token keyword">for</span> _ <span class="token keyword">in</span> range<span class="token punctuation">(</span>num_layers<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>fc <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>d_model<span class="token punctuation">,</span> dec_voc_size<span class="token punctuation">)</span>        <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> dec<span class="token punctuation">,</span> enc<span class="token punctuation">,</span> t_mask<span class="token punctuation">,</span> s_mask<span class="token punctuation">)</span><span class="token punctuation">:</span>        dec <span class="token operator">=</span> self<span class="token punctuation">.</span>embed<span class="token punctuation">(</span>dec<span class="token punctuation">)</span>        <span class="token keyword">for</span> layer <span class="token keyword">in</span> self<span class="token punctuation">.</span>layers<span class="token punctuation">:</span>            dec <span class="token operator">=</span> layer<span class="token punctuation">(</span>dec<span class="token punctuation">,</span> enc<span class="token punctuation">,</span> t_mask<span class="token punctuation">,</span> s_mask<span class="token punctuation">)</span>        <span class="token keyword">return</span> self<span class="token punctuation">.</span>fc<span class="token punctuation">(</span>dec<span class="token punctuation">)</span>        </code></pre><h2 id="Transformer：Conbination-Transformer-Layers"><a href="#Transformer：Conbination-Transformer-Layers" class="headerlink" title="Transformer：Conbination Transformer Layers"></a>Transformer：Conbination Transformer Layers</h2><hr><blockquote><p>《Attention Is All You Need》里的Transformer架构</p></blockquote><img src="https://cyan-1314223569.cos.ap-beijing.myqcloud.com/test/1741076487595.jpg?imageSlim" alt="Transformer" style="zoom:55%;" /><p>之前已经写好了 transformer 的各个模块，这里最后合并一下各个组件，组合成最后的 transformer layer！</p><h4 id="init-参数说明"><a href="#init-参数说明" class="headerlink" title="__init__() 参数说明"></a>__init__() 参数说明</h4><ul><li>src_pad_idx：源序列表示 padding 的 idx</li><li>tgt_pad_idx：目标序列表示 padding 的 idx</li><li>src_voc_size：源语言词汇表大小</li><li>tgt_voc_size：目标语言词汇表大小</li><li>max_len：序列最大长度</li><li>d_model：词嵌入维度</li><li>hidden_dim：前馈神经网络隐藏层维度</li><li>num_heads：多头注意力的头数</li><li>num_layers：编码器和解码器的层数</li><li>dropout&#x3D;0.1：dropout比率</li><li>device&#x3D;None：使用设备</li></ul><h4 id="掩码mask预处理"><a href="#掩码mask预处理" class="headerlink" title="掩码mask预处理"></a>掩码mask预处理</h4><p>我们知道，在 Encoder 和 Decoder 里，mask 操作是必须的一环。mask 种类有两种，一种是处理填充序列的 padding mask，一种是处理因果序列的 casual mask，其中 padding mask 在编码器-解码器的 self-attention 和 cross-attention 里都会用到，而 casual mask 则用于解码器的 self-attention 部分。</p><p>casual mask 的定义：对于每个序列，我们通过定义一个对应的下三角矩阵作为 mask。在计算序列第n个词的 attention score 的时候，只有前 n-1 个 token 参与计算。</p><p>padding mask 的定义：二值矩阵，等于 pad_idx 的部分记为 0，不等于的部分记为 1.</p><p>需要注意的是，mask 的掩码操作在注意力矩阵应用 softmax 操作之前。这个流程是：</p><ol><li>Q 查询矩阵与 K 键矩阵转置相乘，[batch_size, num_heads, seq_q, d_k] 与 [batch_size, num_heads, d_k, seq_k] 相乘，得到的矩阵形状为 [batch_size, num_heads, seq_q, seq_k]</li><li>除以根号 d 进行缩放操作</li><li>接下来在注意力分数矩阵上应用掩码，因此 mask 的形状须是一个四维矩阵。在生成 pad_mask 的时候，我们首先用源序列和目标序列创建基础 mask，q_mask &#x3D; (q !&#x3D; pad_idx)，k_mask &#x3D; (k !&#x3D; pad_idx)，shape 为 [batch_size, seq_q &#x2F; seq_k]，接下来拓展维度使其与查询矩阵与键矩阵相匹配，最后将 q_mask &amp; k_mask，得到的最终 mask 为 [batch_size, 1, seq_q, seq_k]，最后应用掩码时通过广播机制匹配到所有注意力头上。对于 casual_mask，创建 [seq_q, seq_k] 形状的下三角矩阵，然后拓展维度与 pad_mask 按元素乘，得到最终的 mask</li><li>softmax 操作</li></ol><h4 id="forward"><a href="#forward" class="headerlink" title="forward"></a>forward</h4><p>Encoder 只需要传递源序列，Decoder 需要传递 encoder 计算的结果与目的序列（做 cross-attention），在前向过程中，先通过 encoder 计算出每一层 Encoder Layer 对于源序列的输出，然后将每一层的编码器输出传递给每一层的解码器，解码器在进行计算，得到最终的解码输出。</p><pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> torch<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn<span class="token keyword">import</span> torch<span class="token punctuation">.</span>optim <span class="token keyword">as</span> optim<span class="token keyword">import</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">as</span> data<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional <span class="token keyword">as</span> F<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token keyword">import</span> random<span class="token keyword">import</span> math<span class="token keyword">from</span> torch <span class="token keyword">import</span> Tensor<span class="token keyword">import</span> os<span class="token keyword">import</span> multi_attention<span class="token keyword">import</span> layernorm<span class="token keyword">import</span> embedding<span class="token keyword">import</span> encoder<span class="token keyword">import</span> decoder<span class="token keyword">class</span> <span class="token class-name">Transformer</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment" spellcheck="true"># src_pad_idx: 源序列的填充索引</span>    <span class="token comment" spellcheck="true"># tgt_pad_idx: 目标序列的填充索引</span>    <span class="token comment" spellcheck="true"># 填充索引是单个数值，在词表中用来表示填充符号padding token的索引值，通常设为0或-1</span>    <span class="token comment" spellcheck="true"># src_voc_size: 源序列的词汇表大小</span>    <span class="token comment" spellcheck="true"># tgt_voc_size: 目标序列的词汇表大小</span>    <span class="token comment" spellcheck="true"># max_len: 序列的最大长度</span>    <span class="token comment" spellcheck="true"># d_model: 词嵌入的维度</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> src_pad_idx<span class="token punctuation">,</span> tgt_pad_idx<span class="token punctuation">,</span> src_voc_size<span class="token punctuation">,</span> tgt_voc_size<span class="token punctuation">,</span> max_len<span class="token punctuation">,</span> d_model<span class="token punctuation">,</span> hidden_dim<span class="token punctuation">,</span> num_heads<span class="token punctuation">,</span> num_layers<span class="token punctuation">,</span> dropout<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">,</span> device<span class="token operator">=</span>None<span class="token punctuation">)</span><span class="token punctuation">:</span>        super<span class="token punctuation">(</span>Transformer<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>encoder <span class="token operator">=</span> encoder<span class="token punctuation">.</span>Encoder<span class="token punctuation">(</span>src_voc_size<span class="token punctuation">,</span> max_len<span class="token punctuation">,</span> d_model<span class="token punctuation">,</span> hidden_dim<span class="token punctuation">,</span> num_heads<span class="token punctuation">,</span> num_layers<span class="token punctuation">,</span> dropout<span class="token punctuation">,</span> device<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>decoder <span class="token operator">=</span> decoder<span class="token punctuation">.</span>Decoder<span class="token punctuation">(</span>tgt_voc_size<span class="token punctuation">,</span> max_len<span class="token punctuation">,</span> d_model<span class="token punctuation">,</span> hidden_dim<span class="token punctuation">,</span> num_heads<span class="token punctuation">,</span> num_layers<span class="token punctuation">,</span> dropout<span class="token punctuation">,</span> device<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>src_pad_idx <span class="token operator">=</span> src_pad_idx        self<span class="token punctuation">.</span>tgt_pad_idx <span class="token operator">=</span> tgt_pad_idx        self<span class="token punctuation">.</span>device <span class="token operator">=</span> device    <span class="token keyword">def</span> <span class="token function">make_pad_mask</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> q<span class="token punctuation">,</span> k<span class="token punctuation">,</span> pad_idx_q<span class="token punctuation">,</span> pad_idx_k<span class="token punctuation">)</span><span class="token punctuation">:</span>        len_q<span class="token punctuation">,</span> len_k <span class="token operator">=</span> q<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> k<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># 先用ne()操作转换为二值矩阵，然后通过unsqueeze()操作在q的维度上扩展维度</span>        <span class="token comment" spellcheck="true"># 最后通过repeat()操作将q的维度扩展为(batch_size, 1, len_q, len_k)</span>        <span class="token comment" spellcheck="true"># 这个操作是为了将mask矩阵的维度和score分数矩阵的维度对齐</span>        q <span class="token operator">=</span> q<span class="token punctuation">.</span>ne<span class="token punctuation">(</span>pad_idx_q<span class="token punctuation">)</span><span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span>        q <span class="token operator">=</span> q<span class="token punctuation">.</span>repeat<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> len_k<span class="token punctuation">)</span>        k <span class="token operator">=</span> k<span class="token punctuation">.</span>ne<span class="token punctuation">(</span>pad_idx_k<span class="token punctuation">)</span><span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span>        k <span class="token operator">=</span> k<span class="token punctuation">.</span>repeat<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> len_q<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>        mask <span class="token operator">=</span> q <span class="token operator">&amp;</span> k        <span class="token keyword">return</span> mask        <span class="token keyword">def</span> <span class="token function">make_casual_mask</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> q<span class="token punctuation">,</span> k<span class="token punctuation">)</span><span class="token punctuation">:</span>        mask <span class="token operator">=</span> torch<span class="token punctuation">.</span>tril<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span>q<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> k<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>type<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>BoolTensor<span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>self<span class="token punctuation">.</span>device<span class="token punctuation">)</span>        <span class="token keyword">return</span> mask        <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> src<span class="token punctuation">,</span> tgt<span class="token punctuation">)</span><span class="token punctuation">:</span>        src_mask <span class="token operator">=</span> self<span class="token punctuation">.</span>make_pad_mask<span class="token punctuation">(</span>src<span class="token punctuation">,</span> src<span class="token punctuation">,</span> self<span class="token punctuation">.</span>src_pad_idx<span class="token punctuation">,</span> self<span class="token punctuation">.</span>src_pad_idx<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># 注意*是按元素乘，相当于把两种mask的作用效果叠加了</span>        tgt_mask <span class="token operator">=</span> self<span class="token punctuation">.</span>make_pad_mask<span class="token punctuation">(</span>tgt<span class="token punctuation">,</span> tgt<span class="token punctuation">,</span> self<span class="token punctuation">.</span>tgt_pad_idx<span class="token punctuation">,</span> self<span class="token punctuation">.</span>tgt_pad_idx<span class="token punctuation">)</span><span class="token operator">*</span>self<span class="token punctuation">.</span>make_casual_mask<span class="token punctuation">(</span>tgt<span class="token punctuation">,</span> tgt<span class="token punctuation">)</span>        enc <span class="token operator">=</span> self<span class="token punctuation">.</span>encoder<span class="token punctuation">(</span>src<span class="token punctuation">,</span> src_mask<span class="token punctuation">)</span>        dec <span class="token operator">=</span> self<span class="token punctuation">.</span>decoder<span class="token punctuation">(</span>tgt<span class="token punctuation">,</span> enc<span class="token punctuation">,</span> tgt_mask<span class="token punctuation">,</span> src_mask<span class="token punctuation">)</span>        <span class="token keyword">return</span> dec</code></pre>]]></content>
      
      
      
        <tags>
            
            <tag> 学习笔记 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>“视界感知者”项目开发文档</title>
      <link href="/2024/09/18/xue-xi-shi-jie-gan-zhi-zhe-xiang-mu/"/>
      <url>/2024/09/18/xue-xi-shi-jie-gan-zhi-zhe-xiang-mu/</url>
      
        <content type="html"><![CDATA[<h1 id="“视界感知者”——基于多模态大模型的智能视导杖"><a href="#“视界感知者”——基于多模态大模型的智能视导杖" class="headerlink" title="“视界感知者”——基于多模态大模型的智能视导杖"></a>“视界感知者”——基于多模态大模型的智能视导杖</h1><hr><h3 id="项目概述"><a href="#项目概述" class="headerlink" title="项目概述"></a>项目概述</h3><p>全球视障人士总数达到4200万，其中中国视障人士人数接近1730万，占全球视障群体的40%。目前，导盲杖仍然是视障人士出行时的辅助用具首选项。</p><p>现如今，得益于人工智能时代的飞速发展，市面上涌现了大量智能盲杖，其主要分为两类：基于超声探测技术的避障盲杖以及基于图像识别、目标检测的智能盲杖。然而，这些设备仍存在显著缺陷，主要有以下不足：</p><ul><li>在某些特定场景下效果表现不佳，如超声探测盲杖遇到玻璃、金属、毛绒物会受到限制。</li><li>现有智能盲杖多数仅能识别出物体类别，难以给出物体的品牌、色彩等信息。</li></ul><p>我们项目开发团队在经过大量调研、走访实践后，认识到：视障人士不仅要导航、避障，还需要更多信息，更全面地感知、认知世界——</p><p>于是，项目开发团队利用大模型多模态能力，打造了一款大模型辅助视障人士“感知世界”的智能导盲杖产品。作品以百度飞桨大模型为基础，结合目标检测与图像分类模型完成标签提取任务，并提出了一套门控分类器，在不同场景下筛选提示词模版，增强对不同场景的泛用性，最终通过大模型生成描述文本，为视障人士提供直观的场景感知。</p><p>作品将软硬件相结合，部署模型到后端服务器，在树莓派、ESP开发板等硬件单元上进行调用，组合实现了相应功能，实际开发完成了实物产品原型，并在响应速度、处理效果上展现出优越的性能。</p><p>视界感知者”智能导盲杖，作为项目的核心成果，主要功能如下：</p><ul><li>通过杖身摄像头拍摄前方图像，调用后端Dify模型工作流对图像进行分析，最终语音播报面前场景物体的描述文本。</li><li>通过语音交互实现随时与大模型对话效果，可针对面前图像进行详细提问，辅助视障者感知周遭环境的具体细节。</li></ul><blockquote><p>图1. 项目核心流程图</p></blockquote><p><img src="https://cyan-1314223569.cos.ap-beijing.myqcloud.com/test/image-20241008224920271.png?imageSlim"></p><p>图1.展示了项目的核心工作流程。整体流程如下所示：</p><p><strong>【硬件部署】：</strong>项目原型机利用树莓派ZERO 2W作为前端处理单元，以Aluminum Heat Sink散热片和NCR18650B可充锂电芯集成了效果良好的供电系统与散热系统。通过嵌入到盲杖上的小型摄像头以及麦克风设备，树莓派可以随时接收并处理摄像头捕获到的场景图片、并将用户的问题提供给后端。</p><p><strong>【上传图像、音频】：</strong>在获取到场景图片与用户提问音频后，树莓派作为处理单元，可将图像Web传输到服务器云端。</p><p><strong>【提取Label与Caption】：</strong>这时，云端部署的飞桨社区PP-HGNetV2 图像分类模型及识别模型对图像处理获得Label标签，并在后端通过使用MSDN网络来获取场景信息的Caption描述，输出传入后续工作流。</p><p><strong>【分类器处理】：</strong>针对获取的标签及Caption描述，项目设计了一套提示词筛选分类器，该门控单元基于标签与Caption输入，对Prompts模版进行选取，从而获得合适的Prompts输入模版，再将其提供给大模型。</p><p><strong>【大模型分析描述】：</strong>借助大语言模型，将prompts输入模版填充完成后，输入进大模型，从而得到其反馈的细致场景描述文本。最终文本会传输回到树莓派中，通过语音播报的方式传达给用户，为用户带来更细节化的场景感知体验。</p><p>我们的作品展示如图：</p><blockquote><p>图2. 产品模型图、实拍图</p></blockquote><p align="center">   <img src="https://cyan-1314223569.cos.ap-beijing.myqcloud.com/test/image-20241008225817880.png?imageSlim" width="423"/>   <img src="https://cyan-1314223569.cos.ap-beijing.myqcloud.com/test/image-20241008225902149.png?imageSlim" alt="Image 2" width="235"/>   <img src="https://cyan-1314223569.cos.ap-beijing.myqcloud.com/test/image-20241008225922548.png?imageSlim" alt="Image 3" width="235"/> </p><p><strong>项目宣传展示详见如下视频：</strong></p><iframe src="//player.bilibili.com/player.html?isOutside=true&aid=113272430795219&bvid=BV1xg2sYKEU5&cid=26203587629&p=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true" width="800" height="450"></iframe><h3 id="项目技术方案"><a href="#项目技术方案" class="headerlink" title="项目技术方案"></a>项目技术方案</h3><h4 id="硬件部分"><a href="#硬件部分" class="headerlink" title="硬件部分"></a>硬件部分</h4><p><em>在这里详细呈现组建整个盲杖产品使用的硬件配置，可以参考如下配置复现产品</em></p><ul><li><strong>“视界感知者”一代版本的硬件配置</strong></li></ul><p><strong>核心处理单元：</strong>“视界感知者”内核基于Raspberry Pi Zero 2 W硬件实现，采用低功耗Wifi通信，用户拍照后即可在线实现目标检测。</p><p>Raspberry Pi Zero 2 W小巧轻便、性能强大、功能完善，适合嵌入设备内部集成。且价格适中，能够降低整体产品制造成本。</p><p>树莓派服务端算法模块基于 Paddle Detection，可实现毫秒级计算，通信模块基于SpringBoot 和 Netty 异步通信框架，在主流服务 GPU（单块 Tesla P100）算力下整体实现亚秒级响应。 </p><p><strong>外壳模具：</strong>产品原型机采用未来8200 Pro树脂，在保证散热、防水、强度符合市场使用场景的要求下的同时减轻重量，也降低了成本。摄像头选用picamera v2，体积小但功能强大，耐用性好，维护成本低。</p><p><strong>散热模块：</strong>散热片选用Aluminum Heat Sink for Raspberry Pi Zero 官方提供的铝合金散热片，价格低廉，足够使用，同时会优化外壳设计，考虑通风口和散热孔的布局，提高空气流通效果，有利于散热。</p><p><strong>供电模块：</strong>选用Panasonic NCR18650B电池，这款电池电量在3500毫安左右，树莓派zero 2W树莓派 Zero 2W 的空闲功耗大约是 0.6 瓦到 1.3 瓦之间，满载功耗在 2.65 瓦左右。不考虑设备发热带来额外功耗的理想情况下，一块容量为 3500 毫安时的电池可以让其运行约 58.33 小时（约2天），在满载状态下，可以运行约13.75小时。</p><blockquote><p> 图3. Raspberry Pi Zero 2 W（左），Aluminum Heat Sink for Raspberry Pi（中）， ZeroPanasonic NCR18650B（右）外观图</p></blockquote><p><img src="https://cyan-1314223569.cos.ap-beijing.myqcloud.com/test/image-20241008231116076.png?imageSlim"></p><p>我们按上述硬件配置组装、焊接线材，完成了第一代“视界感知者”的相关设计（PS：也可使用香橙派作为核心处理单元）。</p><p>最初的“视界感知者”仍存在多数不足，如内部空间占用过大、扬声器声音过小、接触不稳定、散热难以保证等。</p><p>Raspberry Pi Zero 2 W虽然性能较强，但其也有较大的发热问题存在，仅用Aluminum Heat Sink for Raspberry Pi Zero构建的散热模块部分难以保证其有效散热。设备在连续使用时间超过1h至1.5h后，会出现明显的过热导致反应卡顿等问题。</p><p>此外，3D打印的模具也存在一些问题，在抓握手感等方面还有显著欠缺。</p><blockquote><p>图4. “视界感知者”一代版本展示图</p></blockquote><p align="center">   <img src="https://cyan-1314223569.cos.ap-beijing.myqcloud.com/test/image-20241009214446776.png?imageSlim" alt="Image 1" width="220"/>   <img src="https://cyan-1314223569.cos.ap-beijing.myqcloud.com/test/image-20241009214522104.png?imageSlim" alt="Image 2" width="240"/>   <img src="https://cyan-1314223569.cos.ap-beijing.myqcloud.com/test/image-20241009214606641.png?imageSlim" alt="Image 3" width="238"/> <img src="https://cyan-1314223569.cos.ap-beijing.myqcloud.com/test/image-20241009214717200.png?imageSlim" alt="Image 3" width="235"/> </p><ul><li><strong>“视界感知者”二代版本的硬件配置</strong></li></ul><p>针对以上问题，我们升级改良了一代“视界感知者”产品：</p><p><strong>核心处理单元：</strong>更换ESP开发板作为核心处理单元。可使用ESP32 DEVKIT DOIT 板作为产品组件。ESP32具有双核处理器，内置了 Wi-Fi 和蓝牙，有多个引脚和可用的外设供我们开发配置。我们与AiSpea（北京市赛博创力科技有限公司）联合开发了这款新型ESP开发板。</p><p><strong>外壳模具：</strong>我们重新建模产品，使用新一版的建模外观，并对把手进行了重新设计。在制作产品时也采用了更柔韧的树脂材质。围绕上一代存在的尾端触地容易磕绊问题，我们换用了球形滚轮式的尾端样式。</p><p>相比一代产品，二代“视界感知者”通过上述优化，大幅缩小了产品体积，增设了散热通风口与扬声器播放蜂窝口。此外，我们对充电模块重新设计，采用容量更大的可充锂电池，进一步增强了设备的续航能力。</p><blockquote><p>图5. “视界感知者”二代版本展示图、ESP开发板展示图</p></blockquote><p align="center">   <img src="https://cyan-1314223569.cos.ap-beijing.myqcloud.com/test/image-20241009220100448.png?imageSlim" alt="Image 1" width="220"/>   <img src="https://cyan-1314223569.cos.ap-beijing.myqcloud.com/test/image-20241009220110672.png?imageSlim" alt="Image 2" width="220"/>   <img src="https://cyan-1314223569.cos.ap-beijing.myqcloud.com/test/image-20241009220137097.png?imageSlim" alt="Image 3" width="238"/> <img src="https://cyan-1314223569.cos.ap-beijing.myqcloud.com/test/image-20241009220154123.png?imageSlim" alt="Image 3" width="235"/> </p><h4 id="软件部分"><a href="#软件部分" class="headerlink" title="软件部分"></a>软件部分</h4><p><strong>流程总述</strong></p><p>经过实验验证，我们发现，当前大模型辅助盲人感知场景还存在一些较为显著的缺陷：</p><p>（1）难以找到适配多个场景的统一提示词模版，大模型在不同场景下的泛化能力较差。比如在与人交流时和在户外马路上时，会有较大的描述效果差异。</p><p>（2）难以判断场景中的重点部分，过度关注并描述场景整体。大模型往往偏向于将整张图片的每个部分都描述出来，导致对实际重要的地方关注性较差，细节描述冗余。</p><p>因此，我们借助飞桨星河平台的图像分类模型，将每张场景图像的类型作为标签输出，并借助Multi-level Scene Description Network（MSDN）提取图像Caption，将Label与Caption一并作为输入，构造分类器，从而选取适应当前场景图的提示词模版。</p><p>最后，将Caption、Label一并送入大模型，使大模型在描述场景前，对场景的主要物体有了提前感知，从而进一步提升其描述效果，减少上述缺陷带来的影响。</p><p>整个软件部分的流程结构图如下图所示：</p><blockquote><p>图6. 软件功能流程示意图</p></blockquote><p><img src="https://cyan-1314223569.cos.ap-beijing.myqcloud.com/test/image-20241010081733322.png?imageSlim"></p><h5 id="图像分类模型"><a href="#图像分类模型" class="headerlink" title="图像分类模型"></a>图像分类模型</h5><p>我们使用了百度飞桨AI Studio星河社区的通用图像分类模型。</p><p>选取了Top1 Acc(%)表现最优的PP-HGNetV2_B6完成分类任务，并在后端调用获取其输出Label结果，返回到Dify工作流中，Label标签可进一步作为后续输入，辅助大模型整合信息输出场景与物体描述。</p><p>具体的调用代码如下所示：</p><ul><li>imgClassify_api.py（调用模型功能）：</li></ul><pre class=" language-python"><code class="language-python"><span class="token keyword">from</span> flask <span class="token keyword">import</span> Flask<span class="token punctuation">,</span> request<span class="token punctuation">,</span> jsonify<span class="token keyword">import</span> os<span class="token keyword">import</span> cv2<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token keyword">from</span> infer_class2 <span class="token keyword">import</span> classify_imageapp <span class="token operator">=</span> Flask<span class="token punctuation">(</span>__name__<span class="token punctuation">)</span>app<span class="token punctuation">.</span>config<span class="token punctuation">[</span><span class="token string">'JSON_ASCIi'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token boolean">False</span>app<span class="token punctuation">.</span>json<span class="token punctuation">.</span>ensure_ascii <span class="token operator">=</span> <span class="token boolean">False</span>@app<span class="token punctuation">.</span>route<span class="token punctuation">(</span><span class="token string">'/process_image'</span><span class="token punctuation">,</span> methods<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'POST'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token keyword">def</span> <span class="token function">process_image</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    data <span class="token operator">=</span> request<span class="token punctuation">.</span>get_json<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># if not data or 'base64_image' not in data:</span>    <span class="token keyword">if</span> <span class="token operator">not</span> data<span class="token punctuation">:</span>        <span class="token keyword">return</span> jsonify<span class="token punctuation">(</span><span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;"message": "无效的请求，缺少base64_image字段"&amp;#125;), 400</span>    base_64 <span class="token operator">=</span> data<span class="token punctuation">[</span><span class="token string">'base64_image'</span><span class="token punctuation">]</span>    <span class="token comment" spellcheck="true">#k = data['k']</span>    k<span class="token operator">=</span><span class="token number">2</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>k<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># label, confidence = classify_image(base_64)</span>    <span class="token comment" spellcheck="true"># data_dict = &amp;#123;"message": "处理成功", "label": label, "confidence": confidence&amp;#125;</span>    labels_dict <span class="token operator">=</span> classify_image<span class="token punctuation">(</span>base_64<span class="token punctuation">,</span>k<span class="token punctuation">)</span>    data_dict <span class="token operator">=</span> <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;"message": "处理成功", "label": labels_dict&amp;#125;</span>    <span class="token keyword">return</span> jsonify<span class="token punctuation">(</span>data_dict<span class="token punctuation">)</span><span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">'__main__'</span><span class="token punctuation">:</span>    app<span class="token punctuation">.</span>run<span class="token punctuation">(</span>host<span class="token operator">=</span><span class="token string">'0.0.0.0'</span><span class="token punctuation">,</span> port<span class="token operator">=</span><span class="token number">5000</span><span class="token punctuation">)</span></code></pre><ul><li>infer.py（模型推理）：</li></ul><pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> fastdeploy <span class="token keyword">as</span> fd<span class="token keyword">import</span> cv2<span class="token keyword">import</span> os<span class="token keyword">import</span> base64<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token keyword">import</span> argparse<span class="token keyword">def</span> <span class="token function">classify_image</span><span class="token punctuation">(</span>base64_image<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment" spellcheck="true"># 解析参数（这里使用默认的固定参数，可根据需求调整）</span>    manual_args <span class="token operator">=</span> argparse<span class="token punctuation">.</span>Namespace<span class="token punctuation">(</span><span class="token punctuation">)</span>    manual_args<span class="token punctuation">.</span>model <span class="token operator">=</span> <span class="token string">"/home/zhuyifan/PaddleModelDeploy/FastDeploy_Linux_Python_SDK_v1.1.0_x86_64_PP-HGNetV2/model/PPHGNetV2_B6/PPHGNetV2_B6_ssld_infer/"</span>    manual_args<span class="token punctuation">.</span>serial_number <span class="token operator">=</span> None    manual_args<span class="token punctuation">.</span>update_license <span class="token operator">=</span> <span class="token boolean">False</span>    manual_args<span class="token punctuation">.</span>topk <span class="token operator">=</span> <span class="token number">2</span>    manual_args<span class="token punctuation">.</span>device <span class="token operator">=</span> <span class="token string">'cpu'</span>    manual_args<span class="token punctuation">.</span>device_id <span class="token operator">=</span> <span class="token number">0</span>    manual_args<span class="token punctuation">.</span>backend <span class="token operator">=</span> <span class="token string">"default"</span>     args <span class="token operator">=</span> manual_args    <span class="token comment" spellcheck="true"># 配置runtime，加载模型</span>    runtime_option <span class="token operator">=</span> build_option<span class="token punctuation">(</span>args<span class="token punctuation">)</span>    model_file <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>args<span class="token punctuation">.</span>model<span class="token punctuation">,</span> <span class="token string">"inference.pdmodel"</span><span class="token punctuation">)</span>    params_file <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>args<span class="token punctuation">.</span>model<span class="token punctuation">,</span> <span class="token string">"inference.pdiparams"</span><span class="token punctuation">)</span>    config_file <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>args<span class="token punctuation">.</span>model<span class="token punctuation">,</span> <span class="token string">"inference.yml"</span><span class="token punctuation">)</span>    model <span class="token operator">=</span> fd<span class="token punctuation">.</span>vision<span class="token punctuation">.</span>classification<span class="token punctuation">.</span>PaddleClasModel<span class="token punctuation">(</span>        model_file<span class="token punctuation">,</span> params_file<span class="token punctuation">,</span> config_file<span class="token punctuation">,</span> runtime_option<span class="token operator">=</span>runtime_option<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># 解码base64图片</span>    <span class="token keyword">if</span> <span class="token string">'base64,'</span> <span class="token keyword">in</span> base64_image<span class="token punctuation">:</span>        base64_image <span class="token operator">=</span> base64_image<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">'base64,'</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span>    img_data <span class="token operator">=</span> base64<span class="token punctuation">.</span>b64decode<span class="token punctuation">(</span>base64_image<span class="token punctuation">)</span>    nparr <span class="token operator">=</span> np<span class="token punctuation">.</span>frombuffer<span class="token punctuation">(</span>img_data<span class="token punctuation">,</span> np<span class="token punctuation">.</span>uint8<span class="token punctuation">)</span>    im <span class="token operator">=</span> cv2<span class="token punctuation">.</span>imdecode<span class="token punctuation">(</span>nparr<span class="token punctuation">,</span> cv2<span class="token punctuation">.</span>IMREAD_COLOR<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># image = "/home/zhuyifan/PaddleModelDeploy/FastDeploy_Linux_Python_SDK_v1.1.0_x86_64_PP-HGNetV2/example/test.jpg"</span>    <span class="token comment" spellcheck="true"># im = cv2.imread(image)</span>    <span class="token comment" spellcheck="true"># 预测图片分类结果</span>    result <span class="token operator">=</span> model<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>im<span class="token punctuation">,</span> args<span class="token punctuation">.</span>topk<span class="token punctuation">)</span>    label_ids <span class="token operator">=</span> result<span class="token punctuation">.</span>label_ids    scores <span class="token operator">=</span> result<span class="token punctuation">.</span>scores    <span class="token keyword">print</span><span class="token punctuation">(</span>label_ids<span class="token punctuation">,</span> scores<span class="token punctuation">)</span>    label_list_path <span class="token operator">=</span> <span class="token string">"/home/zhuyifan/PaddleModelDeploy/FastDeploy_Linux_Python_SDK_v1.1.0_x86_64_PP-HGNetV2/example/imagenet1k_label_list_chinese .txt"</span>    <span class="token keyword">with</span> open<span class="token punctuation">(</span>label_list_path<span class="token punctuation">,</span> <span class="token string">'r'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>        labels <span class="token operator">=</span> <span class="token punctuation">[</span>line<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">' '</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token keyword">for</span> line <span class="token keyword">in</span> f<span class="token punctuation">.</span>readlines<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span>    label <span class="token operator">=</span> None    confidence <span class="token operator">=</span> None    <span class="token keyword">for</span> label_id<span class="token punctuation">,</span> score <span class="token keyword">in</span> zip<span class="token punctuation">(</span>label_ids<span class="token punctuation">,</span> scores<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">for</span> id_str<span class="token punctuation">,</span> l <span class="token keyword">in</span> labels<span class="token punctuation">:</span>            <span class="token keyword">if</span> int<span class="token punctuation">(</span>id_str<span class="token punctuation">)</span> <span class="token operator">==</span> label_id<span class="token punctuation">:</span>                label <span class="token operator">=</span> l                confidence <span class="token operator">=</span> score                <span class="token keyword">break</span>        <span class="token keyword">if</span> label<span class="token punctuation">:</span>            <span class="token keyword">break</span>    <span class="token keyword">return</span> label<span class="token punctuation">,</span> confidence<span class="token keyword">def</span> <span class="token function">build_option</span><span class="token punctuation">(</span>args<span class="token punctuation">)</span><span class="token punctuation">:</span>    option <span class="token operator">=</span> fd<span class="token punctuation">.</span>RuntimeOption<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">if</span> args<span class="token punctuation">.</span>serial_number<span class="token punctuation">:</span>        encryp_file_path <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>args<span class="token punctuation">.</span>model<span class="token punctuation">,</span> <span class="token string">"encrypt_info.yaml"</span><span class="token punctuation">)</span>        option<span class="token punctuation">.</span>set_authentication<span class="token punctuation">(</span>args<span class="token punctuation">.</span>serial_number<span class="token punctuation">,</span> encryp_file_path<span class="token punctuation">,</span> args<span class="token punctuation">.</span>update_license<span class="token punctuation">)</span>    <span class="token keyword">if</span> args<span class="token punctuation">.</span>device<span class="token punctuation">.</span>lower<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token string">"gpu"</span><span class="token punctuation">:</span>        option<span class="token punctuation">.</span>use_gpu<span class="token punctuation">(</span>args<span class="token punctuation">.</span>device_id<span class="token punctuation">)</span>    <span class="token keyword">if</span> args<span class="token punctuation">.</span>backend<span class="token punctuation">.</span>lower<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token string">"trt"</span><span class="token punctuation">:</span>        <span class="token keyword">assert</span> args<span class="token punctuation">.</span>device<span class="token punctuation">.</span>lower<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token string">"gpu"</span><span class="token punctuation">,</span> <span class="token string">"TensorRT backend require inference on device GPU."</span>        option<span class="token punctuation">.</span>use_trt_backend<span class="token punctuation">(</span><span class="token punctuation">)</span>        option<span class="token punctuation">.</span>trt_option<span class="token punctuation">.</span>set_shape<span class="token punctuation">(</span><span class="token string">"x"</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">224</span><span class="token punctuation">,</span> <span class="token number">224</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">224</span><span class="token punctuation">,</span> <span class="token number">224</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">224</span><span class="token punctuation">,</span> <span class="token number">224</span><span class="token punctuation">]</span><span class="token punctuation">)</span>    <span class="token keyword">elif</span> args<span class="token punctuation">.</span>backend<span class="token punctuation">.</span>lower<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token string">"pptrt"</span><span class="token punctuation">:</span>        <span class="token keyword">assert</span> args<span class="token punctuation">.</span>device<span class="token punctuation">.</span>lower<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token string">"gpu"</span><span class="token punctuation">,</span> <span class="token string">"Paddle - TensorRT backend require inference on device GPU."</span>        option<span class="token punctuation">.</span>use_paddle_infer_backend<span class="token punctuation">(</span><span class="token punctuation">)</span>        option<span class="token punctuation">.</span>paddle_infer_option<span class="token punctuation">.</span>enable_trt <span class="token operator">=</span> <span class="token boolean">True</span>        option<span class="token punctuation">.</span>paddle_infer_option<span class="token punctuation">.</span>collect_trt_shape <span class="token operator">=</span> <span class="token boolean">True</span>        option<span class="token punctuation">.</span>paddle_infer_option<span class="token punctuation">.</span>enable_log_info <span class="token operator">=</span> <span class="token boolean">False</span>        option<span class="token punctuation">.</span>trt_option<span class="token punctuation">.</span>set_shape<span class="token punctuation">(</span><span class="token string">"x"</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">224</span><span class="token punctuation">,</span> <span class="token number">224</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">224</span><span class="token punctuation">,</span> <span class="token number">224</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">224</span><span class="token punctuation">,</span> <span class="token number">224</span><span class="token punctuation">]</span><span class="token punctuation">)</span>    <span class="token keyword">elif</span> args<span class="token punctuation">.</span>backend<span class="token punctuation">.</span>lower<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token string">"ort"</span><span class="token punctuation">:</span>        option<span class="token punctuation">.</span>use_ort_backend<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">elif</span> args<span class="token punctuation">.</span>backend<span class="token punctuation">.</span>lower<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token string">"paddle"</span><span class="token punctuation">:</span>        option<span class="token punctuation">.</span>use_paddle_infer_backend<span class="token punctuation">(</span><span class="token punctuation">)</span>        option<span class="token punctuation">.</span>paddle_infer_option<span class="token punctuation">.</span>enable_log_info <span class="token operator">=</span> <span class="token boolean">False</span>    <span class="token keyword">elif</span> args<span class="token punctuation">.</span>backend<span class="token punctuation">.</span>lower<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token string">"openvino"</span><span class="token punctuation">:</span>        <span class="token keyword">assert</span> args<span class="token punctuation">.</span>device<span class="token punctuation">.</span>lower<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token string">"cpu"</span><span class="token punctuation">,</span> <span class="token string">"OpenVINO backend require inference on device CPU."</span>        option<span class="token punctuation">.</span>use_openvino_backend<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">elif</span> args<span class="token punctuation">.</span>backend<span class="token punctuation">.</span>lower<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token string">"pplite"</span><span class="token punctuation">:</span>        <span class="token keyword">assert</span> args<span class="token punctuation">.</span>device<span class="token punctuation">.</span>lower<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token string">"cpu"</span><span class="token punctuation">,</span> <span class="token string">"Paddle Lite backend require inference on device CPU."</span>        option<span class="token punctuation">.</span>use_lite_backend<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">return</span> optionbase_64 <span class="token operator">=</span> <span class="token string">""</span><span class="token keyword">with</span> open<span class="token punctuation">(</span><span class="token string">'PaddleModelDeploy/FastDeploy_Linux_Python_SDK_v1.1.0_x86_64_PP-HGNetV2/example/base64_example'</span><span class="token punctuation">,</span> <span class="token string">'rb'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>        binary_content <span class="token operator">=</span> f<span class="token punctuation">.</span>read<span class="token punctuation">(</span><span class="token punctuation">)</span>        content <span class="token operator">=</span> binary_content<span class="token punctuation">.</span>decode<span class="token punctuation">(</span><span class="token string">'utf - 8'</span><span class="token punctuation">)</span>        base_64 <span class="token operator">=</span> contentlabel<span class="token punctuation">,</span> confidence <span class="token operator">=</span> classify_image<span class="token punctuation">(</span>base_64<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>label<span class="token punctuation">)</span></code></pre><h5 id="Dify工作流整合"><a href="#Dify工作流整合" class="headerlink" title="Dify工作流整合"></a>Dify工作流整合</h5><p>我们使用Dify平台整合各模型处理过程，搭建起整个项目流程工作流。</p><p>Dify工作流的示意如下所示（仅作展示demo，分类器构建了厕所、教室两个场景作为示意）：</p><blockquote><p>图8. Dify工作流示意图</p></blockquote><p><img src="https://cyan-1314223569.cos.ap-beijing.myqcloud.com/test/image-20241008230656410.png?imageSlim"></p><p>可以参考如下代码进行Dify工作流的调用：</p><pre class=" language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">difiAPI</span><span class="token punctuation">(</span>input_image<span class="token punctuation">,</span>query<span class="token punctuation">)</span><span class="token punctuation">:</span>    buffered <span class="token operator">=</span> BytesIO<span class="token punctuation">(</span><span class="token punctuation">)</span>    input_image<span class="token punctuation">.</span>save<span class="token punctuation">(</span>buffered<span class="token punctuation">,</span> format<span class="token operator">=</span><span class="token string">"PNG"</span><span class="token punctuation">)</span>    base64_image <span class="token operator">=</span> base64<span class="token punctuation">.</span>b64encode<span class="token punctuation">(</span>buffered<span class="token punctuation">.</span>getvalue<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>decode<span class="token punctuation">(</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span>    base64_image <span class="token operator">=</span> <span class="token string">'data:image/jpeg;base64,'</span><span class="token operator">+</span> base64_image    url <span class="token operator">=</span> <span class="token string">"https://api.dify.ai/v1/workflows/run"</span>    headers <span class="token operator">=</span> <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;</span>        <span class="token string">"Authorization"</span><span class="token punctuation">:</span> <span class="token string">"Bearer app-0OW05boo9sfPeGNkMynyuhTp"</span><span class="token punctuation">,</span>        <span class="token string">"Content-Type"</span><span class="token punctuation">:</span> <span class="token string">"application/json"</span>    <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#125;</span>    data <span class="token operator">=</span> <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;</span>        <span class="token string">"inputs"</span><span class="token punctuation">:</span> <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;"query": query, "base64": str(base64_image)&amp;#125;,</span>        <span class="token string">"response_mode"</span><span class="token punctuation">:</span> <span class="token string">"blocking"</span><span class="token punctuation">,</span>        <span class="token string">"user"</span><span class="token punctuation">:</span> <span class="token string">"abc-123"</span>    <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#125;</span>    response <span class="token operator">=</span> requests<span class="token punctuation">.</span>post<span class="token punctuation">(</span>url<span class="token punctuation">,</span> headers <span class="token operator">=</span> headers<span class="token punctuation">,</span> json <span class="token operator">=</span> data<span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>type<span class="token punctuation">(</span>  response<span class="token punctuation">.</span>content<span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>response<span class="token punctuation">.</span>content<span class="token punctuation">)</span>        string_data <span class="token operator">=</span> response<span class="token punctuation">.</span>content<span class="token punctuation">.</span>decode<span class="token punctuation">(</span><span class="token string">'utf - 8'</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># 先将字节流解码为字符串</span>    json_data <span class="token operator">=</span> json<span class="token punctuation">.</span>loads<span class="token punctuation">(</span>string_data<span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 然后进行JSON解析</span>    text_value <span class="token operator">=</span> json_data<span class="token punctuation">[</span><span class="token string">'data'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'outputs'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'text'</span><span class="token punctuation">]</span>     <span class="token comment" spellcheck="true"># 取出text字段的值</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>text_value<span class="token punctuation">)</span>    <span class="token keyword">return</span> text_value</code></pre><h4 id="Demo演示"><a href="#Demo演示" class="headerlink" title="Demo演示"></a>Demo演示</h4><p>我们在飞桨AI Studio星河社区上线项目，以Gradio为前端搭建了我们功能的演示Demo。</p><p>由于无法直接在社区上呈现我们的盲杖产品本身，因此我们实际在星河社区部署的仅仅是盲杖的软件功能演示Demo。具体地，我们通过如下方式搭建了现有的Demo演示：</p><ul><li>用户能够在我们的demo页面开启摄像头拍摄图像，或直接上传图像文件；</li><li>用户能够开启设备麦克风进行录音，或直接上传wav音频文件，输入自己想要提问大模型或与其对话的内容；</li><li>图像文件与音频作为输入，通过Dify进入我们的模型工作流。工作流在后端使用我们部署模型的服务器接口，通过我们设计的分类器等模块，最终经过飞桨文心大模型处理得到最后的场景描述文本。</li><li>场景描述文本会转为音频文件，您可以听到关于该场景图的语音描述。</li></ul><p>具体的Demo演示画面如图所示：</p><blockquote><p>图9. Demo演示界面示意图</p></blockquote><p><img src="https://cyan-1314223569.cos.ap-beijing.myqcloud.com/test/image-20241010083825467.png?imageSlim"></p><p><del>注：由于项目在飞桨平台部署后，连接稳定性相比硬件设备可能有限（飞桨平台服务器的限制），有时会存在较长的等待延迟，如果等待最终结果的时间过长，这并非是后端模块处理流程太慢的缘故。</del></p><p>您可以使用如下代码构建我们的Demo演示前端：</p><pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> gradio <span class="token keyword">as</span> gr<span class="token keyword">import</span> requests<span class="token keyword">from</span> io <span class="token keyword">import</span> BytesIO<span class="token keyword">from</span> PIL <span class="token keyword">import</span> Image<span class="token punctuation">,</span> ExifTags<span class="token keyword">import</span> json<span class="token keyword">import</span> base64<span class="token keyword">import</span> json<span class="token keyword">import</span> base64<span class="token keyword">from</span> io <span class="token keyword">import</span> BytesIO<span class="token keyword">from</span> urllib<span class="token punctuation">.</span>parse <span class="token keyword">import</span> urlencode<span class="token punctuation">,</span> quote_plus<span class="token comment" spellcheck="true"># python /home/aistudio/Gradio.app.py</span>title <span class="token operator">=</span> <span class="token string">"盲杖——飞桨演示版"</span><span class="token keyword">def</span> <span class="token function">vtt</span><span class="token punctuation">(</span>file_path<span class="token punctuation">)</span><span class="token punctuation">:</span>    url <span class="token operator">=</span> <span class="token string">"https://vop.baidu.com/server_api"</span>    <span class="token comment" spellcheck="true"># 读取音频文件</span>    <span class="token keyword">with</span> open<span class="token punctuation">(</span>file_path<span class="token punctuation">,</span> <span class="token string">'rb'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> audio_file<span class="token punctuation">:</span>        audio_data <span class="token operator">=</span> audio_file<span class="token punctuation">.</span>read<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># 对音频数据进行Base64编码</span>    base64_audio <span class="token operator">=</span> base64<span class="token punctuation">.</span>b64encode<span class="token punctuation">(</span>audio_data<span class="token punctuation">)</span><span class="token punctuation">.</span>decode<span class="token punctuation">(</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># 定义请求的 payload</span>    payload <span class="token operator">=</span> <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;</span>        <span class="token string">"format"</span><span class="token punctuation">:</span> <span class="token string">"wav"</span><span class="token punctuation">,</span>  <span class="token comment" spellcheck="true"># 根据音频格式调整</span>        <span class="token string">"rate"</span><span class="token punctuation">:</span> <span class="token number">16000</span><span class="token punctuation">,</span>    <span class="token comment" spellcheck="true"># 根据音频采样率调整</span>        <span class="token string">"channel"</span><span class="token punctuation">:</span> <span class="token number">1</span><span class="token punctuation">,</span>        <span class="token string">"cuid"</span><span class="token punctuation">:</span> <span class="token string">"xAxXo9S0RTzXRU1INrMioJOi7ta3zGBs"</span><span class="token punctuation">,</span>        <span class="token string">"token"</span><span class="token punctuation">:</span> <span class="token string">"24.b0acaa76ec97b7dcb69eda11b0220891.2592000.1730967744.282335-115786479"</span><span class="token punctuation">,</span>        <span class="token string">"speech"</span><span class="token punctuation">:</span> base64_audio<span class="token punctuation">,</span>        <span class="token string">"len"</span><span class="token punctuation">:</span> len<span class="token punctuation">(</span>audio_data<span class="token punctuation">)</span>    <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#125;</span>    headers <span class="token operator">=</span> <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;</span>        <span class="token string">'Content - Type'</span><span class="token punctuation">:</span> <span class="token string">'application/json'</span><span class="token punctuation">,</span>        <span class="token string">'Accept'</span><span class="token punctuation">:</span> <span class="token string">'application/json'</span>    <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#125;</span>    response <span class="token operator">=</span> requests<span class="token punctuation">.</span>post<span class="token punctuation">(</span>url<span class="token punctuation">,</span> headers <span class="token operator">=</span> headers<span class="token punctuation">,</span> json <span class="token operator">=</span> payload<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">#print(type(response.content))</span>    <span class="token comment" spellcheck="true">#b'&amp;#123;"corpus_no":"7423668938825248267","err_msg":"success.","err_no":0,"result":["\xe5\xa4\xa7\xe7\x86\x8a\xe7\x8c\xab\xe5\x9c\xa8\xe5\x93\xaa\xef\xbc\x9f"],"sn":"728897213551728457617"&amp;#125;\n</span>    string_data <span class="token operator">=</span> response<span class="token punctuation">.</span>content<span class="token punctuation">.</span>decode<span class="token punctuation">(</span><span class="token string">'utf - 8'</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># 先将字节流解码为字符串</span>    json_data <span class="token operator">=</span> json<span class="token punctuation">.</span>loads<span class="token punctuation">(</span>string_data<span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 然后进行JSON解析</span>    text_value <span class="token operator">=</span> json_data<span class="token punctuation">[</span><span class="token string">'result'</span><span class="token punctuation">]</span>    <span class="token comment" spellcheck="true"># 取出text字段的值</span>    <span class="token comment" spellcheck="true">#print(text_value)</span>    <span class="token keyword">return</span> text_value<span class="token keyword">def</span> <span class="token function">tts</span><span class="token punctuation">(</span>text<span class="token punctuation">)</span><span class="token punctuation">:</span>    TOKEN <span class="token operator">=</span> <span class="token string">"24.b46eb2202b81ff94efa5603c3fddaba4.2592000.1731076355.282335-115786479"</span>    TEXT <span class="token operator">=</span> <span class="token string">"欢迎使用百度语音合成。"</span>    <span class="token comment" spellcheck="true"># 发音人选择</span>    PER <span class="token operator">=</span> <span class="token number">4</span>    SPD <span class="token operator">=</span> <span class="token number">5</span>    PIT <span class="token operator">=</span> <span class="token number">5</span>    VOL <span class="token operator">=</span> <span class="token number">5</span>    AUE <span class="token operator">=</span> <span class="token number">3</span>    CUID <span class="token operator">=</span> <span class="token string">"xAxXo9S0RTzXRU1INrMioJOi7ta3zGBs"</span>  <span class="token comment" spellcheck="true"># 设置 CUID</span>    TTS_URL <span class="token operator">=</span> <span class="token string">'http://tsn.baidu.com/text2audio'</span>    <span class="token comment" spellcheck="true"># 构造请求参数</span>    tex <span class="token operator">=</span> quote_plus<span class="token punctuation">(</span>text<span class="token punctuation">)</span>    params <span class="token operator">=</span> <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;</span>        <span class="token string">'tok'</span><span class="token punctuation">:</span> TOKEN<span class="token punctuation">,</span>        <span class="token string">'tex'</span><span class="token punctuation">:</span> tex<span class="token punctuation">,</span>        <span class="token string">'per'</span><span class="token punctuation">:</span> PER<span class="token punctuation">,</span>        <span class="token string">'spd'</span><span class="token punctuation">:</span> SPD<span class="token punctuation">,</span>        <span class="token string">'pit'</span><span class="token punctuation">:</span> PIT<span class="token punctuation">,</span>        <span class="token string">'vol'</span><span class="token punctuation">:</span> VOL<span class="token punctuation">,</span>        <span class="token string">'aue'</span><span class="token punctuation">:</span> AUE<span class="token punctuation">,</span>        <span class="token string">'cuid'</span><span class="token punctuation">:</span> CUID<span class="token punctuation">,</span>        <span class="token string">'lan'</span><span class="token punctuation">:</span> <span class="token string">'zh'</span><span class="token punctuation">,</span>        <span class="token string">'ctp'</span><span class="token punctuation">:</span> <span class="token number">1</span>    <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#125;</span>    data <span class="token operator">=</span> urlencode<span class="token punctuation">(</span>params<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># 发送请求</span>    req <span class="token operator">=</span> requests<span class="token punctuation">.</span>post<span class="token punctuation">(</span>TTS_URL<span class="token punctuation">,</span> data<span class="token operator">=</span>data<span class="token punctuation">.</span>encode<span class="token punctuation">(</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># 处理响应</span>    <span class="token keyword">if</span> req<span class="token punctuation">.</span>headers<span class="token punctuation">[</span><span class="token string">'content-type'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>find<span class="token punctuation">(</span><span class="token string">'audio/'</span><span class="token punctuation">)</span> <span class="token operator">&lt;</span> <span class="token number">0</span><span class="token punctuation">:</span>        <span class="token keyword">with</span> open<span class="token punctuation">(</span><span class="token string">'/home/zhuyifan/tts_error.txt'</span><span class="token punctuation">,</span> <span class="token string">'wb'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> of<span class="token punctuation">:</span>            of<span class="token punctuation">.</span>write<span class="token punctuation">(</span>req<span class="token punctuation">.</span>content<span class="token punctuation">)</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"tts api error: "</span> <span class="token operator">+</span> req<span class="token punctuation">.</span>text<span class="token punctuation">)</span>    <span class="token keyword">else</span><span class="token punctuation">:</span>        <span class="token keyword">with</span> open<span class="token punctuation">(</span><span class="token string">"/home/aistudio/result.mp3"</span><span class="token punctuation">,</span> <span class="token string">'wb'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> of<span class="token punctuation">:</span>            of<span class="token punctuation">.</span>write<span class="token punctuation">(</span>req<span class="token punctuation">.</span>content<span class="token punctuation">)</span>    <span class="token keyword">return</span> <span class="token string">"/home/aistudio/result.mp3"</span><span class="token keyword">def</span> <span class="token function">difiAPI</span><span class="token punctuation">(</span>input_image<span class="token punctuation">,</span>query<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment" spellcheck="true">#query = "hello"</span><span class="token comment" spellcheck="true"># 根据图片格式进行转换（如果是PNG则转换为RGB以便后续压缩为JPEG）</span>         <span class="token comment" spellcheck="true"># if input_image.format is not None:</span>    <span class="token comment" spellcheck="true">#     print(input_image.format)</span>    <span class="token comment" spellcheck="true"># try:</span>    <span class="token comment" spellcheck="true">#     exif = input_image.getexif()</span>    <span class="token comment" spellcheck="true">#     for tag, value in exif.items():</span>    <span class="token comment" spellcheck="true">#         if tag in ExifTags.TAGS and ExifTags.TAGS[tag] == 'Format':</span>    <span class="token comment" spellcheck="true">#             print(value)</span>    <span class="token comment" spellcheck="true"># except AttributeError:</span>    <span class="token comment" spellcheck="true">#     pass</span>    buffered <span class="token operator">=</span> BytesIO<span class="token punctuation">(</span><span class="token punctuation">)</span>    input_image<span class="token punctuation">.</span>save<span class="token punctuation">(</span>buffered<span class="token punctuation">,</span> format<span class="token operator">=</span><span class="token string">"PNG"</span><span class="token punctuation">)</span>    base64_image <span class="token operator">=</span> base64<span class="token punctuation">.</span>b64encode<span class="token punctuation">(</span>buffered<span class="token punctuation">.</span>getvalue<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>decode<span class="token punctuation">(</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span>    base64_image <span class="token operator">=</span> <span class="token string">'data:image/jpeg;base64,'</span><span class="token operator">+</span> base64_image    <span class="token comment" spellcheck="true"># with open("/home/zhuyifan/PaddleModelDeploy/VisWorld_example/gradio_code/MangZhangPP/1/tmp", 'w') as f:</span>    <span class="token comment" spellcheck="true">#     f.write(str(base64_image))</span>        url <span class="token operator">=</span> <span class="token string">"https://api.dify.ai/v1/workflows/run"</span>    headers <span class="token operator">=</span> <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;</span>        <span class="token string">"Authorization"</span><span class="token punctuation">:</span> <span class="token string">"Bearer app-0OW05boo9sfPeGNkMynyuhTp"</span><span class="token punctuation">,</span>        <span class="token string">"Content-Type"</span><span class="token punctuation">:</span> <span class="token string">"application/json"</span>    <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#125;</span>    data <span class="token operator">=</span> <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;</span>        <span class="token string">"inputs"</span><span class="token punctuation">:</span> <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;"query": query, "base64": str(base64_image)&amp;#125;,</span>        <span class="token string">"response_mode"</span><span class="token punctuation">:</span> <span class="token string">"blocking"</span><span class="token punctuation">,</span>        <span class="token string">"user"</span><span class="token punctuation">:</span> <span class="token string">"abc-123"</span>    <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#125;</span>    response <span class="token operator">=</span> requests<span class="token punctuation">.</span>post<span class="token punctuation">(</span>url<span class="token punctuation">,</span> headers <span class="token operator">=</span> headers<span class="token punctuation">,</span> json <span class="token operator">=</span> data<span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>type<span class="token punctuation">(</span>  response<span class="token punctuation">.</span>content<span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>response<span class="token punctuation">.</span>content<span class="token punctuation">)</span>        string_data <span class="token operator">=</span> response<span class="token punctuation">.</span>content<span class="token punctuation">.</span>decode<span class="token punctuation">(</span><span class="token string">'utf - 8'</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># 先将字节流解码为字符串</span>    json_data <span class="token operator">=</span> json<span class="token punctuation">.</span>loads<span class="token punctuation">(</span>string_data<span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 然后进行JSON解析</span>    text_value <span class="token operator">=</span> json_data<span class="token punctuation">[</span><span class="token string">'data'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'outputs'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'text'</span><span class="token punctuation">]</span>     <span class="token comment" spellcheck="true"># 取出text字段的值</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>text_value<span class="token punctuation">)</span>    <span class="token keyword">return</span> text_value<span class="token keyword">def</span> <span class="token function">process</span><span class="token punctuation">(</span>input_image<span class="token punctuation">,</span> input_audio<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment" spellcheck="true">#print(type(input_audio))</span>    query_text <span class="token operator">=</span> vtt<span class="token punctuation">(</span>input_audio<span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>query_text<span class="token punctuation">)</span>    output_text <span class="token operator">=</span> difiAPI<span class="token punctuation">(</span>input_image<span class="token operator">=</span>input_image<span class="token punctuation">,</span> query<span class="token operator">=</span>query_text<span class="token punctuation">)</span>    output_audio <span class="token operator">=</span> tts<span class="token punctuation">(</span>output_text<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">#print(output_text)</span>    <span class="token comment" spellcheck="true">#output_audio = "/home/zhuyifan/PaddleModelDeploy/VisWorld_example/gradio_code/MangZhangPP/我的前面是什么.wav"</span>    <span class="token keyword">return</span> output_text<span class="token punctuation">,</span> output_audiodemo_image <span class="token operator">=</span> <span class="token string">"/home/aistudio/test.jpg"</span>demo_audio <span class="token operator">=</span> <span class="token string">"/home/aistudio/demo_whatinfrontofme.wav"</span>examples <span class="token operator">=</span> <span class="token punctuation">[</span>    <span class="token punctuation">[</span>demo_image<span class="token punctuation">,</span> demo_audio<span class="token punctuation">]</span><span class="token punctuation">]</span>demo <span class="token operator">=</span> gr<span class="token punctuation">.</span>Interface<span class="token punctuation">(</span>fn <span class="token operator">=</span> process<span class="token punctuation">,</span>                    inputs <span class="token operator">=</span> <span class="token punctuation">[</span>gr<span class="token punctuation">.</span>Image<span class="token punctuation">(</span>type <span class="token operator">=</span> <span class="token string">"pil"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> gr<span class="token punctuation">.</span>Audio<span class="token punctuation">(</span>type <span class="token operator">=</span> <span class="token string">"filepath"</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">,</span>                    outputs <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">"text"</span><span class="token punctuation">,</span> gr<span class="token punctuation">.</span>Audio<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">,</span>                    title <span class="token operator">=</span> title<span class="token punctuation">,</span>examples<span class="token operator">=</span>examples<span class="token punctuation">)</span>demo<span class="token punctuation">.</span>launch<span class="token punctuation">(</span>share <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">,</span>server_name<span class="token operator">=</span><span class="token string">"0.0.0.0"</span><span class="token punctuation">,</span>server_port<span class="token operator">=</span><span class="token number">8080</span> <span class="token punctuation">)</span><span class="token comment" spellcheck="true"># python /home/aistudio/work/Gradio.app.py</span></code></pre><h4 id="盲杖功能实现"><a href="#盲杖功能实现" class="headerlink" title="盲杖功能实现"></a>盲杖功能实现</h4><p>我们在这里放出可部署在树莓派&#x2F;香橙派上的盲杖功能构建代码，您可以参照如下代码和上述流程，使用同样的Dify工作流和模型搭建逻辑构建起整个导盲杖并实现对应功能。</p><p>我们的模型放在后端服务器处理，通过MQTT协议连接前端与后端服务器。您也可以参照MQTT客户端与服务器对接的处理方式，在服务器上搭建模型处理流程，并与Dify工作流相调用，整合在一起。</p><p>具体代码如下：</p><pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> time<span class="token keyword">import</span> wave<span class="token keyword">import</span> sys<span class="token keyword">import</span> subprocess<span class="token keyword">from</span> threading <span class="token keyword">import</span> Event<span class="token keyword">import</span> threading<span class="token keyword">import</span> queue<span class="token keyword">import</span> signal<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token keyword">import</span> requests<span class="token keyword">import</span> json<span class="token keyword">import</span> cv2<span class="token keyword">import</span> paho<span class="token punctuation">.</span>mqtt<span class="token punctuation">.</span>client <span class="token keyword">as</span> mqtt<span class="token keyword">import</span> pvporcupine<span class="token keyword">import</span> pvrecorder<span class="token keyword">from</span> pvrecorder <span class="token keyword">import</span> PvRecorder<span class="token keyword">import</span> os<span class="token keyword">import</span> base64<span class="token keyword">import</span> urllib<span class="token punctuation">.</span>parse<span class="token keyword">from</span> queue <span class="token keyword">import</span> Empty<span class="token keyword">import</span> csv<span class="token keyword">from</span> concurrent<span class="token punctuation">.</span>futures <span class="token keyword">import</span> ThreadPoolExecutor<span class="token punctuation">,</span> Future<span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd<span class="token keyword">import</span> keyboard<span class="token comment" spellcheck="true"># 设备ID和相关配置</span>DEV_ID <span class="token operator">=</span> <span class="token string">'f0:f5:bd:49:f4:2e'</span>mindb <span class="token operator">=</span> <span class="token number">6000</span>  <span class="token comment" spellcheck="true"># 默认最小声音，小于则结束</span>waitTime <span class="token operator">=</span> <span class="token number">2</span>   <span class="token comment" spellcheck="true"># 开始时候等待3秒不说话则自动终止</span>delayTime <span class="token operator">=</span> <span class="token number">0.5</span>  <span class="token comment" spellcheck="true"># 小声1.3秒后自动终止</span>debounce_time <span class="token operator">=</span> <span class="token number">1</span>  <span class="token comment" spellcheck="true"># 去抖时间</span>CHUNK <span class="token operator">=</span> <span class="token number">8192</span>RECORD_CHANNELS <span class="token operator">=</span> <span class="token number">1</span>RECORD_RATE <span class="token operator">=</span> <span class="token number">16000</span>WAVE_OUTPUT_FILENAME <span class="token operator">=</span> <span class="token string">"send.wav"</span>MQTT_SERVER <span class="token operator">=</span> <span class="token string">"150.158.77.109"</span>MQTT_PORT <span class="token operator">=</span> <span class="token number">1883</span>TOPIC <span class="token operator">=</span> <span class="token string">"paho/test/"</span> <span class="token operator">+</span> DEV_IDmsgId <span class="token operator">=</span> <span class="token number">0</span>image_id <span class="token operator">=</span> <span class="token string">""</span>take_photo <span class="token operator">=</span> <span class="token boolean">False</span><span class="token comment" spellcheck="true"># 初始化摄像头</span>camera_index <span class="token operator">=</span> None<span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">if</span> cv2<span class="token punctuation">.</span>VideoCapture<span class="token punctuation">(</span>i<span class="token punctuation">)</span><span class="token punctuation">.</span>isOpened<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        camera_index <span class="token operator">=</span> i        <span class="token keyword">break</span><span class="token keyword">if</span> camera_index <span class="token keyword">is</span> None<span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"未检测到摄像头"</span><span class="token punctuation">)</span>    sys<span class="token punctuation">.</span>exit<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>f<span class="token string">"找到摄像头，使用索引: &amp;#123;camera_index&amp;#125;"</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 初始化录音设备索引</span>usb_mic_index <span class="token operator">=</span> None<span class="token comment" spellcheck="true"># 全局变量用于存储扬声器设备</span>speaker_device <span class="token operator">=</span> None<span class="token comment" spellcheck="true"># 自动检测并设置 USB 录音设备索引</span><span class="token keyword">def</span> <span class="token function">detect_usb_mic_index</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Detecting USB mic index..."</span><span class="token punctuation">)</span>    devices <span class="token operator">=</span> PvRecorder<span class="token punctuation">.</span>get_available_devices<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token keyword">for</span> index<span class="token punctuation">,</span> device <span class="token keyword">in</span> enumerate<span class="token punctuation">(</span>devices<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">if</span> <span class="token string">"Camera"</span> <span class="token keyword">in</span> device<span class="token punctuation">:</span>  <span class="token comment" spellcheck="true"># 检测设备名称中是否包含“Camera”</span>            <span class="token keyword">print</span><span class="token punctuation">(</span>f<span class="token string">"USB Camera found at index &amp;#123;index&amp;#125;."</span><span class="token punctuation">)</span>            <span class="token keyword">return</span> index        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"USB Camera not found."</span><span class="token punctuation">)</span>    <span class="token keyword">return</span> None<span class="token comment" spellcheck="true"># 设置 usb_mic_index 为自动检测的结果</span>usb_mic_index <span class="token operator">=</span> detect_usb_mic_index<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">if</span> usb_mic_index <span class="token keyword">is</span> None<span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"No suitable USB mic found. Exiting."</span><span class="token punctuation">)</span><span class="token keyword">else</span><span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>f<span class="token string">"Using USB mic at index &amp;#123;usb_mic_index&amp;#125;."</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 获取录音设备索引的函数</span><span class="token keyword">def</span> <span class="token function">detect_usb_mic_index</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Detecting USB mic index..."</span><span class="token punctuation">)</span>    devices <span class="token operator">=</span> PvRecorder<span class="token punctuation">.</span>get_available_devices<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token keyword">if</span> <span class="token operator">not</span> devices<span class="token punctuation">:</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"No audio devices found."</span><span class="token punctuation">)</span>        <span class="token keyword">return</span> None        <span class="token keyword">for</span> index<span class="token punctuation">,</span> device <span class="token keyword">in</span> enumerate<span class="token punctuation">(</span>devices<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">print</span><span class="token punctuation">(</span>f<span class="token string">"Device &amp;#123;index&amp;#125;: &amp;#123;device&amp;#125;"</span><span class="token punctuation">)</span>        <span class="token keyword">if</span> <span class="token string">"Camera"</span> <span class="token keyword">in</span> device<span class="token punctuation">:</span>  <span class="token comment" spellcheck="true"># 自动选择包含 "Camera" 的设备</span>            <span class="token keyword">print</span><span class="token punctuation">(</span>f<span class="token string">"USB Camera found at index &amp;#123;index&amp;#125;."</span><span class="token punctuation">)</span>            <span class="token keyword">return</span> index        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"USB Camera not found."</span><span class="token punctuation">)</span>    <span class="token keyword">return</span> None    <span class="token keyword">def</span> <span class="token function">find_speaker_device</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">global</span> speaker_device    <span class="token keyword">if</span> speaker_device<span class="token punctuation">:</span>        <span class="token comment" spellcheck="true"># 如果设备已经打开，直接返回设备</span>        <span class="token keyword">return</span> speaker_device    result <span class="token operator">=</span> subprocess<span class="token punctuation">.</span>run<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">'aplay'</span><span class="token punctuation">,</span> <span class="token string">'-l'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> stdout<span class="token operator">=</span>subprocess<span class="token punctuation">.</span>PIPE<span class="token punctuation">,</span> text<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>    output <span class="token operator">=</span> result<span class="token punctuation">.</span>stdout    <span class="token comment" spellcheck="true"># 检查 USB 音频设备</span>    <span class="token keyword">if</span> <span class="token string">"USB Audio Device"</span> <span class="token keyword">in</span> output<span class="token punctuation">:</span>        card_index <span class="token operator">=</span> None        <span class="token keyword">for</span> line <span class="token keyword">in</span> output<span class="token punctuation">.</span>splitlines<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token keyword">if</span> <span class="token string">"USB Audio Device"</span> <span class="token keyword">in</span> line<span class="token punctuation">:</span>                card_index <span class="token operator">=</span> line<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">':'</span><span class="token punctuation">,</span> <span class="token string">''</span><span class="token punctuation">)</span>                <span class="token keyword">break</span>        <span class="token keyword">if</span> card_index <span class="token keyword">is</span> <span class="token operator">not</span> None<span class="token punctuation">:</span>            speaker_device <span class="token operator">=</span> f<span class="token string">"plughw:&amp;#123;card_index&amp;#125;,0"</span>            <span class="token keyword">print</span><span class="token punctuation">(</span>f<span class="token string">"Detected USB speaker device: &amp;#123;speaker_device&amp;#125;"</span><span class="token punctuation">)</span>            <span class="token keyword">return</span> speaker_device    <span class="token comment" spellcheck="true"># 检查 audiocodec 设备</span>    <span class="token keyword">if</span> <span class="token string">"audiocodec"</span> <span class="token keyword">in</span> output<span class="token punctuation">:</span>        card_index <span class="token operator">=</span> None        <span class="token keyword">for</span> line <span class="token keyword">in</span> output<span class="token punctuation">.</span>splitlines<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token keyword">if</span> <span class="token string">"audiocodec"</span> <span class="token keyword">in</span> line<span class="token punctuation">:</span>                card_index <span class="token operator">=</span> line<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">':'</span><span class="token punctuation">,</span> <span class="token string">''</span><span class="token punctuation">)</span>                <span class="token keyword">break</span>        <span class="token keyword">if</span> card_index <span class="token keyword">is</span> <span class="token operator">not</span> None<span class="token punctuation">:</span>            speaker_device <span class="token operator">=</span> f<span class="token string">"plughw:&amp;#123;card_index&amp;#125;,0"</span>            <span class="token keyword">print</span><span class="token punctuation">(</span>f<span class="token string">"Detected audiocodec speaker device: &amp;#123;speaker_device&amp;#125;"</span><span class="token punctuation">)</span>            <span class="token keyword">return</span> speaker_device    <span class="token comment" spellcheck="true"># 未找到合适的设备</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"No valid speaker device found."</span><span class="token punctuation">)</span>    <span class="token keyword">return</span> None<span class="token keyword">def</span> <span class="token function">initialize_device</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">"""初始化设备并保持状态"""</span>    <span class="token keyword">global</span> speaker_device    speaker_device <span class="token operator">=</span> find_speaker_device<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">if</span> speaker_device<span class="token punctuation">:</span>        <span class="token keyword">try</span><span class="token punctuation">:</span>            <span class="token comment" spellcheck="true"># 尝试打开设备以保持其状态</span>            subprocess<span class="token punctuation">.</span>run<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">'aplay'</span><span class="token punctuation">,</span> <span class="token string">'-D'</span><span class="token punctuation">,</span> speaker_device<span class="token punctuation">,</span> <span class="token string">'-f'</span><span class="token punctuation">,</span> <span class="token string">'cd'</span><span class="token punctuation">,</span> <span class="token string">'/dev/zero'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> timeout<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> stdout<span class="token operator">=</span>subprocess<span class="token punctuation">.</span>PIPE<span class="token punctuation">,</span> stderr<span class="token operator">=</span>subprocess<span class="token punctuation">.</span>PIPE<span class="token punctuation">)</span>            <span class="token keyword">print</span><span class="token punctuation">(</span>f<span class="token string">"Device &amp;#123;speaker_device&amp;#125; initialized."</span><span class="token punctuation">)</span>        <span class="token keyword">except</span> subprocess<span class="token punctuation">.</span>TimeoutExpired<span class="token punctuation">:</span>            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Device initialization timed out."</span><span class="token punctuation">)</span>        <span class="token keyword">except</span> subprocess<span class="token punctuation">.</span>CalledProcessError <span class="token keyword">as</span> e<span class="token punctuation">:</span>            <span class="token keyword">print</span><span class="token punctuation">(</span>f<span class="token string">"Error initializing device: &amp;#123;e&amp;#125;"</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 初始化设备</span>initialize_device<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># 动态检测环境音量并设置 mindb</span><span class="token keyword">def</span> <span class="token function">detect_environment_volume</span><span class="token punctuation">(</span>duration<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> sample_rate<span class="token operator">=</span><span class="token number">16000</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">"""    检测当前环境音量，并根据环境音量调整 mindb 值。        :param duration: 检测持续时间（秒）    :param sample_rate: 采样率    :return: 动态计算得到的最小声音值    """</span>    recorder <span class="token operator">=</span> PvRecorder<span class="token punctuation">(</span>frame_length<span class="token operator">=</span><span class="token number">512</span><span class="token punctuation">,</span> device_index<span class="token operator">=</span>usb_mic_index<span class="token punctuation">)</span>    recorder<span class="token punctuation">.</span>start<span class="token punctuation">(</span><span class="token punctuation">)</span>    frames <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"开始检测环境音量，请保持安静..."</span><span class="token punctuation">)</span>    <span class="token keyword">for</span> _ <span class="token keyword">in</span> range<span class="token punctuation">(</span>int<span class="token punctuation">(</span>duration <span class="token operator">*</span> sample_rate <span class="token operator">/</span> <span class="token number">512</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        frames<span class="token punctuation">.</span>append<span class="token punctuation">(</span>recorder<span class="token punctuation">.</span>read<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    recorder<span class="token punctuation">.</span>stop<span class="token punctuation">(</span><span class="token punctuation">)</span>        audio_data <span class="token operator">=</span> np<span class="token punctuation">.</span>concatenate<span class="token punctuation">(</span>frames<span class="token punctuation">)</span>    rms <span class="token operator">=</span> np<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span>np<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>np<span class="token punctuation">.</span>square<span class="token punctuation">(</span>audio_data<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    min_volume <span class="token operator">=</span> rms <span class="token operator">*</span> <span class="token number">10</span>  <span class="token comment" spellcheck="true"># 简单转换为适当的 dB 值（这里需要调整具体的转换逻辑）</span>        <span class="token keyword">print</span><span class="token punctuation">(</span>f<span class="token string">"环境音量检测完成，最小声音阈值为: &amp;#123;min_volume&amp;#125;"</span><span class="token punctuation">)</span>    <span class="token keyword">return</span> min_volumemindb <span class="token operator">=</span> detect_environment_volume<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">try</span><span class="token punctuation">:</span>    recorder <span class="token operator">=</span> PvRecorder<span class="token punctuation">(</span>frame_length<span class="token operator">=</span><span class="token number">512</span><span class="token punctuation">,</span> device_index<span class="token operator">=</span>usb_mic_index<span class="token punctuation">)</span>    recorder<span class="token punctuation">.</span>start<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"录音器已启动"</span><span class="token punctuation">)</span>    recorder<span class="token punctuation">.</span>stop<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"录音器已停止"</span><span class="token punctuation">)</span><span class="token keyword">except</span> Exception <span class="token keyword">as</span> e<span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>f<span class="token string">"录音器启动失败: &amp;#123;e&amp;#125;"</span><span class="token punctuation">)</span>    sys<span class="token punctuation">.</span>exit<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 标志位</span>record_type <span class="token operator">=</span> <span class="token number">0</span>  <span class="token comment" spellcheck="true"># 0 未录音 1 按住录音 2 语音唤醒</span>flag <span class="token operator">=</span> <span class="token number">0</span>  <span class="token comment" spellcheck="true"># 是否开始录音 0未开始 1开始 2结束</span>button_timestamp <span class="token operator">=</span> <span class="token number">0</span>mqtt_list <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>play_url_list <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>playing_audio <span class="token operator">=</span> <span class="token boolean">False</span>  <span class="token comment" spellcheck="true"># 是否正在播放音频</span>audio_play_event <span class="token operator">=</span> threading<span class="token punctuation">.</span>Event<span class="token punctuation">(</span><span class="token punctuation">)</span>current_msgId <span class="token operator">=</span> <span class="token number">0</span>new_msgId <span class="token operator">=</span> <span class="token number">0</span>current_play_process <span class="token operator">=</span> Noneaudio_queue <span class="token operator">=</span> queue<span class="token punctuation">.</span>Queue<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">def</span> <span class="token function">stop_current_audio</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">global</span> current_play_process<span class="token punctuation">,</span> audio_play_event    <span class="token keyword">if</span> current_play_process<span class="token punctuation">:</span>        audio_play_event<span class="token punctuation">.</span>set<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 设置事件来通知停止播放</span>        current_play_process<span class="token punctuation">.</span>terminate<span class="token punctuation">(</span><span class="token punctuation">)</span>        current_play_process<span class="token punctuation">.</span>wait<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"已终止当前音频播放"</span><span class="token punctuation">)</span>    audio_play_event<span class="token punctuation">.</span>clear<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 重置事件</span><span class="token keyword">def</span> <span class="token function">download_audio_file</span><span class="token punctuation">(</span>url<span class="token punctuation">,</span> local_filename<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">"""下载音频文件到本地"""</span>    <span class="token keyword">try</span><span class="token punctuation">:</span>        response <span class="token operator">=</span> requests<span class="token punctuation">.</span>get<span class="token punctuation">(</span>url<span class="token punctuation">,</span> stream<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>        <span class="token keyword">if</span> response<span class="token punctuation">.</span>status_code <span class="token operator">==</span> <span class="token number">200</span><span class="token punctuation">:</span>            <span class="token keyword">with</span> open<span class="token punctuation">(</span>local_filename<span class="token punctuation">,</span> <span class="token string">'wb'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>                <span class="token keyword">for</span> chunk <span class="token keyword">in</span> response<span class="token punctuation">.</span>iter_content<span class="token punctuation">(</span>chunk_size<span class="token operator">=</span><span class="token number">8192</span><span class="token punctuation">)</span><span class="token punctuation">:</span>                    f<span class="token punctuation">.</span>write<span class="token punctuation">(</span>chunk<span class="token punctuation">)</span>            <span class="token keyword">print</span><span class="token punctuation">(</span>f<span class="token string">"下载完成: &amp;#123;local_filename&amp;#125;"</span><span class="token punctuation">)</span>            <span class="token keyword">return</span> local_filename        <span class="token keyword">else</span><span class="token punctuation">:</span>            <span class="token keyword">print</span><span class="token punctuation">(</span>f<span class="token string">"下载音频失败，状态码: &amp;#123;response.status_code&amp;#125;"</span><span class="token punctuation">)</span>            <span class="token keyword">return</span> None    <span class="token keyword">except</span> Exception <span class="token keyword">as</span> e<span class="token punctuation">:</span>        <span class="token keyword">print</span><span class="token punctuation">(</span>f<span class="token string">"下载音频时发生错误: &amp;#123;e&amp;#125;"</span><span class="token punctuation">)</span>        <span class="token keyword">return</span> None<span class="token keyword">def</span> <span class="token function">play_audio_file</span><span class="token punctuation">(</span>file_path<span class="token punctuation">,</span> msgId<span class="token operator">=</span>None<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">global</span> current_play_process<span class="token punctuation">,</span> audio_play_event        audio_play_event<span class="token punctuation">.</span>clear<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">if</span> msgId <span class="token keyword">is</span> <span class="token operator">not</span> None<span class="token punctuation">:</span>        <span class="token keyword">try</span><span class="token punctuation">:</span>            msgId <span class="token operator">=</span> int<span class="token punctuation">(</span>msgId<span class="token punctuation">)</span>        <span class="token keyword">except</span> ValueError<span class="token punctuation">:</span>            <span class="token keyword">print</span><span class="token punctuation">(</span>f<span class="token string">"无效的 msgId 值: &amp;#123;msgId&amp;#125;"</span><span class="token punctuation">)</span>            <span class="token keyword">return</span>        <span class="token keyword">print</span><span class="token punctuation">(</span>f<span class="token string">"播放音频: &amp;#123;file_path&amp;#125; (msgId: &amp;#123;msgId&amp;#125;)"</span><span class="token punctuation">)</span>    <span class="token keyword">try</span><span class="token punctuation">:</span>        current_play_process <span class="token operator">=</span> subprocess<span class="token punctuation">.</span>Popen<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">'aplay'</span><span class="token punctuation">,</span> <span class="token string">'-D'</span><span class="token punctuation">,</span> speaker_device<span class="token punctuation">,</span> <span class="token string">'-q'</span><span class="token punctuation">,</span> file_path<span class="token punctuation">]</span><span class="token punctuation">,</span> stdout<span class="token operator">=</span>subprocess<span class="token punctuation">.</span>PIPE<span class="token punctuation">,</span> stderr<span class="token operator">=</span>subprocess<span class="token punctuation">.</span>PIPE<span class="token punctuation">)</span>        <span class="token keyword">while</span> current_play_process<span class="token punctuation">.</span>poll<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">is</span> None<span class="token punctuation">:</span>            <span class="token keyword">if</span> audio_play_event<span class="token punctuation">.</span>is_set<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>                current_play_process<span class="token punctuation">.</span>terminate<span class="token punctuation">(</span><span class="token punctuation">)</span>                current_play_process<span class="token punctuation">.</span>wait<span class="token punctuation">(</span><span class="token punctuation">)</span>                <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"已终止当前音频播放"</span><span class="token punctuation">)</span>                <span class="token keyword">return</span>            time<span class="token punctuation">.</span>sleep<span class="token punctuation">(</span><span class="token number">0.1</span><span class="token punctuation">)</span>        <span class="token keyword">print</span><span class="token punctuation">(</span>f<span class="token string">"播放完成: &amp;#123;file_path&amp;#125; (msgId: &amp;#123;msgId&amp;#125;)"</span><span class="token punctuation">)</span>    <span class="token keyword">except</span> subprocess<span class="token punctuation">.</span>CalledProcessError <span class="token keyword">as</span> e<span class="token punctuation">:</span>        <span class="token keyword">print</span><span class="token punctuation">(</span>f<span class="token string">"播放音频时发生错误: &amp;#123;e&amp;#125;"</span><span class="token punctuation">)</span>    <span class="token keyword">finally</span><span class="token punctuation">:</span>        current_play_process <span class="token operator">=</span> None      <span class="token keyword">def</span> <span class="token function">speech_queue_handler</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">"""处理音频播放队列，确保最新的消息音频优先播放"""</span>    <span class="token keyword">global</span> play_url_list<span class="token punctuation">,</span> current_msgId<span class="token punctuation">,</span> new_msgId    <span class="token keyword">while</span> <span class="token boolean">True</span><span class="token punctuation">:</span>        <span class="token keyword">if</span> play_url_list<span class="token punctuation">:</span>            audio_data <span class="token operator">=</span> play_url_list<span class="token punctuation">.</span>pop<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>            audio_url<span class="token punctuation">,</span> msgId <span class="token operator">=</span> audio_data<span class="token punctuation">[</span><span class="token string">'url'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> audio_data<span class="token punctuation">[</span><span class="token string">'msgId'</span><span class="token punctuation">]</span>            local_file <span class="token operator">=</span> download_audio_file<span class="token punctuation">(</span>audio_url<span class="token punctuation">,</span> <span class="token string">'downloaded_audio.wav'</span><span class="token punctuation">)</span>            <span class="token keyword">if</span> local_file<span class="token punctuation">:</span>                <span class="token keyword">if</span> msgId <span class="token operator">>=</span> current_msgId<span class="token punctuation">:</span>  <span class="token comment" spellcheck="true"># 检查新消息的 msgId</span>                    play_audio_file<span class="token punctuation">(</span>local_file<span class="token punctuation">,</span> msgId<span class="token punctuation">)</span>                <span class="token keyword">if</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>exists<span class="token punctuation">(</span>local_file<span class="token punctuation">)</span><span class="token punctuation">:</span>                    os<span class="token punctuation">.</span>remove<span class="token punctuation">(</span>local_file<span class="token punctuation">)</span>            <span class="token keyword">else</span><span class="token punctuation">:</span>                <span class="token keyword">print</span><span class="token punctuation">(</span>f<span class="token string">"下载音频文件失败，跳过播放。"</span><span class="token punctuation">)</span>        <span class="token keyword">else</span><span class="token punctuation">:</span>            time<span class="token punctuation">.</span>sleep<span class="token punctuation">(</span><span class="token number">0.01</span><span class="token punctuation">)</span>handler_thread <span class="token operator">=</span> threading<span class="token punctuation">.</span>Thread<span class="token punctuation">(</span>target<span class="token operator">=</span>speech_queue_handler<span class="token punctuation">)</span>handler_thread<span class="token punctuation">.</span>start<span class="token punctuation">(</span><span class="token punctuation">)</span>mqtt_client <span class="token operator">=</span> None  <span class="token comment" spellcheck="true"># 全局 MQTT 客户端实例</span><span class="token keyword">def</span> <span class="token function">handle_mqtt_message</span><span class="token punctuation">(</span>message<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">"""自定义处理 MQTT 消息的函数"""</span>    <span class="token keyword">global</span> msgId        cmd_type <span class="token operator">=</span> message<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">"cmd"</span><span class="token punctuation">)</span>        <span class="token keyword">if</span> cmd_type <span class="token operator">==</span> <span class="token string">"text_to_speech"</span><span class="token punctuation">:</span>        <span class="token keyword">if</span> int<span class="token punctuation">(</span>message<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">"msgId"</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">==</span> msgId<span class="token punctuation">:</span>            audio_urls <span class="token operator">=</span> message<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">"data"</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">)</span>            <span class="token keyword">for</span> url <span class="token keyword">in</span> audio_urls<span class="token punctuation">:</span>                local_file <span class="token operator">=</span> download_audio_file<span class="token punctuation">(</span>url<span class="token punctuation">,</span> <span class="token string">'downloaded_audio.wav'</span><span class="token punctuation">)</span>                <span class="token keyword">if</span> local_file<span class="token punctuation">:</span>                    play_audio_file<span class="token punctuation">(</span>local_file<span class="token punctuation">,</span> msgId<span class="token operator">=</span>message<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">"msgId"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token keyword">elif</span> cmd_type <span class="token operator">==</span> <span class="token string">"multi_chat_config"</span><span class="token punctuation">:</span>        wav_url <span class="token operator">=</span> message<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">"data"</span><span class="token punctuation">,</span> <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;&amp;#125;).get("wav_url")</span>        <span class="token keyword">if</span> wav_url<span class="token punctuation">:</span>            local_file <span class="token operator">=</span> download_audio_file<span class="token punctuation">(</span>wav_url<span class="token punctuation">,</span> <span class="token string">'downloaded_audio.wav'</span><span class="token punctuation">)</span>            <span class="token keyword">if</span> local_file<span class="token punctuation">:</span>                play_audio_file<span class="token punctuation">(</span>local_file<span class="token punctuation">,</span> msgId<span class="token operator">=</span>message<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">"msgId"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">def</span> <span class="token function">on_connect</span><span class="token punctuation">(</span>client<span class="token punctuation">,</span> userdata<span class="token punctuation">,</span> flags<span class="token punctuation">,</span> rc<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">"""连接回调函数"""</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Connected with result code "</span> <span class="token operator">+</span> str<span class="token punctuation">(</span>rc<span class="token punctuation">)</span><span class="token punctuation">)</span>    client<span class="token punctuation">.</span>subscribe<span class="token punctuation">(</span>TOPIC<span class="token punctuation">)</span><span class="token keyword">def</span> <span class="token function">on_message</span><span class="token punctuation">(</span>client<span class="token punctuation">,</span> userdata<span class="token punctuation">,</span> msg<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">"""消息处理回调函数"""</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>f<span class="token string">"收到消息: &amp;#123;msg.topic&amp;#125; &amp;#123;str(msg.payload)&amp;#125;"</span><span class="token punctuation">)</span>    <span class="token keyword">try</span><span class="token punctuation">:</span>        message <span class="token operator">=</span> json<span class="token punctuation">.</span>loads<span class="token punctuation">(</span>msg<span class="token punctuation">.</span>payload<span class="token punctuation">.</span>decode<span class="token punctuation">(</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># 调用用户自定义的消息处理回调</span>        <span class="token keyword">if</span> userdata<span class="token punctuation">:</span>            userdata<span class="token punctuation">(</span>message<span class="token punctuation">)</span>    <span class="token keyword">except</span> Exception <span class="token keyword">as</span> e<span class="token punctuation">:</span>        <span class="token keyword">print</span><span class="token punctuation">(</span>f<span class="token string">"解析消息时发生错误: &amp;#123;e&amp;#125;"</span><span class="token punctuation">)</span><span class="token keyword">def</span> <span class="token function">start_mqtt</span><span class="token punctuation">(</span>on_message_callback<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">"""启动 MQTT 客户端"""</span>    <span class="token keyword">global</span> mqtt_client    <span class="token keyword">if</span> mqtt_client <span class="token keyword">is</span> None<span class="token punctuation">:</span>  <span class="token comment" spellcheck="true"># 确保只创建一个 MQTT 客户端实例</span>        mqtt_client <span class="token operator">=</span> mqtt<span class="token punctuation">.</span>Client<span class="token punctuation">(</span><span class="token punctuation">)</span>        mqtt_client<span class="token punctuation">.</span>on_connect <span class="token operator">=</span> on_connect        mqtt_client<span class="token punctuation">.</span>on_message <span class="token operator">=</span> on_message        mqtt_client<span class="token punctuation">.</span>user_data_set<span class="token punctuation">(</span>on_message_callback<span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 设置用户数据</span>        mqtt_client<span class="token punctuation">.</span>connect<span class="token punctuation">(</span>MQTT_SERVER<span class="token punctuation">,</span> MQTT_PORT<span class="token punctuation">,</span> <span class="token number">60</span><span class="token punctuation">)</span>        mqtt_client<span class="token punctuation">.</span>loop_start<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">def</span> <span class="token function">mqtt_queue_handler</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">"""启动 MQTT 队列处理程序"""</span>    start_mqtt<span class="token punctuation">(</span>handle_mqtt_message<span class="token punctuation">)</span>mqtt_queue_handler<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">def</span> <span class="token function">record_handler</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">global</span> button_timestamp<span class="token punctuation">,</span> record_type<span class="token punctuation">,</span> image_id<span class="token punctuation">,</span> take_photo<span class="token punctuation">,</span> msgId    <span class="token keyword">while</span> <span class="token boolean">True</span><span class="token punctuation">:</span>        last_press_time <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">-</span> button_timestamp        <span class="token keyword">if</span> last_press_time <span class="token operator">></span> <span class="token number">0.5</span><span class="token punctuation">:</span>            <span class="token keyword">continue</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"开始录音"</span><span class="token punctuation">)</span>        take_photo <span class="token operator">=</span> <span class="token boolean">True</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"调起拍照程序"</span><span class="token punctuation">)</span>        recorder<span class="token punctuation">.</span>start<span class="token punctuation">(</span><span class="token punctuation">)</span>        frames <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>        flag <span class="token operator">=</span> <span class="token number">0</span>        <span class="token keyword">while</span> <span class="token boolean">True</span><span class="token punctuation">:</span>            last_press_time <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">-</span> button_timestamp            frame <span class="token operator">=</span> recorder<span class="token punctuation">.</span>read<span class="token punctuation">(</span><span class="token punctuation">)</span>            frames<span class="token punctuation">.</span>append<span class="token punctuation">(</span>frame<span class="token punctuation">)</span>            <span class="token keyword">if</span> record_type <span class="token operator">==</span> <span class="token number">1</span><span class="token punctuation">:</span>  <span class="token comment" spellcheck="true"># 按住录音模式</span>                <span class="token keyword">if</span> last_press_time <span class="token operator">></span> debounce_time<span class="token punctuation">:</span>                    <span class="token keyword">break</span>            <span class="token keyword">elif</span> record_type <span class="token operator">==</span> <span class="token number">2</span><span class="token punctuation">:</span>  <span class="token comment" spellcheck="true"># 语音唤醒模式</span>                temp <span class="token operator">=</span> np<span class="token punctuation">.</span>max<span class="token punctuation">(</span>frame<span class="token punctuation">)</span>                <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"当前音量："</span><span class="token punctuation">,</span> temp<span class="token punctuation">)</span>                <span class="token keyword">if</span> flag <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>                    <span class="token keyword">if</span> temp <span class="token operator">></span> mindb<span class="token punctuation">:</span>                        flag <span class="token operator">=</span> <span class="token number">1</span>                        button_timestamp <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span>                    <span class="token keyword">if</span> last_press_time <span class="token operator">></span> waitTime<span class="token punctuation">:</span>                        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"等待超时，自动终止"</span><span class="token punctuation">)</span>                        flag <span class="token operator">=</span> <span class="token number">2</span>                        <span class="token keyword">break</span>                <span class="token keyword">else</span><span class="token punctuation">:</span>                    <span class="token keyword">if</span> temp <span class="token operator">></span> mindb<span class="token punctuation">:</span>                        button_timestamp <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span>                    <span class="token keyword">if</span> last_press_time <span class="token operator">></span> delayTime<span class="token punctuation">:</span>                        <span class="token keyword">break</span>        button_timestamp <span class="token operator">=</span> <span class="token number">0</span>        <span class="token keyword">if</span> flag <span class="token operator">==</span> <span class="token number">2</span><span class="token punctuation">:</span>            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"等待超时，自动终止，不发送文件"</span><span class="token punctuation">)</span>            recorder<span class="token punctuation">.</span>stop<span class="token punctuation">(</span><span class="token punctuation">)</span>            record_type <span class="token operator">=</span> <span class="token number">0</span>            <span class="token keyword">continue</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"* done recording"</span><span class="token punctuation">)</span>        <span class="token keyword">print</span><span class="token punctuation">(</span>msgId<span class="token punctuation">)</span>        recorder<span class="token punctuation">.</span>stop<span class="token punctuation">(</span><span class="token punctuation">)</span>        wf <span class="token operator">=</span> wave<span class="token punctuation">.</span>open<span class="token punctuation">(</span>WAVE_OUTPUT_FILENAME<span class="token punctuation">,</span> <span class="token string">'wb'</span><span class="token punctuation">)</span>        wf<span class="token punctuation">.</span>setnchannels<span class="token punctuation">(</span>RECORD_CHANNELS<span class="token punctuation">)</span>        wf<span class="token punctuation">.</span>setsampwidth<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span>        wf<span class="token punctuation">.</span>setframerate<span class="token punctuation">(</span>RECORD_RATE<span class="token punctuation">)</span>        <span class="token keyword">for</span> frame <span class="token keyword">in</span> frames<span class="token punctuation">:</span>            wf<span class="token punctuation">.</span>writeframes<span class="token punctuation">(</span>np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>frame<span class="token punctuation">,</span> dtype<span class="token operator">=</span>np<span class="token punctuation">.</span>int16<span class="token punctuation">)</span><span class="token punctuation">.</span>tobytes<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        wf<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>        record_type <span class="token operator">=</span> <span class="token number">0</span>        msgId <span class="token operator">+=</span> <span class="token number">1</span>                responsePost <span class="token operator">=</span> requests<span class="token punctuation">.</span>post<span class="token punctuation">(</span>            <span class="token string">'http://openpin3.z33.fun/chatbyvoiceAsync22/'</span><span class="token punctuation">,</span>            files<span class="token operator">=</span><span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;'audio_file': open(WAVE_OUTPUT_FILENAME, 'rb')&amp;#125;,</span>            data<span class="token operator">=</span><span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;</span>                <span class="token string">'devId'</span><span class="token punctuation">:</span> DEV_ID<span class="token punctuation">,</span>                <span class="token string">'nfcId'</span><span class="token punctuation">:</span> <span class="token string">'0'</span><span class="token punctuation">,</span>                <span class="token string">'msgId'</span><span class="token punctuation">:</span> str<span class="token punctuation">(</span>msgId<span class="token punctuation">)</span><span class="token punctuation">,</span>                <span class="token string">'respond_format'</span><span class="token punctuation">:</span> <span class="token string">'wav'</span><span class="token punctuation">,</span>                <span class="token string">'image_id'</span><span class="token punctuation">:</span> image_id            <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#125;</span>        <span class="token punctuation">)</span>        <span class="token keyword">print</span><span class="token punctuation">(</span>responsePost<span class="token punctuation">.</span>json<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        play_audio_file<span class="token punctuation">(</span>file_path<span class="token operator">=</span><span class="token string">'di.wav'</span><span class="token punctuation">,</span> msgId<span class="token operator">=</span>None<span class="token punctuation">)</span><span class="token keyword">def</span> <span class="token function">button_handler</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">global</span> button_timestamp<span class="token punctuation">,</span> record_type    <span class="token keyword">while</span> <span class="token boolean">True</span><span class="token punctuation">:</span>        result <span class="token operator">=</span> subprocess<span class="token punctuation">.</span>run<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">'gpio'</span><span class="token punctuation">,</span> <span class="token string">'read'</span><span class="token punctuation">,</span> <span class="token string">'27'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> capture_output<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> text<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>        <span class="token keyword">if</span> int<span class="token punctuation">(</span>result<span class="token punctuation">.</span>stdout<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>  <span class="token comment" spellcheck="true"># 按钮按下时为低电平</span>            <span class="token keyword">if</span> record_type <span class="token operator">!=</span> <span class="token number">1</span><span class="token punctuation">:</span>                <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'刚按下'</span><span class="token punctuation">)</span>                <span class="token comment" spellcheck="true"># 停止当前音频播放</span>                stop_current_audio<span class="token punctuation">(</span><span class="token punctuation">)</span>            button_timestamp <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span>            record_type <span class="token operator">=</span> <span class="token number">1</span>        time<span class="token punctuation">.</span>sleep<span class="token punctuation">(</span><span class="token number">0.1</span><span class="token punctuation">)</span>            <span class="token keyword">def</span> <span class="token function">update_registration</span><span class="token punctuation">(</span>chinese_name<span class="token punctuation">,</span> english_name<span class="token punctuation">)</span><span class="token punctuation">:</span>    csv_file <span class="token operator">=</span> <span class="token string">'/home/orangepi/program/qiandao/stuinfo.csv'</span>    updated <span class="token operator">=</span> <span class="token boolean">False</span>    <span class="token keyword">try</span><span class="token punctuation">:</span>        <span class="token keyword">with</span> open<span class="token punctuation">(</span>csv_file<span class="token punctuation">,</span> <span class="token string">'r'</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">,</span> errors<span class="token operator">=</span><span class="token string">'ignore'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> file<span class="token punctuation">:</span>            reader <span class="token operator">=</span> list<span class="token punctuation">(</span>csv<span class="token punctuation">.</span>reader<span class="token punctuation">(</span>file<span class="token punctuation">)</span><span class="token punctuation">)</span>            header <span class="token operator">=</span> reader<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>            rows <span class="token operator">=</span> reader<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span>    <span class="token keyword">except</span> Exception <span class="token keyword">as</span> e<span class="token punctuation">:</span>        <span class="token keyword">print</span><span class="token punctuation">(</span>f<span class="token string">"读取文件时出错: &amp;#123;e&amp;#125;"</span><span class="token punctuation">)</span>        <span class="token keyword">return</span>    <span class="token keyword">for</span> row <span class="token keyword">in</span> rows<span class="token punctuation">:</span>        <span class="token keyword">if</span> row<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">==</span> chinese_name <span class="token operator">or</span> row<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span> <span class="token operator">==</span> english_name<span class="token punctuation">:</span>  <span class="token comment" spellcheck="true"># 匹配 ChineseName 或 EnglishName</span>            row<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">'已注册'</span>            updated <span class="token operator">=</span> <span class="token boolean">True</span>    <span class="token keyword">if</span> updated<span class="token punctuation">:</span>        <span class="token keyword">try</span><span class="token punctuation">:</span>            <span class="token keyword">with</span> open<span class="token punctuation">(</span>csv_file<span class="token punctuation">,</span> <span class="token string">'w'</span><span class="token punctuation">,</span> newline<span class="token operator">=</span><span class="token string">''</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> file<span class="token punctuation">:</span>                writer <span class="token operator">=</span> csv<span class="token punctuation">.</span>writer<span class="token punctuation">(</span>file<span class="token punctuation">)</span>                writer<span class="token punctuation">.</span>writerow<span class="token punctuation">(</span>header<span class="token punctuation">)</span>                writer<span class="token punctuation">.</span>writerows<span class="token punctuation">(</span>rows<span class="token punctuation">)</span>            <span class="token keyword">print</span><span class="token punctuation">(</span>f<span class="token string">"已更新 &amp;#123;chinese_name&amp;#125; / &amp;#123;english_name&amp;#125; 的注册状态为已注册。"</span><span class="token punctuation">)</span>        <span class="token keyword">except</span> Exception <span class="token keyword">as</span> e<span class="token punctuation">:</span>            <span class="token keyword">print</span><span class="token punctuation">(</span>f<span class="token string">"写入文件时出错: &amp;#123;e&amp;#125;"</span><span class="token punctuation">)</span>    <span class="token keyword">else</span><span class="token punctuation">:</span>        <span class="token keyword">print</span><span class="token punctuation">(</span>f<span class="token string">"&amp;#123;chinese_name&amp;#125; / &amp;#123;english_name&amp;#125; 没有找到匹配的记录，未更新。"</span><span class="token punctuation">)</span>        <span class="token keyword">def</span> <span class="token function">get_file_content_as_base64</span><span class="token punctuation">(</span>path<span class="token punctuation">,</span> urlencoded<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">task</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">with</span> open<span class="token punctuation">(</span>path<span class="token punctuation">,</span> <span class="token string">"rb"</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>            content <span class="token operator">=</span> base64<span class="token punctuation">.</span>b64encode<span class="token punctuation">(</span>f<span class="token punctuation">.</span>read<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>decode<span class="token punctuation">(</span><span class="token string">"utf8"</span><span class="token punctuation">)</span>            <span class="token keyword">if</span> urlencoded<span class="token punctuation">:</span>                content <span class="token operator">=</span> urllib<span class="token punctuation">.</span>parse<span class="token punctuation">.</span>quote_plus<span class="token punctuation">(</span>content<span class="token punctuation">)</span>            <span class="token keyword">return</span> content    <span class="token keyword">return</span> task<span class="token keyword">def</span> <span class="token function">upload_image_to_baidu</span><span class="token punctuation">(</span>image_base64<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">task</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        url <span class="token operator">=</span> <span class="token string">"https://aip.baidubce.com/rest/2.0/face/v3/multi-search?access_token=24.b6c23d3dcf5623492dfb639a408d9538.2592000.1727015570.282335-106648411"</span>        payload <span class="token operator">=</span> json<span class="token punctuation">.</span>dumps<span class="token punctuation">(</span><span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;</span>            <span class="token string">"group_id_list"</span><span class="token punctuation">:</span> <span class="token string">"group4"</span><span class="token punctuation">,</span>            <span class="token string">"image"</span><span class="token punctuation">:</span> image_base64<span class="token punctuation">,</span>            <span class="token string">"image_type"</span><span class="token punctuation">:</span> <span class="token string">"BASE64"</span><span class="token punctuation">,</span>            <span class="token string">"max_face_num"</span><span class="token punctuation">:</span> <span class="token number">1</span><span class="token punctuation">,</span>            <span class="token string">"match_threshold"</span><span class="token punctuation">:</span> <span class="token number">80</span><span class="token punctuation">,</span>            <span class="token string">"quality_control"</span><span class="token punctuation">:</span> <span class="token string">"NORMAL"</span>        <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#125;)</span>        headers <span class="token operator">=</span> <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;</span>            <span class="token string">'Content-Type'</span><span class="token punctuation">:</span> <span class="token string">'application/json'</span>        <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#125;</span>        response <span class="token operator">=</span> requests<span class="token punctuation">.</span>post<span class="token punctuation">(</span>url<span class="token punctuation">,</span> headers<span class="token operator">=</span>headers<span class="token punctuation">,</span> data<span class="token operator">=</span>payload<span class="token punctuation">)</span>        <span class="token keyword">try</span><span class="token punctuation">:</span>            result <span class="token operator">=</span> response<span class="token punctuation">.</span>json<span class="token punctuation">(</span><span class="token punctuation">)</span>            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"API Response:"</span><span class="token punctuation">,</span> result<span class="token punctuation">)</span>        <span class="token keyword">except</span> json<span class="token punctuation">.</span>JSONDecodeError<span class="token punctuation">:</span>            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"无法解析 JSON 响应。"</span><span class="token punctuation">)</span>            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"响应文本:"</span><span class="token punctuation">,</span> response<span class="token punctuation">.</span>text<span class="token punctuation">)</span>            <span class="token keyword">return</span>        <span class="token keyword">if</span> result<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">"error_code"</span><span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token number">0</span> <span class="token operator">and</span> <span class="token string">"face_list"</span> <span class="token keyword">in</span> result<span class="token punctuation">[</span><span class="token string">"result"</span><span class="token punctuation">]</span><span class="token punctuation">:</span>            <span class="token keyword">for</span> face <span class="token keyword">in</span> result<span class="token punctuation">[</span><span class="token string">"result"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"face_list"</span><span class="token punctuation">]</span><span class="token punctuation">:</span>                <span class="token keyword">if</span> <span class="token string">"user_list"</span> <span class="token keyword">in</span> face <span class="token operator">and</span> len<span class="token punctuation">(</span>face<span class="token punctuation">[</span><span class="token string">"user_list"</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">></span> <span class="token number">0</span><span class="token punctuation">:</span>                    <span class="token keyword">for</span> user <span class="token keyword">in</span> face<span class="token punctuation">[</span><span class="token string">"user_list"</span><span class="token punctuation">]</span><span class="token punctuation">:</span>                        user_info <span class="token operator">=</span> json<span class="token punctuation">.</span>loads<span class="token punctuation">(</span>user<span class="token punctuation">[</span><span class="token string">"user_info"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>                        chinese_name <span class="token operator">=</span> user_info<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">"ChineseName"</span><span class="token punctuation">,</span> <span class="token string">"未知"</span><span class="token punctuation">)</span>                        english_name <span class="token operator">=</span> user_info<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">"EnglishName"</span><span class="token punctuation">,</span> <span class="token string">"未知"</span><span class="token punctuation">)</span>                        <span class="token keyword">print</span><span class="token punctuation">(</span>f<span class="token string">"用户 ID: &amp;#123;user['user_id']&amp;#125;, 中文名: &amp;#123;chinese_name&amp;#125;, 英文名: &amp;#123;english_name&amp;#125;"</span><span class="token punctuation">)</span>                        <span class="token comment" spellcheck="true"># 启动更新注册状态的任务</span>                        update_registration_task_thread <span class="token operator">=</span> threading<span class="token punctuation">.</span>Thread<span class="token punctuation">(</span>target<span class="token operator">=</span>update_registration<span class="token punctuation">,</span> args<span class="token operator">=</span><span class="token punctuation">(</span>chinese_name<span class="token punctuation">,</span> english_name<span class="token punctuation">)</span><span class="token punctuation">)</span>                        update_registration_task_thread<span class="token punctuation">.</span>start<span class="token punctuation">(</span><span class="token punctuation">)</span>                <span class="token keyword">else</span><span class="token punctuation">:</span>                    <span class="token keyword">print</span><span class="token punctuation">(</span>f<span class="token string">"错误: &amp;#123;result.get('error_msg')&amp;#125;"</span><span class="token punctuation">)</span>        <span class="token keyword">else</span><span class="token punctuation">:</span>            <span class="token keyword">print</span><span class="token punctuation">(</span>f<span class="token string">"错误: &amp;#123;result.get('error_msg')&amp;#125;"</span><span class="token punctuation">)</span>    <span class="token keyword">return</span> task<span class="token keyword">def</span> <span class="token function">capture_image_and_upload</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">global</span> image_id<span class="token punctuation">,</span> take_photo    <span class="token keyword">while</span> <span class="token boolean">True</span><span class="token punctuation">:</span>        <span class="token keyword">if</span> <span class="token operator">not</span> take_photo<span class="token punctuation">:</span>            time<span class="token punctuation">.</span>sleep<span class="token punctuation">(</span><span class="token number">0.1</span><span class="token punctuation">)</span>            <span class="token keyword">continue</span>        <span class="token keyword">else</span><span class="token punctuation">:</span>            cap <span class="token operator">=</span> cv2<span class="token punctuation">.</span>VideoCapture<span class="token punctuation">(</span>camera_index<span class="token punctuation">)</span>            ret<span class="token punctuation">,</span> frame <span class="token operator">=</span> cap<span class="token punctuation">.</span>read<span class="token punctuation">(</span><span class="token punctuation">)</span>            <span class="token keyword">if</span> ret<span class="token punctuation">:</span>                image_path <span class="token operator">=</span> <span class="token string">'capture.jpg'</span>                cv2<span class="token punctuation">.</span>imwrite<span class="token punctuation">(</span>image_path<span class="token punctuation">,</span> frame<span class="token punctuation">)</span>                cap<span class="token punctuation">.</span>release<span class="token punctuation">(</span><span class="token punctuation">)</span>                responsePost <span class="token operator">=</span> requests<span class="token punctuation">.</span>post<span class="token punctuation">(</span>                    <span class="token string">'http://openpin3.z33.fun/upload_image22'</span><span class="token punctuation">,</span>                    files<span class="token operator">=</span><span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;'image': open(image_path, 'rb')&amp;#125;,</span>                    data<span class="token operator">=</span><span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;'devId': DEV_ID&amp;#125;</span>                <span class="token punctuation">)</span><span class="token punctuation">.</span>json<span class="token punctuation">(</span><span class="token punctuation">)</span>                image_id <span class="token operator">=</span> responsePost<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">'image_id'</span><span class="token punctuation">)</span>                <span class="token keyword">print</span><span class="token punctuation">(</span>responsePost<span class="token punctuation">)</span>                <span class="token comment" spellcheck="true"># 获取图片的base64编码并上传到百度飞桨API</span>                <span class="token keyword">with</span> ThreadPoolExecutor<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">as</span> executor<span class="token punctuation">:</span>                    base64_future <span class="token operator">=</span> executor<span class="token punctuation">.</span>submit<span class="token punctuation">(</span>get_file_content_as_base64<span class="token punctuation">(</span>image_path<span class="token punctuation">)</span><span class="token punctuation">)</span>                    image_base64 <span class="token operator">=</span> base64_future<span class="token punctuation">.</span>result<span class="token punctuation">(</span><span class="token punctuation">)</span>                    upload_future <span class="token operator">=</span> executor<span class="token punctuation">.</span>submit<span class="token punctuation">(</span>upload_image_to_baidu<span class="token punctuation">(</span>image_base64<span class="token punctuation">)</span><span class="token punctuation">)</span>                    upload_future<span class="token punctuation">.</span>result<span class="token punctuation">(</span><span class="token punctuation">)</span>                            take_photo <span class="token operator">=</span> <span class="token boolean">False</span><span class="token keyword">def</span> <span class="token function">wake_word_handler</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">global</span> record_type<span class="token punctuation">,</span> button_timestamp<span class="token punctuation">,</span> msgId<span class="token punctuation">,</span> take_photo    porcupine_chinese <span class="token operator">=</span> pvporcupine<span class="token punctuation">.</span>create<span class="token punctuation">(</span>        access_key<span class="token operator">=</span><span class="token string">'Slo6YfShQZ5PRQYx5xlUuPAd+M/rGa1UBtHqhL74s9C9GC+Jbu8kww=='</span><span class="token punctuation">,</span>  <span class="token comment" spellcheck="true"># 替换为你的 Access Key</span>        keyword_paths<span class="token operator">=</span><span class="token punctuation">[</span>            <span class="token string">'/home/orangepi/program/xiaosheng.ppn'</span>        <span class="token punctuation">]</span><span class="token punctuation">,</span>        model_path<span class="token operator">=</span><span class="token string">'/home/orangepi/program/porcupine_params_zh.pv'</span><span class="token punctuation">,</span>        sensitivities<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">0.5</span><span class="token punctuation">]</span>    <span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># porcupine_english = pvporcupine.create(</span>    <span class="token comment" spellcheck="true">#     access_key='srMJbguZzBwoUtxKuqmGmymN1Uz4YYwBGPSkv7yPoTkPTAA6nL0lhw==',  # 替换为你的 Access Key</span>    <span class="token comment" spellcheck="true">#     keyword_paths=[</span>    <span class="token comment" spellcheck="true">#         '/home/orangepi/program/HelloNeo.ppn'</span>    <span class="token comment" spellcheck="true">#     ],</span>    <span class="token comment" spellcheck="true">#     sensitivities=[0.4]</span>    <span class="token comment" spellcheck="true"># )</span>    <span class="token keyword">while</span> <span class="token boolean">True</span><span class="token punctuation">:</span>        <span class="token keyword">if</span> record_type <span class="token operator">!=</span> <span class="token number">0</span><span class="token punctuation">:</span>            time<span class="token punctuation">.</span>sleep<span class="token punctuation">(</span><span class="token number">0.1</span><span class="token punctuation">)</span>            <span class="token keyword">continue</span>                recorder<span class="token punctuation">.</span>start<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token keyword">try</span><span class="token punctuation">:</span>            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Listening for wake word..."</span><span class="token punctuation">)</span>            <span class="token keyword">while</span> <span class="token boolean">True</span><span class="token punctuation">:</span>                <span class="token keyword">if</span> record_type <span class="token operator">!=</span> <span class="token number">0</span><span class="token punctuation">:</span>                    <span class="token keyword">break</span>                                audio_frame <span class="token operator">=</span> recorder<span class="token punctuation">.</span>read<span class="token punctuation">(</span><span class="token punctuation">)</span>                                keyword_index_chinese <span class="token operator">=</span> porcupine_chinese<span class="token punctuation">.</span>process<span class="token punctuation">(</span>audio_frame<span class="token punctuation">)</span>                <span class="token keyword">if</span> keyword_index_chinese <span class="token operator">>=</span> <span class="token number">0</span><span class="token punctuation">:</span>                    <span class="token keyword">print</span><span class="token punctuation">(</span>f<span class="token string">"Detected Chinese wake word: &amp;#123;keyword_index_chinese&amp;#125;"</span><span class="token punctuation">)</span>                    recorder<span class="token punctuation">.</span>stop<span class="token punctuation">(</span><span class="token punctuation">)</span>                                        stop_current_audio<span class="token punctuation">(</span><span class="token punctuation">)</span>                                        msgId <span class="token operator">+=</span> <span class="token number">1</span>                    play_audio_file<span class="token punctuation">(</span>file_path<span class="token operator">=</span><span class="token string">'/home/orangepi/program/xiaosheng.wav'</span><span class="token punctuation">,</span> msgId<span class="token operator">=</span>msgId<span class="token punctuation">)</span>                    <span class="token keyword">break</span>                                                    <span class="token comment" spellcheck="true"># keyword_index_english = porcupine_english.process(audio_frame)</span>                <span class="token comment" spellcheck="true"># if keyword_index_english >= 0:</span>                <span class="token comment" spellcheck="true">#     print(f"Detected English wake word: &amp;#123;keyword_index_english&amp;#125;")</span>                <span class="token comment" spellcheck="true">#     recorder.stop()</span>                <span class="token comment" spellcheck="true">#     play_audio_file(file_path='/home/orangepi/program/nio-wozaine.wav')</span>                <span class="token comment" spellcheck="true">#     break</span>                        <span class="token keyword">except</span> IOError <span class="token keyword">as</span> e<span class="token punctuation">:</span>            <span class="token keyword">print</span><span class="token punctuation">(</span>f<span class="token string">"Error reading from recorder: &amp;#123;e&amp;#125;"</span><span class="token punctuation">)</span>        <span class="token keyword">finally</span><span class="token punctuation">:</span>            button_timestamp <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span>            record_type <span class="token operator">=</span> <span class="token number">2</span>capture_task <span class="token operator">=</span> threading<span class="token punctuation">.</span>Thread<span class="token punctuation">(</span>target<span class="token operator">=</span>capture_image_and_upload<span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">"拍照程序"</span><span class="token punctuation">)</span>mqtt_queue_handler_task <span class="token operator">=</span> threading<span class="token punctuation">.</span>Thread<span class="token punctuation">(</span>target<span class="token operator">=</span>mqtt_queue_handler<span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">"mqtt消息处理程序"</span><span class="token punctuation">)</span>speech_queue_handler_task <span class="token operator">=</span> threading<span class="token punctuation">.</span>Thread<span class="token punctuation">(</span>target<span class="token operator">=</span>speech_queue_handler<span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">"播报程序"</span><span class="token punctuation">)</span>button_handler_task <span class="token operator">=</span> threading<span class="token punctuation">.</span>Thread<span class="token punctuation">(</span>target<span class="token operator">=</span>button_handler<span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">"按键处理程序"</span><span class="token punctuation">)</span>record_handler_task <span class="token operator">=</span> threading<span class="token punctuation">.</span>Thread<span class="token punctuation">(</span>target<span class="token operator">=</span>record_handler<span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">"录音程序"</span><span class="token punctuation">)</span>wake_word_handler_task <span class="token operator">=</span> threading<span class="token punctuation">.</span>Thread<span class="token punctuation">(</span>target<span class="token operator">=</span>wake_word_handler<span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">"唤醒词监听程序"</span><span class="token punctuation">)</span>capture_task<span class="token punctuation">.</span>start<span class="token punctuation">(</span><span class="token punctuation">)</span>mqtt_queue_handler_task<span class="token punctuation">.</span>start<span class="token punctuation">(</span><span class="token punctuation">)</span>speech_queue_handler_task<span class="token punctuation">.</span>start<span class="token punctuation">(</span><span class="token punctuation">)</span>button_handler_task<span class="token punctuation">.</span>start<span class="token punctuation">(</span><span class="token punctuation">)</span>record_handler_task<span class="token punctuation">.</span>start<span class="token punctuation">(</span><span class="token punctuation">)</span>wake_word_handler_task<span class="token punctuation">.</span>start<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 等待所有线程完成</span>capture_task<span class="token punctuation">.</span>join<span class="token punctuation">(</span><span class="token punctuation">)</span>mqtt_queue_handler_task<span class="token punctuation">.</span>join<span class="token punctuation">(</span><span class="token punctuation">)</span>speech_queue_handler_task<span class="token punctuation">.</span>join<span class="token punctuation">(</span><span class="token punctuation">)</span>button_handler_task<span class="token punctuation">.</span>join<span class="token punctuation">(</span><span class="token punctuation">)</span>record_handler_task<span class="token punctuation">.</span>join<span class="token punctuation">(</span><span class="token punctuation">)</span>wake_word_handler_task<span class="token punctuation">.</span>join<span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre>]]></content>
      
      
      
        <tags>
            
            <tag> 学习笔记 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Patch-level Routing in MOE：针对局部图像区域分配专家，提高样本效率</title>
      <link href="/2024/05/28/lun-wen-patch-level-routing-in-moe/"/>
      <url>/2024/05/28/lun-wen-patch-level-routing-in-moe/</url>
      
        <content type="html"><![CDATA[<h1 id="Patch-level-Routing：针对局部图像区域分配专家，提高样本效率"><a href="#Patch-level-Routing：针对局部图像区域分配专家，提高样本效率" class="headerlink" title="Patch-level Routing：针对局部图像区域分配专家，提高样本效率"></a>Patch-level Routing：针对局部图像区域分配专家，提高样本效率</h1><ul><li><strong>现代神经网络模型（CNNs）：</strong>在处理大规模数据集时表现出色，但训练这些模型所需的数据和计算资源非常庞大。</li><li><strong>MOE混合专家模型：</strong>通过将输入数据动态分配给一组专家（子模型）中的一个或多个，能够提高计算效率。</li><li><strong>解决思路：</strong>将输入图像分割成若干个patch，每个patch独立地分配给不同的专家。针对图像数据的局部特征进行专家分配，以提高样本效率。</li><li><strong>突出问题：</strong>pMoE证明了为减少所需数量的训练样本，多批次能够提升效果与效率，但其理论来源与实验支撑还不够充分。</li><li><strong>论文贡献：</strong>理论证明分析了pMOE的优势，实际进行实验验证，详细量化其计算复杂度、内存使用与训练时间等方面的优点。</li></ul><hr><h3 id="模型架构："><a href="#模型架构：" class="headerlink" title="模型架构："></a>模型架构：</h3><img src="https://cyan-1314223569.cos.ap-beijing.myqcloud.com/test/image-20240529084952905.png?imageSlim"  width="500" /><h4 id="pMOE示例：卷积神经网络的专家模型"><a href="#pMOE示例：卷积神经网络的专家模型" class="headerlink" title="pMOE示例：卷积神经网络的专家模型"></a>pMOE示例：卷积神经网络的专家模型</h4><ol><li><p><strong>模型架构</strong></p><ul><li><p><strong>专家网络</strong>：pMOE 包含多个专家，每个专家是一个两层的卷积神经网络 (CNN)。每个专家负责处理输入样本的部分图像块。</p></li><li><p><strong>门控单元</strong>：每个专家对应一个可训练的路由门控，决定哪些图像块由哪个专家进行处理。</p></li></ul></li><li><p><strong>工作原理</strong></p><ul><li><strong>图像分块</strong>：先将输入图像（例如狐狸的图片）划分成若干个不重叠的图像块。</li><li><strong>路由选择</strong>：路由器根据图像块的特征值，生成一个评分分布，表示每个专家对每个图像块的适合程度。确保专家仅处理与其相关的图像块，过滤掉与分类无关的图像块。</li><li><strong>特征聚合：</strong>各个专家网络处理完图像块后，会生成相应的特征图。这些特征图会在模型的上层进行聚合，形成最终的特征表示。聚合后的特征用于最终的分类任务，图中展示了最终的分类结果为“狐狸 (Fox)”。</li></ul></li><li><p><strong>训练模式</strong></p><ul><li><strong>分离训练</strong>：首先训练路由器，然后固定路由器参数，训练专家网络。</li><li><strong>联合训练</strong>：同时训练路由器和专家网络，优化整体性能。</li></ul></li><li><p><strong>理论优势</strong></p><ul><li><strong>样本复杂度</strong>：pMOE 在达到相同泛化误差的情况下，所需的训练样本数量显著减少。本篇论文通过理论证明 pMOE 的样本复杂度和模型复杂度均较传统 CNN 模型降低。</li><li><strong>计算效率</strong>：在视觉任务中，pMOE 的训练和推理计算量分别比单一专家模型减少约 20% 和 50%，但仍保持相同的测试精度。</li></ul></li></ol><h4 id="论文贡献：三项主要研究成果"><a href="#论文贡献：三项主要研究成果" class="headerlink" title="论文贡献：三项主要研究成果"></a>论文贡献：三项主要研究成果</h4><ol><li><p>理论验证了只要路由门控向专家发送的补丁数 <code>l</code> 大于某个特定的阈值，pMOE便可降低模型复杂度与计算复杂度。</p><img src="https://cyan-1314223569.cos.ap-beijing.myqcloud.com/test/image-20240529090936527.png?imageSlim"  width="500" /></li><li><p>能够有效提升模型的抗干扰能力，与将图像整体输入的MOE模型相比能够更好地丢弃类无关部分，处理分类任务。由于干扰减少，专家能够更高效地学习，直接导致样本复杂性和模型复杂性的降低。</p></li><li><p>通过实验验证了理论证明。</p></li></ol><h4 id="pMOE模型原理："><a href="#pMOE模型原理：" class="headerlink" title="pMOE模型原理："></a>pMOE模型原理：</h4><img src="https://cyan-1314223569.cos.ap-beijing.myqcloud.com/test/image-20240529092131288.png?imageSlim"  width="500" /><ol><li><strong>pMOE架构</strong>:<ul><li>pMOE模型包括 𝑘 个专家和相应的 𝑘  个路由器。</li><li>每个路由器为每个专家选择 𝑙 中的 𝑛 个patches（𝑙&lt;𝑛<em>l</em>&lt;<em>n</em>）。</li></ul></li><li><strong>路由门控</strong>：<ul><li>每个专家的路由器都包含一个可训练的门控向量 $w_{s}$ ∈ 𝑅𝑑。</li><li>给定一个样本 𝑥，路由器为每个patch 𝑗 计算一个路由值。</li></ul></li><li><strong>专家模型</strong>:<ul><li>每个专家是一个具有相同架构的两层卷积神经网络（CNN）。</li><li>设 𝑚 表示所有专家中的神经元总数。每个专家包含 𝑚&#x2F;𝑘 神经元。</li></ul></li><li><strong>模型定义</strong>:</li></ol><img src="https://cyan-1314223569.cos.ap-beijing.myqcloud.com/test/image-20240529092628373.png?imageSlim"  width="600" /><h4 id="训练方法："><a href="#训练方法：" class="headerlink" title="训练方法："></a>训练方法：</h4><ul><li>三种模型训练方法：</li></ul><img src="https://cyan-1314223569.cos.ap-beijing.myqcloud.com/test/image-20240529093413367.png?imageSlim"  width="500" /><hr><h3 id="思路拓展："><a href="#思路拓展：" class="headerlink" title="思路拓展："></a>思路拓展：</h3><ol><li><strong>文本片段分割分配专家：</strong>类似于图像的patch分割，可以将文本先分割成多个片段，如句子、段落或固定长度的n-grams。将这些文本片段分批独立地送入不同的门控单元，再分配给不同的专家，利用专家的多样性来处理不同类型的文本片段，是否能够提升计算效率和学习速度？</li><li><strong>层级结构专家分配：</strong>文本数据多数具有层级结构，如章节、段落、句子等。是否可以参照Patch-level Routing的方法，设计一种层级结构的专家分配策略，将标题、首段、尾段等分割出来再在不同层级上使用不同的专家？例如，顶层专家处理整体段落或章节，底层专家处理句子或词。</li></ol>]]></content>
      
      
      
        <tags>
            
            <tag> 论文笔记 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MOELoRA: 一种基于MOE多任务医疗应用下的高效参数微调方法</title>
      <link href="/2024/05/18/lun-wen-moelora/"/>
      <url>/2024/05/18/lun-wen-moelora/</url>
      
        <content type="html"><![CDATA[<h1 id="MOELoRA-一种基于-MOE-多任务医疗应用下的高效参数微调方法"><a href="#MOELoRA-一种基于-MOE-多任务医疗应用下的高效参数微调方法" class="headerlink" title="MOELoRA: 一种基于 MOE 多任务医疗应用下的高效参数微调方法"></a>MOELoRA: 一种基于 MOE 多任务医疗应用下的高效参数微调方法</h1><ul><li><strong>医疗领域的LLM微调困境：</strong>①任务多样性太大；②参数量大，微调成本太高</li><li><strong>解决思路：</strong>MOE与LoRA结合，针对特定领域任务进行微调</li><li><strong>突出问题：</strong>不同任务下的数据量在质量、规模上都存在差距（A任务有1000个数据，B任务有5000个数据，使得微调参数会倾向于样本量更大的任务，破坏少样本任务的处理性能。如何解决？）</li></ul><hr><h4 id="模型架构："><a href="#模型架构：" class="headerlink" title="模型架构："></a>模型架构：</h4><ul><li>多个专家作为可训练的参数，其中每个专家由一对低秩矩阵组成，以保持少量的可训练的参数。</li><li>为所有的MOELoRA层提出了一个任务动机的门函数，该函数可以调节每个专家的贡献，并为各种任务生成不同的参数。</li></ul><p><strong>使用MOELoRA对LLM的参数高效微调过程的可视化表示如下：</strong></p><p><img src="https://cyan-1314223569.cos.ap-beijing.myqcloud.com/test/image-20240519223632525.png?imageSlim"></p><ol><li><p><strong>Attention层</strong>：</p><ul><li>包含多头注意力机制的标准组件，其中Q（Query）、K（Key）、V（Value）各自通过LoRA适配器进行增强。</li><li>每个Q、K、V矩阵都通过MOE-LoRA增强，即每个矩阵都分别有专门的LoRA专家进行调整。</li><li>这些LoRA专家由底部的门控（Gate）单元动态选择，门控根据输入的任务ID决定激活哪些专家。</li></ul></li><li><p><strong>Layer Norm和Add层</strong>：</p><ul><li><p>Transformer架构中的每个子层输出后都会经过一个添加（Add）和层归一化（Layer Norm）操作。</p></li><li><p>在此架构中，W表示权重矩阵，包括由MoE-LoRA微调的参数。</p></li></ul></li><li><p><strong>Gate单元</strong>：</p><ul><li><p>根据输入的任务ID（如文档底部所示），决定哪些LoRA专家参与当前任务的计算。</p></li><li><p>确保每个特定任务都能调用最适合它的专家组合，从而实现高效的任务特定微调。</p></li></ul></li><li><p><strong>训练与固定权重</strong>：</p><ul><li>图中用火焰符号标注的权重（W）是可训练的，而用雪花符号标注的是固定的，表明在微调过程中这部分权重不会被更新。</li></ul></li></ol><hr><h4 id="MOELoRA层："><a href="#MOELoRA层：" class="headerlink" title="MOELoRA层："></a>MOELoRA层：</h4><p><img src="https://cyan-1314223569.cos.ap-beijing.myqcloud.com/test/image-20240519225817161.png?imageSlim"></p><ul><li><p>每个专家都被替换为了一个低秩矩阵相乘的形式</p></li><li><p>任务 $T_{j}$ 样本的线性层与MOELoRA层配对的前向过程表示为：</p></li></ul><p><img src="https://cyan-1314223569.cos.ap-beijing.myqcloud.com/test/image-20240519230406663.png?imageSlim"></p><hr><h4 id="任务驱动的门控单元："><a href="#任务驱动的门控单元：" class="headerlink" title="任务驱动的门控单元："></a>任务驱动的门控单元：</h4><p>权重计算公式：</p><p><img src="https://cyan-1314223569.cos.ap-beijing.myqcloud.com/test/image-20240519231110060.png?imageSlim"></p><ul><li>任务驱动的门函数为每个任务产生一组<strong>独特</strong>的贡献权值</li></ul><p><img src="https://cyan-1314223569.cos.ap-beijing.myqcloud.com/test/image-20240519231241393.png?imageSlim"></p><p>如果门函数是由输入向量x驱动的，权向量将在样本之间有所不同。因此只将任务身份输入到门函数中，这意味着每个样本都将拥有其独特的ωj，从而导致一个特定于样本的微调参数矩阵。<em>（这个地方有点不太理解……？）</em></p><ol><li><strong>任务定制：</strong>每个任务都使用一组参数进行微调，这有助于学习更多特定于任务的信息，缓解数据不平衡的问题。</li><li><strong>推理效率：</strong>检索到的微调LLM显示出减少的推理延迟。这是由于消除了与LoRA层相关的额外正向计算的需要。</li></ol><hr><h4 id="算法实现过程："><a href="#算法实现过程：" class="headerlink" title="算法实现过程："></a>算法实现过程：</h4><p><img src="https://cyan-1314223569.cos.ap-beijing.myqcloud.com/test/image-20240519231739537.png?imageSlim"></p>]]></content>
      
      
      
        <tags>
            
            <tag> 论文笔记 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MOE混合专家模型架构</title>
      <link href="/2024/05/08/xue-xi-moe-hun-he-zhuan-jia-mo-xing/"/>
      <url>/2024/05/08/xue-xi-moe-hun-he-zhuan-jia-mo-xing/</url>
      
        <content type="html"><![CDATA[<h2 id="MOE-混合专家模型"><a href="#MOE-混合专家模型" class="headerlink" title="MOE 混合专家模型"></a>MOE 混合专家模型</h2><ul><li>与稠密模型相比， <strong>预训练速度更快</strong></li><li>与具有相同参数数量的模型相比，具有更快的 <strong>推理速度</strong></li><li>需要 <strong>大量显存</strong>，因为所有专家系统都需要加载到内存中</li><li>在 <strong>微调方面存在诸多挑战</strong>，但对混合专家模型进行 <strong>指令调优具有很大的潜力</strong>。</li></ul><hr><h4 id="模型架构："><a href="#模型架构：" class="headerlink" title="模型架构："></a>模型架构：</h4><p>MOE是一种基于Transformer架构的模型，主要由两个部分组成：</p><ul><li><strong>稀疏 MoE 层</strong>: 取代传统 Transformer 模型中的前馈网络 (FFN) 层。MoE 层包含若干“专家模型”，每个专家本身是一个独立的神经网络。在实际应用中，这些专家通常是前馈网络 (FFN)，也可以是更复杂的网络结构，甚至可以是 MoE 层本身，从而形成层级式的 MoE 结构。</li><li><strong>门控网络单元</strong>: 决定哪些令牌 (token) 被发送到哪个专家。例如，在下图中，“More”这个 <code>token</code> 可能被发送到第二个专家，而“Parameters”这个 <code>token</code> 被发送到第一个专家。有时，一个 <code>token</code> 甚至可以被发送到多个专家。门控单元的设计是 MoE 使用中的一个关键点，与网络的其他部分一同进行预训练。</li></ul><p><img src="C:\Users\86133\AppData\Roaming\Typora\typora-user-images\image-20240508171027413.png"></p><p>其中，门控网络通常是一个带有Softmax的简单网络，学习将输入发送给哪一个专家的分类。</p><p><img src="C:\Users\86133\AppData\Roaming\Typora\typora-user-images\image-20240508171640190.png"></p><p>所有专家模型都会对所有输入进行运算，但通过门控网络的输出进行加权乘法操作。</p><p><img src="C:\Users\86133\AppData\Roaming\Typora\typora-user-images\image-20240508171722067.png"></p><h4 id="数据需求："><a href="#数据需求：" class="headerlink" title="数据需求："></a>数据需求：</h4><p>对于MOE模型，数据的质量比数据数量更重要。多个专家模型的训练需要确保有涵盖每一个领域的大量数据作为支撑，专家 gating network 也需要分配平衡。故而常需要一个分类器质检，确保数据的质量。</p><p>MOE的更多参数也意味着我们需要更多数据去训练。</p><h4 id="并行训练："><a href="#并行训练：" class="headerlink" title="并行训练："></a>并行训练：</h4><p>MOE在训练中可以采用数据并行或模型并行的训练方法。</p><p><strong>· 数据并行：</strong>多个显卡对同一个MOE（参数一致），每个显卡进行不同的专家模型训练。将数据并行地发送到MOE之中，实现数据并行训练。</p><p><strong>· 模型并行：</strong>将MOE的多个专家拆到多个显卡当中，依次输入相关参数，但每次可能会索引到其它卡的专家模型之中，故而需要卡间通信。</p><p><img src="C:\Users\86133\AppData\Roaming\Typora\typora-user-images\image-20240508172345121.png"></p>]]></content>
      
      
      
        <tags>
            
            <tag> 学习笔记 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>LoRA微调原理</title>
      <link href="/2024/05/07/xue-xi-lora-wei-diao-yuan-li/"/>
      <url>/2024/05/07/xue-xi-lora-wei-diao-yuan-li/</url>
      
        <content type="html"><![CDATA[<h2 id="Lora-微调原理"><a href="#Lora-微调原理" class="headerlink" title="Lora 微调原理"></a>Lora 微调原理</h2><blockquote><p>大语言模型微调算法</p></blockquote><hr><p><strong>基本原理：</strong>低秩矩阵相乘升维，与预训练权重矩阵叠加，实现模型微调</p><p><strong>原理简述：</strong>冻结预训练的模型参数，然后在Transfomer的每一层中加入一个可训练的旁路矩阵（低秩可分离矩阵），接着将旁路输出与初始路径输出相加输入到网络当中。在训练的时候，只训练这些新增的低秩矩阵的参数。其中低秩矩阵由两个矩阵组成，第一个矩阵负责降维，第二个矩阵负责升维，中间层维度为r，两个低秩矩阵能够大幅度减小参数量。</p><p><img src="C:\Users\86133\AppData\Roaming\Typora\typora-user-images\image-20240508103941588.png"></p><p><strong>原理解释：</strong></p><p>输入为<code>x</code>，输出为<code>h</code>，预训练模型：</p><p>$h&#x3D;W_{0}x$</p><p>在全参数量上微调（regular finetuning）：</p><p>$h&#x3D;W_{0}x+△Wx$</p><p>如果采用低秩可分离矩阵（LoRA），则：<br>$$h&#x3D;W_{0}x+△Wx&#x3D;W_{0}x+BAx $$</p><p>在这个过程中，最核心的步骤便是将 $△W$ 进行分解，将其分解为两个低秩矩阵。如果只使用单独的一个矩阵，那么参数量为 $$d<em>d$$，如果使用低秩可分离矩阵，此时原来的大矩阵可分解为两个秩为 $r$ 的大小为 $$d</em>r$$ 的小矩阵，参数量大小为 ，由于 $$r&lt;d$$ 所以可以大幅度减少参数量。</p><p>即：*<em>A矩阵采用一个 $$d</em>r$$ 矩阵，B矩阵采用一个 $$r<em>d$$ 矩阵，总参数量 $$2r</em>d$$ **</p><p><strong>公式推导：</strong></p><p>LoRA 作用形式：$W&#x3D;W_{plm}+aW_{lora}&#x3D;W_{plm}+aB_{lora_{zeros}}*A_{lora_{gaussian}}$</p><p>论文中，将 LoRA 作用在 Query 与 Value 权重矩阵上效果最好：</p><p><code>attention query</code> 映射矩阵：$W_{q}&#x3D;W_{q_{plm}}+aW_{q_{lora}}$</p><p><code>attention value</code> 映射矩阵：$W_{v}&#x3D;W_{v_{plm}}+aW_{v_{lora}}$</p><p><img src="C:\Users\86133\AppData\Roaming\Typora\typora-user-images\image-20240508141215200.png"></p><p><code>Attention</code> 计算结果：</p><p>$head&#x3D;softmax(Q,K)XW&#x3D;softmax(Q,K)X(W_{v_{plm}}+aX<em>W_{v_{lora}})&#x3D;softmax(Q,K)XW_{v_{plm}}+a</em>softmax(Q,K)XW_{v_{lora}}$</p><hr><p><strong>低秩分解：</strong></p><p>· 如何实现低秩分解？</p><p>低秩分解是一种将矩阵分解为低秩近似的技术。在LORA中，我们使用低秩矩阵来编码参数增量。假设我们有一个预训练的权重矩阵，它的维度是高的。我们可以将<strong>这个矩阵分解为两个低秩矩阵的乘积</strong>，例如：$$W&#x3D; UV^T$$其中U 和V是低秩矩阵。</p><pre class=" language-text"><code class="language-text">##矩阵中，row2 = row1 * 2，row3 = row1*3，也就是说，矩阵中的每一行，都可以通过第一行线性表示。A = [[1, 2, 3],[2, 4, 6],[3, 6, 9]]#任意一行，总可以用其他两行的线性组合来表示。B = [[1, 2, 3],   [7, 11, 5],[8, 13, 8]]#任意一行，都不能从其余行的线性组合中推导而来。C = [[1, 0, 0],[0, 1, 0],[0, 0, 1]]#求解秩：A = np.array(A)B = np.array(B)C = np.array(C) print("Rank of A:", np.linalg.matrix_rank(A)) # 1print("Rank of B:", np.linalg.matrix_rank(B)) # 2print("Rank of C:", np.linalg.matrix_rank(C)) # 3# 对矩阵A来说，由于只要掌握其中的任意一行，其余行都可以由这一行线性推导而来，因此A的秩是1。# 对矩阵B来说，由于只要掌握其中的任意两行，其余行都可以由这两行线性组合推导而来，因此B的秩是2。# 对矩阵C来说，由于必须完全掌握三行，才能得到完整的C，因此C的秩是3。# 简单理解一下，秩表示的是矩阵的信息量。#如果矩阵中的某一维，总可以通过其余维度线性推导而来，那么对模型来说，#这一维的信息是冗余的，是重复表达的。#对A和B的情况，我们称为秩亏（rank deficient），#对C的情况，我们称为满秩（full rank）。</code></pre><p>· 对A矩阵，采用随机高斯初始化；对B矩阵，采用zero初始化。这样做的原因是要<strong>保证梯度更新有效。</strong></p><p><img src="C:\Users\86133\AppData\Roaming\Typora\typora-user-images\image-20240508142401355.png"></p><p>$ℎ_{𝑖}^{(2)}$ 是输出向量 $h$ 的第 $i$ 个元素，$B_{i,k}$ 是矩阵 $B$ 的元素，$A_{i,k}$ 是矩阵 $A$ 的元素，而 $x_{j}$ 是输入向量 $x$ 的第 $j$ 个元素。</p><p>计算权重 $B$ 中元素 $B_{i,k}$ 的偏导数来进行梯度下降。固定 $i$ 和 $k$，对所有的 $j$ 进行求和，将 $A$ 的对应元素与输入向量的元素相乘并累加。</p><p>$B_{i,k}$ 的每个更新都是由 $x$ 和 $A$ 的对应元素的乘积影响的，故而对A矩阵，采用随机高斯初始化；对B矩阵，采用zero初始化。</p>]]></content>
      
      
      
        <tags>
            
            <tag> 学习笔记 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>水手与海</title>
      <link href="/2024/04/19/wen-ji-shui-shou-yu-hai/"/>
      <url>/2024/04/19/wen-ji-shui-shou-yu-hai/</url>
      
        <content type="html"><![CDATA[<h1 id="水手与海"><a href="#水手与海" class="headerlink" title="水手与海"></a>水手与海</h1><hr><p>从狼奔豕突和闪闪发光的漫游者之间变换的林中猎手的梦中醒来，迎面是咸腥的海风和刚刚降下风帆的帆船。</p><p>在船只与陆地之间有零星的水手正在搬运货物，古铜色虬扎的皮肤诉说着海上曾经的波涛惊骇。</p><p>你伫立在原地，水手打量着你，远比一件货品来得匆匆。</p><p>你上前礼貌地询问方位，时间几何，来处归途，你描述模糊记忆里的那不勒斯，希冀从他人口中获得吉光片羽真实的引线。</p><p>有些人熟视无睹，有的水手向你摇头拒绝交谈，有的人留下只言片语，也有人停下来同你攀谈，你一一道谢。</p><p>你得到了一些讯息，此处远离内陆，少有人烟，与你所见并无二致。而停泊的帆船很快就要再度起航，返航前往尚算和平的王国城都。</p><p>在城郭高高的城墙被水泥钢筋乃至鲜血浇灌垒砌之前，恶龙突破重重防守，掠走王国的明珠，为王国上空覆下浓重的阴影。</p><p>——恶龙。那并不是一个人的梦魇，扇动着看不见的死亡之翼，伴随着诡秘的雾气，恶龙掀翻船只，向海底献上众人的遗骨。</p><p>水手止了声音，眼里蒙上一层海雾般的阴翳。</p><p>像想起征战的英雄，往日的故友，更甚是早逝的小女儿。</p><p>他最终调转了话头，询问你的来时去往。</p><hr><p>一番交谈后，你表示希望一同搭乘船只前往遥远的王国，记忆里的那不勒斯与水手口中描述的城郭并无二致。但摸遍浑身上下，却有些尴尬地发现自己身上并无分文。</p><p>你于是捧出了那颗宝石。</p><p>“你……”</p><p>水手看向你，起了个话头，最终却什么也没说。他应允了你上船的请求，却没有收下那枚宝石。</p><p>“你认识一个……紫色眼睛的旅行者吗？”</p><p>“不……没什么。”</p><p>在即将开口的时候，他却摇摇头，示意你不用再向他传达你的回答。</p><p>你默然。</p><p>自冲角看向向船尾高悬的船灯，主桅旁的舱室壁上搁靠着一人高细长的桨船和数量不菲的木桶。</p><p>当最后一缕残阳没入海平面，船长发号施令，舵手掌握方向，水手们扬起船帆，将锚拉回甲板上。</p><p>跟随者罗盘的指引，船只谨慎地沿着海岸线行驶。</p><hr><p>接连几天都是好天气，海面上风平浪静。</p><p>这段时日来，你一直在船上做一些力所能及的事，譬如搬抬重物，值夜，更甚是哄小孩儿入睡。</p><p>当夜幕降下的时候，小孩子纷纷被传唤进船舱内。“勇士”收起了长剑，自己掖好了被角。“恶龙”也归了巢，久久不肯入眠，拉着大人的衣角请求一个甜蜜的睡前故事。</p><p>船上讲述的睡前故事虽夜夜相似，但如同摇篮上的床铃，会在梦境里变幻着绮丽的花样。</p><p>“故事的一开始是毁坏一切的邪恶巨龙，灾难的降临，流离失所的人们，弥漫的硝烟和灼热的泪水。”</p><p>“那我也会和爸爸妈妈分开吗？”</p><p>重复的故事也会衍化出千百个为什么，而当干净得只有渴求着答案的目光望向你时，第一时间，你难以拒绝。</p><p>有时候孩子会像这样小心翼翼地问。</p><p>“一定不会分开。”</p><p>“那我会和克鲁鲁分开吗？”</p><p>孩子的眼睫颤动着，小声地再度确认。</p><p>你没有再做出回应。</p><p>孩子的母亲向你传达的故事的终局，在孩子的枕席边，睡梦之前——溪流总会重新流动，鲜花将于暖春盛放，思乡者终会重归故土。</p><p>勇者历经重重磨难，必然战胜恶龙，救回公主。</p><p>你摸了摸孩子的头，没有多做解释，只是慢慢将希望倾吐于唇齿之间。</p><p>“勇者踏上讨伐恶龙的征途，勇者帮助了形形色色的人，勇者历经了千辛万苦。”</p><p>“就勇者一个人吗？”</p><p>“他孤身一人。”</p><p>你顿了顿，像是在咀嚼故事中那位英雄的奋战史——</p><p>“勇者并不鲁莽行事，他虽然勇敢，却从未冲动。”</p><hr><p>夜色渐浓，舱室外越发安静，只有风声和潺潺的水声依旧。所有在甲板上工作的成年人逐渐变得无精打采，身体逐渐变得僵冷。而正在此刻，甲板上升起了低低的歌声。</p><p>歌声从四面透风的船长室传来，在甲板上盘旋，舵手用低沉的嗓音唱着一首小调。</p><p><del>在汪洋的怀抱深处，躺着我们的故乡。游荡的船只知晓她的存在，他们唱着歌儿离开这里，归来时亦在海滩上吟唱</del></p><p><del>她被一群平凡之人所深深爱着，死在她怀里的人们也依旧爱她。流浪旅人在汪洋徜徉，梦魂却在她的边界游荡，谁会忘记她？我们的故乡</del></p><p><del>在旅途中出生的孩子，未曾见过她的容颜，却仍追寻海岸线。不愿割舍的她携着海风，亦将新生儿爱抚</del></p><p>这并不是一首搏击浪潮的海洋之歌，而是一首莼鲈之思的缱倦乡曲。思念着远方厚重的泥土，无论我们身在何处，星辰之下抑或大海之上。</p><p>值夜的水手们默默挺起了脊背，先是一个人，接着两个，三个……一起轻轻哼唱。</p><p>歌声浮在甲板上，船室将它隔绝，此时母亲们的摇篮曲刚落下最后一个音节，有些未完的睡前故事也进行到最后一段。</p><p>“恶龙从巢穴中苏醒，转身向着勇者咆哮，声音震耳欲聋。”</p><p>“勇者面向恶龙，守卫着背后的家园，高举起象征着勇气与正义的勇者之剑。”</p><p>“勇者说道：”</p><p>“‘大陆的花朵将重新绽放，公主将回归王国，而你，恶龙，将死于我的剑下。’”</p><p>如同幼猫酣睡一般心满意足，孩子们安然落入英雄和鲜花的梦之旅中。</p><hr><p>怒号的狂风和热情的涌流陆续带走了“她”的一部分。</p><p>浪潮裹挟着一部分的“她”奔向远方，又有一部分的“她”被风所吹散。</p><p>海水捧着扬帆的船只，一部分的“她”不断下沉，沉到陈年船骸的怀里，船骸的金色桅杆斜斜地竖着，无数的珍宝在海底寂静无声。</p><p>时间流淌着，现世的人们从不回头，“她”漂浮于水面之上，在半空中徘徊，分散继而又聚拢，“她”无法仅凭借自己的力量鼓动风帆，游魂并不是真正的自由。</p><p>“她”是否在等待着什么？是还有什么未竟之事吗？以至于被束缚于此，以致于在漫长的轮回里徜徉，灵魂久久不灭。</p><p>——最后一部分的“她”，打着旋，拂过旅行者的发梢，追逐着一个个远望的目光，一张张模糊的面影。</p><p>但“她”总不能停驻太久，她只能借助风声和浪潮拍打的声音，祈祷般为所见之人祝福着，与那思乡的曲调相合。</p>]]></content>
      
      
      
        <tags>
            
            <tag> 文集 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>NovelAI生成绘画素材</title>
      <link href="/2024/04/14/xue-xi-novelai-shi-yong-xin-de/"/>
      <url>/2024/04/14/xue-xi-novelai-shi-yong-xin-de/</url>
      
        <content type="html"><![CDATA[<h1 id="NovelAI-生成-CG-素材"><a href="#NovelAI-生成-CG-素材" class="headerlink" title="NovelAI 生成 CG 素材"></a>NovelAI 生成 CG 素材</h1><p>近期在尝试制作的Unity游戏项目需要一些CG素材，由于实在缺乏资金向画师约稿……所以这边就想着用NovelAI或者Midjourney这样的AI绘画工具来生成一些令人满意的素材~</p><p>试了一下，还是NovelAI的生成效果比较好。不过用起来也很麻烦呀，需要去调整很多东西，改一些参数，合理选择<code>Tag</code>才能保证产图的效果。</p><p>在这个过程中，也可以学到一些调参方面的经验吧，大概。</p><hr><blockquote><p><strong>登录已有的NovelAI网页资源</strong></p></blockquote><p>XianYun Web：<a href="https://nai3.xianyun.cool/main#/gen_img">https://nai3.xianyun.cool/main#/gen_img</a></p><p>不建议用NovelAI官网提供的版本……之前试着用过，效果并不如一些整合后的资源网所能提供的效果好。</p><h3 id="一、界面介绍"><a href="#一、界面介绍" class="headerlink" title="一、界面介绍"></a>一、界面介绍</h3><p><img src="https://cyan-1314223569.cos.ap-beijing.myqcloud.com/test/NovelAI%E7%95%8C%E9%9D%A2%E5%9B%BE.jpg?imageSlim"></p><p><strong>主绘图界面主要分为三部分：Prompts编辑、绘制次数设定、绘图参数调整。</strong></p><h4 id="Prompts编辑"><a href="#Prompts编辑" class="headerlink" title="Prompts编辑"></a>Prompts编辑</h4><p>在<code>Prompts</code>编辑界面，主要是<code>Tag</code>的选取。选取<code>Tag</code>对图像质量有着不可忽略的指导作用，一定要确保<code>Tag</code>符合自己的要求标准。</p><ol><li><code>Tag</code>必须是英文输入，以”,”为间隔。实际上输入语言文本也能够进行生成，不过不太建议这样做。（虽然不太清楚它的文本序列<code>Encoder-Decoder</code>怎么设置的，应该是从一串文本序列里识别到特定的标签然后拿标签进行指导生成？）可以用上面自带的内容翻译进行中英互译。</li><li><code>Tag</code>里的括号表示加权，对某一个提示词的指导权重进行加强，直白点就是围绕这个提示词的生成效果变得更重。</li><li>如果不知道该用哪些提示词比较好，可以在左侧的<code>Tag</code>编辑器里预选一些可参考的提示词。</li><li>可以在<code>Tag</code>里指导生成图像所选用的画师画风。格式为”artist: xxx”，只要是模型预训练过的画师数据都可以进行指导生成。</li><li>词条笔记本、上传词条、随机<code>Tag</code>这些，日常使用很少用到，不作详述。</li></ol><h4 id="绘图参数调整"><a href="#绘图参数调整" class="headerlink" title="绘图参数调整"></a>绘图参数调整</h4><p>在调参界面，可以设定模型绘制的一些参数。一般来说都不必刻意去进行更改。</p><p><strong>长宽设置：</strong><code>Width</code>和<code>Height</code>可以指定生成的图像大小比例，特定分辨率需要勾选启用分辨率才能应用生成。一般来说要增加图像的长宽像素的话，需要更多的显存。大尺度的图像一致性会随着分辨率的提高而变差（模型是在 512x512 的基础上训练的）。非常小的值（例如 256 像素）也会降低图像质量。</p><p><strong>采样器设置：</strong>目前好用的有 <code>Euler</code>，<code>Euler a</code>（更细腻），和 <code>DDIM</code>。推荐 <code>Euler a</code> 和 <code>DDIM</code>，**新手推荐使用 <code>Euler a</code>**。</p><p><code>Euler a</code> 富有创造力，不同步数可以生产出不同的图片。调太高步数 (&gt;30) 效果不会更好。</p><p><code>DDIM</code> 收敛快，但效率相对较低，因为需要很多 step 才能获得好的结果，<strong>适合在重绘时候使用</strong></p><p><code>LMS</code> 和 <code>PLMS</code> 是 <code>Euler</code> 的衍生，它们使用一种相关但稍有不同的方法（平均过去的几个步骤以提高准确性）。大概 30 step 可以得到稳定结果</p><p><code>PLMS</code> 是一种有效的 LMS（经典方法），可以更好地处理神经网络结构中的奇异性</p><p><code>DPM2</code> 是一种神奇的方法，它旨在改进 DDIM，减少步骤以获得良好的结果。它需要每一步运行两次去噪，它的速度大约是 DDIM 的两倍。但是如果你在进行调试提示词的实验，这个采样器效果不怎么样……</p><p><code>Euler</code> 是最简单的，因此也是最快的之一。（搬运自AiDraw的文档指导~）</p><p>※ <code>Steps</code>一般不要设置得太少，毕竟是基于Stable Diffusion降噪生成图像。但设置得太高也会徒增生成时间。一般来说拉到28就够了。</p><h4 id="绘制次数设定"><a href="#绘制次数设定" class="headerlink" title="绘制次数设定"></a>绘制次数设定</h4><p>简单易懂，设定一次绘制多少幅画。</p><h3 id="二、拓展功能"><a href="#二、拓展功能" class="headerlink" title="二、拓展功能"></a>二、拓展功能</h3><p>除了最重要的NovelAI绘图部分，网站还设定了许多额外的拓展功能可供使用。</p><h4 id="图像超分辨率"><a href="#图像超分辨率" class="headerlink" title="图像超分辨率"></a>图像超分辨率</h4><p><img src="https://cyan-1314223569.cos.ap-beijing.myqcloud.com/test/NovelAI-%E5%9B%BE%E5%83%8F%E8%B6%85%E5%88%86%E8%BE%A8%E7%8E%87.jpg?imageSlim"></p><p>如果对生成的图像清晰度要求比较高，可以在这里对图像进行清晰化缩放。</p><p>一般来说，选择<code>SwinIR_4x</code>放大算法就够用啦。</p><h4 id="Tag编辑器"><a href="#Tag编辑器" class="headerlink" title="Tag编辑器"></a>Tag编辑器</h4><p><img src="https://cyan-1314223569.cos.ap-beijing.myqcloud.com/test/NovelAI-Tag%E7%BC%96%E8%BE%91.jpg?imageSlim"></p><p>如果对绘画功能的提示词<code>Tag</code>设置不明晰的话，可以借助<code>Tag</code>编辑器辅助选择<code>Tag</code>。</p><p>预设提供的<code>Tag</code>标签有很多，随心所欲搭配直到生成令人满意的结果吧。</p><p>除此之外，还有<strong>图像反推Tag</strong>、<strong>图像Tag识别</strong>两项功能，从提供的图像中识别出对应的标签（可能是基于CLIP模型做的吧？之前读<code>Diffu Musk</code>论文的时候读到过类似功能的实现方法）。</p><hr><p>总的来说，差不多就是这样啦。之前看很多大佬通过NovelAI搭配出了非常好看的生成效果，现在自己也试着尝试一下吧。干什么都不容易哇，仅仅是利用AI进行一个生成，想要得到好的结果也需要很多学习和努力。</p><p>姑且自己设置提示词生成了一点素材，后续再挑拣一些后期修改放到Unity项目里吧：</p><p><img src="https://cyan-1314223569.cos.ap-beijing.myqcloud.com/test/2bdb3aa480d5d437ac1a44f83ddd795.png?imageSlim"></p>]]></content>
      
      
      
        <tags>
            
            <tag> 学习笔记 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>在Linux服务器上升级Python版本</title>
      <link href="/2024/03/11/xue-xi-linux-fu-wu-qi-shang-sheng-ji-python-ban-ben/"/>
      <url>/2024/03/11/xue-xi-linux-fu-wu-qi-shang-sheng-ji-python-ban-ben/</url>
      
        <content type="html"><![CDATA[<h1 id="在-Linux-服务器上升级-Python-版本"><a href="#在-Linux-服务器上升级-Python-版本" class="headerlink" title="在 Linux 服务器上升级 Python 版本"></a>在 Linux 服务器上升级 Python 版本</h1><p>近段时间在用导师给的服务器跑项目，所以升级了一下 Python 版本。这里分享下自己在升级 Python 时的流程和遇到的一些问题~</p><p>参考博客：<a href="https://blog.csdn.net/Jxq_IT/article/details/103971862">https://blog.csdn.net/Jxq_IT/article/details/103971862</a></p><hr><blockquote><p><strong>直接更新系统Python版本</strong></p></blockquote><h4 id="一、查看系统中的Python版本"><a href="#一、查看系统中的Python版本" class="headerlink" title="一、查看系统中的Python版本"></a>一、查看系统中的Python版本</h4><p>我的服务器是 Ubuntu 18.04.6 版本，之前预装的 Python 版本是 3.7.13，由于论文需要，故要升级到 3.10 版本。首先我们用如下指令查看当前系统的 Python 版本：</p><ol><li><p>使用<code>Python</code>或<code>Python3</code>命令：</p><pre class=" language-text"><code class="language-text">python --versionpython3 --version</code></pre></li><li><p>直接查看<code>bin</code>文件夹下安装的 Python 目录：</p><pre class=" language-text"><code class="language-text">ls /usr/bin/python*</code></pre></li></ol><h4 id="二、利用wget下载对应版本的Python包"><a href="#二、利用wget下载对应版本的Python包" class="headerlink" title="二、利用wget下载对应版本的Python包"></a>二、利用wget下载对应版本的Python包</h4><ol><li><p>在当前的目录下，安装 Python 包。指令如下：</p><pre class=" language-text"><code class="language-text">wget https://www.python.org/ftp/python/3.10.13/Python-3.10.13.tgz</code></pre></li><li><p>上传服务器并解压缩：</p><pre class=" language-text"><code class="language-text">tar -xf Python-3.10.13.tgz</code></pre></li><li><p>进入解压缩后的文件夹，并编译：</p><pre class=" language-text"><code class="language-text">./configure && make && make install</code></pre></li></ol><p><img src="https://cyan-1314223569.cos.ap-beijing.myqcloud.com/test/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E5%9B%BE_1.jpg?imageSlim" alt="Python官网的相关版本"></p><p>网址：<a href="https://www.python.org/downloads/source/">https://www.python.org/downloads/source/</a></p><p><strong>编译结束后，正常情况下会装到&#x2F;usr&#x2F;local&#x2F;bin目录下，记得去看一下！</strong></p><p><img src="https://cyan-1314223569.cos.ap-beijing.myqcloud.com/test/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E5%9B%BE_2.jpg?imageSlim"></p><h4 id="三、创建软连接"><a href="#三、创建软连接" class="headerlink" title="三、创建软连接"></a>三、创建软连接</h4><ol><li><p>首先检查系统是否已经有 <code>python3、python </code>的软链接，可以使用以下命令：</p><pre class=" language-text"><code class="language-text">ls -l /usr/bin/python3ls -l /usr/bin/python</code></pre></li><li><p>删除现有软连接，并创建新的软连接指向<code>Python 3.10</code>：</p><pre class=" language-text"><code class="language-text">sudo rm /usr/bin/python3sudo rm /usr/bin/pythonsudo ln -s /usr/local/bin/python3.10 /usr/bin/python3sudo ln -s /usr/local/bin/python3.10 /usr/bin/pythonsudo ln -sf /usr/local/bin/python3.10-config /usr/bin/python-config</code></pre></li></ol><p>​※注意，如果已经是root用户的话，不需要加sudo哦</p><h4 id="四、检查环境变量"><a href="#四、检查环境变量" class="headerlink" title="四、检查环境变量"></a>四、检查环境变量</h4><p>要运行一下 <code>echo $PATH</code> 来查看当前的 <code>PATH</code> 设置，确保 <code>/usr/bin</code>（或存放了 Python 3.10 软链接的目录）在任何可能包含旧 Python 版本的目录之前。否则的话，执行<code>python --version</code>仍然会显示之前的版本！</p><pre class=" language-text"><code class="language-text">export PATH=/usr/bin:$PATH</code></pre><p>执行这个命令，暂时将将 <code>/usr/bin</code> 移到 <code>PATH</code> 的前面。</p><p>最后，再运行一遍<code>python --version</code>来检查。如果还是不行，试试用<code>hash -r</code>清除一下bash的缓存，或重新打开 shell 会话。</p><blockquote><p><strong>使用Conda管理Python版本</strong></p></blockquote><p>使用Conda来进行管理的话，操作起来就方便多啦。当然你需要先保证系统里预装了Conda。</p><pre class=" language-text"><code class="language-text">conda create -n myenv python=3.10conda activate myenv</code></pre><p>这样会创建一个名为 <code>myenv</code> 的新环境，其中安装了 <code>Python 3.10</code>，然后激活这个环境。</p><p>如果 <code>conda activate</code> 命令提示不能正确使用，按它的提示来，初始化一下 Conda 对 shell 的支持：</p><pre class=" language-text"><code class="language-text">conda init bash</code></pre><hr><p>好的，以上就是我的解决过程啦！希望能够帮到你~⁽(◍˃̵͈̑ᴗ˂̵͈̑)⁽</p>]]></content>
      
      
      
        <tags>
            
            <tag> 学习笔记 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>2024-新春寄语</title>
      <link href="/2024/02/10/sui-bi-2024-xin-chun-ji-yu/"/>
      <url>/2024/02/10/sui-bi-2024-xin-chun-ji-yu/</url>
      
        <content type="html"><![CDATA[<h1 id="2024-新春寄语"><a href="#2024-新春寄语" class="headerlink" title="2024-新春寄语"></a>2024-新春寄语</h1><hr><p>现在的烟花款式变得越来越多啦，造型和花型也都越来越漂亮，有点变相地羡慕小侄子们嘞。</p><p>小时候总在期待着的放烟花的活动，到现在这个年纪，早已不执着于那份纯真的趣味，仅仅只会欣赏烟火绽放瞬间夺目的光点。点燃它们的乐趣就给侄子们享受啦。</p><p>曾经的快乐总会伴着时光慢慢地在心里改变。随着自身的成长，每年的长度也都不尽相同。或许十年之后，一年之期和现在也不会再是同样的感受。</p><p>所以，好好把握当下吧！多陪伴身边的人，用双手掬起流淌在掌心的岁月。人生漫漫，每一年都无比珍重，每一刻都独特耀眼。<br>新年快乐！</p><p>愿新的一年里，也能怀揣这份小小的幸福，度过每一日的一点一滴。</p><p><img src="https://cyan-1314223569.cos.ap-beijing.myqcloud.com/test/2024.jpg?imageSlim"></p>]]></content>
      
      
      
        <tags>
            
            <tag> 随笔 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>トレイル（小径）</title>
      <link href="/2023/10/26/wen-ji-xiao-jing/"/>
      <url>/2023/10/26/wen-ji-xiao-jing/</url>
      
        <content type="html"><![CDATA[<h1 id="トレイル（小径）——cover-mamenoi"><a href="#トレイル（小径）——cover-mamenoi" class="headerlink" title="トレイル（小径）——cover.mamenoi"></a>トレイル（小径）——cover.mamenoi</h1><hr><p>掩埋在纯白细沙里的脚尖</p><p>海风在耳边轻轻诉说</p><p>眼前蔓延的青蓝色</p><p>睁开眼那是多么耀眼的光芒</p><p>至今只在书中领略过的光彩</p><p>无法估计的色温量</p><p>深深印在眼底的圆影</p><hr><p>唯有海浪知晓那从未被翻过的扉页</p><p>我们不曾知晓尚未往复重现的历史</p><p>我们并肩仰望的星</p><p>繁星中的某一颗必定是我们的小船</p><p>触及到的这盏灯火</p><p>是多少年月前的产物呢</p><p>浅浅的记忆渐渐流逝</p><p>触及到的全部此刻化作证明</p><p>黑夜最终消散在天空</p><p>带来了全新的黎明</p><hr><p>那并不是理所当然</p><p>聆听声音</p><p>停下脚步</p><p>世上竟有如此撼人心弦的景色</p><p>不如上前追问</p><p>即便明知就算询问也不会有答案</p><hr><p>我们又能否找到呢</p><p>就像是掬起一片小小的希望般——</p>]]></content>
      
      
      
        <tags>
            
            <tag> 文集 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>写在前面</title>
      <link href="/2023/10/11/preface-my-daliy-life-xie-zai-qian-mian/"/>
      <url>/2023/10/11/preface-my-daliy-life-xie-zai-qian-mian/</url>
      
        <content type="html"><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><hr><p>自从上了大学之后，越来越觉得自己的懒癌愈发难以医治。每天的日常片段除了手机里混杂着各种信息的网络帖子，剩下的也就是刷刷视频、看看漫画之类的娱乐手段。虽然正经的学业、工作也有在努力，但思来想去，总觉得这样的日常生活实在缺乏乐趣。总得给自己找点儿什么有意思的事，丰富一下自己的生活色彩吧？</p><p>抱着这样的想法，我就搭建了这个属于自己的博客网页。每当自己突然来点什么想法，或者干出来什么有意思的事情的时候，就用文字把它们记录下来放到这里。就像初高中的时候大家总有那么一两个小笔记本，上面涂涂画画几页勾线都是自己的心路痕迹。</p><p>其实写博客就是调理生活的调味剂吧，常记录自己的经历与思考，自然也就能更多地发现那些值得品味的地方。况且有了这个念想在，也就会更多地在生活中发掘自己的思考——“这件事&#x2F;这个想法也许可以记下来呢”，我常常会有这样的念头冒出来。</p><p>回想起高中那会儿，那时候的自己还有点文学情怀（虽然各类文学作品都不甚了解，顶多算找到点儿文字乐趣），加上高中语文老师的要求，就有一个所谓“积累本”，用来记录整理从各个途径里获得的那些有价值的文字。想来老师的意思是让我们积累些作文素材，以便填补些高考时肚子里的墨水来用。不过我倒是直接把它当成了类似日记本一样的存在，那时候喜欢文字，也喜欢自己写一些东西，就索性直接也把自己写的东西都放在上面。</p><p>那可能就是我最初的“个人博客”了吧，当然自己的文笔并不算出色，也只能随便写写供自己翻看。</p><p>总而言之，我想是时候留下一点痕迹供以后的自己翻找回味啦。随着年龄增长也越发体会到时间流逝的加速，今年与明年也往往不再是同样的长度。这个空间不保留完美的人生范本，只收集属于自己的原生态切片。希望以后的自己能够坚持在这里留下印记。</p><p>这些文字既是写给自己的路标，也企盼着它能荡起别处某个人心里的涟漪。我常以为这世间的一切种种归根结底都是情感的传递，若某个句子也激起了你的共鸣，欢迎留下你的回声。期待着我们之间有一个共时性的瞬间绽放。</p>]]></content>
      
      
      
        <tags>
            
            <tag> 随笔 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
