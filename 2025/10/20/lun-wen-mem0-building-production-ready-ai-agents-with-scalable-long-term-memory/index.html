<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Mem0：Building Production-Ready AI Agents with Scalable Long-Term Memory, HTML,CSS,JavaScript,JQuery,React,Vue,js等">
    <meta name="description" content="Mem0 是 Agent Memory 领域的经典作，针对现有 Agent 系统依赖上下文短期记忆，而对长期记忆优化不足的问题，设计了一种记忆组织与维护架构。同时一并提出基于知识图谱的 Mem0g。">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Mem0：Building Production-Ready AI Agents with Scalable Long-Term Memory | Cyan&#39;s Blog</title>
    <link rel="icon" type="image/png" href="/favicon.png">
    


    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/css/matery.css">
<link rel="stylesheet" type="text/css" href="/css/my.css">
<link rel="stylesheet" type="text/css" href="/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/css/post.css">




    
        <link rel="stylesheet" type="text/css" href="/css/reward.css">
    



    <script src="/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 6.3.0"><link rel="stylesheet" href="/css/prism-tomorrow.css" type="text/css"></head>


<body>
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/" class="waves-effect waves-light">
                    
                    <img src="/medias/logo.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Cyan&#39;s Blog</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/contact" class="waves-effect waves-light">
      
      <i class="fas fa-comments" style="zoom: 0.6;"></i>
      
      <span>留言板</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="深色/浅色模式" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/medias/logo.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Cyan&#39;s Blog</div>
        <div class="logo-desc">
            
            个人博客
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/contact" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-comments"></i>
			
			留言板
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/blinkfox/hexo-theme-matery" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/blinkfox/hexo-theme-matery" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://cyan-1314223569.cos.ap-beijing.myqcloud.com/test/Pasted%20image%2020251019220421.png')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Mem0：Building Production-Ready AI Agents with Scalable Long-Term Memory</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/tags/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/">
                                <span class="chip bg-color">论文笔记</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2025-10-20
                </div>
                

                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp;
                    3.4k
                </div>
                

                

                
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <p>原文链接：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2504.19413">https://arxiv.org/abs/2504.19413</a></p>
<h3 id="Background-Motivation"><a href="#Background-Motivation" class="headerlink" title="Background &amp; Motivation"></a>Background &amp; Motivation</h3><p>论文针对现有 Agent 系统记忆能力有限，从而导致长时间对话时，容易忘记过去的信息或是给出错误解答的问题，尝试设计一种记忆架构来维护一个“记忆库”，从而帮助 Agent 在每次解决问题时，能够调用已有记忆解决问题，并能不断更新记忆。</p>
<p><img src="https://cyan-1314223569.cos.ap-beijing.myqcloud.com/test/Pasted%20image%2020251019220041.png" alt="缺乏记忆机制与具备记忆机制的 Agent 系统对比"></p>
<p>为了弥补这一缺陷，本文提出了 <strong>Mem0</strong>，一种记忆架构，它能够动态地提取和整合对话中的关键信息，让 AI 系统能记住重要内容并跨会话持续对话。进一步，论文还提出了 <strong>Mem0g</strong>，在 Mem0 的基础上加入了知识图谱，构建图结构记忆。</p>
<h3 id="Method"><a href="#Method" class="headerlink" title="Method"></a>Method</h3><h4 id="Mem0"><a href="#Mem0" class="headerlink" title="Mem0"></a>Mem0</h4><p><strong>Mem0</strong> 的架构核心在于记忆提取与记忆更新机制，旨在确保 AI 系统能够动态地提取对话中的关键信息，并有效地更新其记忆库。这个过程分为两个主要阶段：<strong>记忆提取（Extraction）</strong> 和 <strong>记忆更新（Update）</strong>。</p>
<p><img src="https://cyan-1314223569.cos.ap-beijing.myqcloud.com/test/Pasted%20image%2020251019220421.png" alt="Mem0 的整体架构图"></p>
<h5 id="提取阶段"><a href="#提取阶段" class="headerlink" title="提取阶段"></a>提取阶段</h5><p>当系统接收到一个新的消息对（如用户提问和AI回答）时，提取阶段便会启动。为了准确理解当前对话的上下文，系统会结合两种信息源：</p>
<ul>
<li><strong>全局上下文</strong>：从数据库中检索的整个对话的摘要 $S$，提供对话的宏观主题。</li>
<li><strong>局部上下文</strong>：最近消息序列 ${m_{t-m},…,m_{t-2}}$。</li>
</ul>
<p>组合成一个完整的提示（prompt）<strong>P</strong>，输入给LLM实现的抽取函数 <strong>ϕ</strong>。LLM会基于这些信息，抽取出本轮对话中值得记忆的关键信息（如“用户是素食主义者”），形成一组候选记忆。</p>
<p>在摘要生成阶段，会采用一个异步生成模块。当新的对话消息进入系统后，指导大模型根据对话信息生成摘要：</p>
<pre class=" language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">_create_procedural_memory</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> messages<span class="token punctuation">,</span> metadata<span class="token operator">=</span>None<span class="token punctuation">,</span> prompt<span class="token operator">=</span>None<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""
    # 异步摘要生成模块：创建程序化记忆（会话摘要）
    # 该函数接收对话消息，使用LLM生成一个摘要，并将其存储为特殊类型的记忆
    
    Args:
        messages (list): 待处理的对话消息列表
        metadata (dict): 存储元数据信息
        prompt (str, optional): 自定义提示词，默认使用系统提示
    """</span>
    logger<span class="token punctuation">.</span>info<span class="token punctuation">(</span><span class="token string">"Creating procedural memory"</span><span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># 1. 构建系统提示和用户消息，用于指导LLM生成摘要</span>
    parsed_messages <span class="token operator">=</span> <span class="token punctuation">[</span>
        <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;"role": "system", "content": prompt or PROCEDURAL_MEMORY_SYSTEM_PROMPT&amp;#125;,</span>
        <span class="token operator">*</span>messages<span class="token punctuation">,</span>
        <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;</span>
            <span class="token string">"role"</span><span class="token punctuation">:</span> <span class="token string">"user"</span><span class="token punctuation">,</span>
            <span class="token string">"content"</span><span class="token punctuation">:</span> <span class="token string">"Create procedural memory of the above conversation."</span><span class="token punctuation">,</span>
        <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#125;,</span>
    <span class="token punctuation">]</span>

    <span class="token keyword">try</span><span class="token punctuation">:</span>
        <span class="token comment" spellcheck="true"># 2. 使用LLM生成对话的摘要记忆</span>
        procedural_memory <span class="token operator">=</span> self<span class="token punctuation">.</span>llm<span class="token punctuation">.</span>generate_response<span class="token punctuation">(</span>messages<span class="token operator">=</span>parsed_messages<span class="token punctuation">)</span>
    <span class="token keyword">except</span> Exception <span class="token keyword">as</span> e<span class="token punctuation">:</span>
        logger<span class="token punctuation">.</span>error<span class="token punctuation">(</span>f<span class="token string">"Error generating procedural memory summary: &amp;#123;e&amp;#125;"</span><span class="token punctuation">)</span>
        <span class="token keyword">raise</span>

    <span class="token keyword">if</span> metadata <span class="token keyword">is</span> None<span class="token punctuation">:</span>
        <span class="token keyword">raise</span> ValueError<span class="token punctuation">(</span><span class="token string">"Metadata cannot be done for procedural memory."</span><span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># 3. 标记这是一个程序化记忆（会话摘要）</span>
    metadata<span class="token punctuation">[</span><span class="token string">"memory_type"</span><span class="token punctuation">]</span> <span class="token operator">=</span> MemoryType<span class="token punctuation">.</span>PROCEDURAL<span class="token punctuation">.</span>value
    
    <span class="token comment" spellcheck="true"># 4. 为摘要生成向量嵌入</span>
    embeddings <span class="token operator">=</span> self<span class="token punctuation">.</span>embedding_model<span class="token punctuation">.</span>embed<span class="token punctuation">(</span>procedural_memory<span class="token punctuation">,</span> memory_action<span class="token operator">=</span><span class="token string">"add"</span><span class="token punctuation">)</span>
    
    <span class="token comment" spellcheck="true"># 5. 创建记忆并存储在向量数据库中</span>
    memory_id <span class="token operator">=</span> self<span class="token punctuation">.</span>_create_memory<span class="token punctuation">(</span>procedural_memory<span class="token punctuation">,</span> <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;procedural_memory: embeddings&amp;#125;, metadata=metadata)</span>
    capture_event<span class="token punctuation">(</span><span class="token string">"mem0._create_procedural_memory"</span><span class="token punctuation">,</span> self<span class="token punctuation">,</span> <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;"memory_id": memory_id, "sync_type": "sync"&amp;#125;)</span>

    <span class="token comment" spellcheck="true"># 6. 返回创建的记忆结果</span>
    result <span class="token operator">=</span> <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;"results": [&amp;#123;"id": memory_id, "memory": procedural_memory, "event": "ADD"&amp;#125;]&amp;#125;</span>

    <span class="token keyword">return</span> result
</code></pre>
<p>Mem0 会将 <strong>会话摘要</strong> 和 <strong>最近消息</strong> 结合起来（很常见的全局和局部信息结合的思想），与当前的新消息（用户和助手的最新一轮对话）一起，生成一个 <strong>综合提示（P）</strong>。这个提示会被送入一个<strong>提取函数</strong>，通过大语言模型（LLM）来处理和提取出一组 <strong>候选记忆（Ω）</strong>。这些候选记忆是与当前对话相关的关键信息，用于后续更新知识库中的记忆。</p>
<pre class=" language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">_add_to_vector_store</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> messages<span class="token punctuation">,</span> metadata<span class="token punctuation">,</span> filters<span class="token punctuation">,</span> infer<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""
    提取记忆功能：处理消息并提取记忆事实
    该函数实现了记忆的提取和存储过程
    """</span>
    <span class="token comment" spellcheck="true"># 如果不需要生成记忆片段，则直接存储原始消息(按原样存储)</span>
    <span class="token keyword">if</span> <span class="token operator">not</span> infer<span class="token punctuation">:</span>
        returned_memories <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        <span class="token keyword">for</span> message <span class="token keyword">in</span> messages<span class="token punctuation">:</span>
            <span class="token keyword">if</span> message<span class="token punctuation">[</span><span class="token string">"role"</span><span class="token punctuation">]</span> <span class="token operator">!=</span> <span class="token string">"system"</span><span class="token punctuation">:</span>
                message_embeddings <span class="token operator">=</span> self<span class="token punctuation">.</span>embedding_model<span class="token punctuation">.</span>embed<span class="token punctuation">(</span>message<span class="token punctuation">[</span><span class="token string">"content"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">"add"</span><span class="token punctuation">)</span>
                memory_id <span class="token operator">=</span> self<span class="token punctuation">.</span>_create_memory<span class="token punctuation">(</span>message<span class="token punctuation">[</span><span class="token string">"content"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> message_embeddings<span class="token punctuation">,</span> metadata<span class="token punctuation">)</span>
                returned_memories<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;"id": memory_id, "memory": message["content"], "event": "ADD"&amp;#125;)</span>
        <span class="token keyword">return</span> returned_memories

    <span class="token comment" spellcheck="true"># 1. 解析对话消息，形成上下文</span>
    parsed_messages <span class="token operator">=</span> parse_messages<span class="token punctuation">(</span>messages<span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># 2. 构建提示，使用最近消息窗口作为上下文</span>
    <span class="token keyword">if</span> self<span class="token punctuation">.</span>config<span class="token punctuation">.</span>custom_fact_extraction_prompt<span class="token punctuation">:</span>
        system_prompt <span class="token operator">=</span> self<span class="token punctuation">.</span>config<span class="token punctuation">.</span>custom_fact_extraction_prompt
        user_prompt <span class="token operator">=</span> f<span class="token string">"Input:\n&amp;#123;parsed_messages&amp;#125;"</span>
    <span class="token keyword">else</span><span class="token punctuation">:</span>
        system_prompt<span class="token punctuation">,</span> user_prompt <span class="token operator">=</span> get_fact_retrieval_messages<span class="token punctuation">(</span>parsed_messages<span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 提取记忆的system prompt自己看源码吧，比较长这里就不贴了</span>

    <span class="token comment" spellcheck="true"># 3. 使用LLM提取事实（候选记忆）</span>
    response <span class="token operator">=</span> self<span class="token punctuation">.</span>llm<span class="token punctuation">.</span>generate_response<span class="token punctuation">(</span>
        messages<span class="token operator">=</span><span class="token punctuation">[</span>
            <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;"role": "system", "content": system_prompt&amp;#125;,</span>
            <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;"role": "user", "content": user_prompt&amp;#125;,</span>
        <span class="token punctuation">]</span><span class="token punctuation">,</span>
        response_format<span class="token operator">=</span><span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;"type": "json_object"&amp;#125;,</span>
    <span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># 4. 解析LLM输出，获取候选记忆</span>
    <span class="token keyword">try</span><span class="token punctuation">:</span>
        response <span class="token operator">=</span> remove_code_blocks<span class="token punctuation">(</span>response<span class="token punctuation">)</span>
        new_retrieved_facts <span class="token operator">=</span> json<span class="token punctuation">.</span>loads<span class="token punctuation">(</span>response<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token string">"facts"</span><span class="token punctuation">]</span>  <span class="token comment" spellcheck="true"># 候选记忆列表</span>
    <span class="token keyword">except</span> Exception <span class="token keyword">as</span> e<span class="token punctuation">:</span>
        logging<span class="token punctuation">.</span>error<span class="token punctuation">(</span>f<span class="token string">"Error in new_retrieved_facts: &amp;#123;e&amp;#125;"</span><span class="token punctuation">)</span>
        new_retrieved_facts <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        
    <span class="token comment" spellcheck="true"># 5. 准备从向量数据库检索相似记忆，以便后续进行更新决策</span>
    retrieved_old_memory <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    new_message_embeddings <span class="token operator">=</span> <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;&amp;#125;</span>
    <span class="token keyword">for</span> new_mem <span class="token keyword">in</span> new_retrieved_facts<span class="token punctuation">:</span>
        <span class="token comment" spellcheck="true"># 为每个候选记忆生成向量嵌入</span>
        messages_embeddings <span class="token operator">=</span> self<span class="token punctuation">.</span>embedding_model<span class="token punctuation">.</span>embed<span class="token punctuation">(</span>new_mem<span class="token punctuation">,</span> <span class="token string">"add"</span><span class="token punctuation">)</span>
        new_message_embeddings<span class="token punctuation">[</span>new_mem<span class="token punctuation">]</span> <span class="token operator">=</span> messages_embeddings
        <span class="token comment" spellcheck="true"># 检索向量数据库中与候选记忆语义相似的现有记忆</span>
        existing_memories <span class="token operator">=</span> self<span class="token punctuation">.</span>vector_store<span class="token punctuation">.</span>search<span class="token punctuation">(</span>
            query<span class="token operator">=</span>new_mem<span class="token punctuation">,</span>
            vectors<span class="token operator">=</span>messages_embeddings<span class="token punctuation">,</span>
            limit<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span>
            filters<span class="token operator">=</span>filters<span class="token punctuation">,</span>
        <span class="token punctuation">)</span>
        <span class="token comment" spellcheck="true"># 收集相似的现有记忆</span>
        <span class="token keyword">for</span> mem <span class="token keyword">in</span> existing_memories<span class="token punctuation">:</span>
            retrieved_old_memory<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;"id": mem.id, "text": mem.payload["data"]&amp;#125;)</span>
</code></pre>
<p>提取出的候选记忆并不会被直接存入数据库，而是会进入更新阶段，以确保记忆库的一致性和无冗余。该过程通过一个智能的“工具调用（Tool Call）”机制实现，具体流程如下：</p>
<p><img src="https://cyan-1314223569.cos.ap-beijing.myqcloud.com/test/Pasted%20image%2020251019221554.png"></p>
<p>Mem0 首先会检索出与候选记忆语义最相似的若干个现有记忆(向量数据库向量检索)。然后通过function call的形式调用记忆更新工具来更新记忆。工具有4个：</p>
<ul>
<li><strong>ADD</strong>：如果候选记忆是全新的信息，则添加。</li>
<li><strong>UPDATE</strong>：如果候选记忆是对现有信息的补充或更新，则进行修改。</li>
<li><strong>DELETE</strong>：如果候选记忆与现有信息相矛盾，则删除旧信息。</li>
<li><strong>NOOP</strong>：如果候选记忆是重复或无关的，则不执行任何操作。</li>
</ul>
<p>当现有记忆与新提取的候选记忆存在冲突时，Mem0 会决定是否删除、更新或添加新记忆。</p>
<h4 id="Mem0g"><a href="#Mem0g" class="headerlink" title="Mem0g"></a>Mem0g</h4><p><img src="https://cyan-1314223569.cos.ap-beijing.myqcloud.com/test/Pasted%20image%2020251019221749.png" alt="Mem0g 基本架构图"></p>
<p><strong>Mem0g</strong> 引入了传统知识图谱的思想来增强其对复杂关系的处理能力。与 Mem0 主要通过文本和摘要来管理记忆不同，Mem0g 通过三元组方式将记忆存储为头节点、尾节点和关系边的图，这种结构能更好地捕捉了不同实体之间的关系。同样是两个阶段（提取和更新）。</p>
<p>以图 $G&#x3D;(V,E,L)$ 建模记忆（实体、关系、Label）</p>
<p>首先通过一个<strong>实体提取模块</strong>从对话中识别出所有相关的实体（例如人物、地点、事件等）及实体类别。随后，系统会通过<strong>关系生成模块</strong>根据对话上下文建立实体之间的关系，形成一组三元组（如实体 A 、实体 B及关系 R）。这些三元组也就组成了一个记忆知识图谱。</p>
<p>Mem0g在抽取实体和关系的时候就是用<strong>大模型+prompt</strong>完成，没有用传统nlp中实体识别或者关系抽取的方法。并且，它是采用<strong>两阶段</strong>完成，即先实体抽取，再关系生成。</p>
<p>每个entity（node）包含三部分信息：</p>
<ul>
<li>entity type classification：用于标记这个实体属于哪一类  </li>
<li>embedding vector：实体语义含义的向量表示，便于后续做语义相似度检索和推理  </li>
<li>metadata： 主要包括创建时间戳（creation timestamp），用于记录这个实体被加入知识图谱的时间，有助于时序推理</li>
</ul>
<pre class=" language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">MemoryGraph</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> config<span class="token punctuation">:</span> MemoryConfig <span class="token operator">=</span> MemoryConfig<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""
        知识图谱记忆模块初始化
        负责实体提取、关系生成和图谱维护
        """</span>
        self<span class="token punctuation">.</span>config <span class="token operator">=</span> config
        <span class="token comment" spellcheck="true"># 初始化图数据库存储</span>
        self<span class="token punctuation">.</span>graph_store <span class="token operator">=</span> GraphStoreFactory<span class="token punctuation">.</span>create<span class="token punctuation">(</span>
            self<span class="token punctuation">.</span>config<span class="token punctuation">.</span>graph_store<span class="token punctuation">.</span>provider<span class="token punctuation">,</span> self<span class="token punctuation">.</span>config<span class="token punctuation">.</span>graph_store<span class="token punctuation">.</span>config
        <span class="token punctuation">)</span>
        <span class="token comment" spellcheck="true"># 初始化LLM用于实体和关系提取</span>
        self<span class="token punctuation">.</span>llm <span class="token operator">=</span> LlmFactory<span class="token punctuation">.</span>create<span class="token punctuation">(</span>self<span class="token punctuation">.</span>config<span class="token punctuation">.</span>llm<span class="token punctuation">.</span>provider<span class="token punctuation">,</span> self<span class="token punctuation">.</span>config<span class="token punctuation">.</span>llm<span class="token punctuation">.</span>config<span class="token punctuation">)</span>
        <span class="token comment" spellcheck="true"># 初始化嵌入模型用于语义相似度计算</span>
        self<span class="token punctuation">.</span>embedding_model <span class="token operator">=</span> EmbedderFactory<span class="token punctuation">.</span>create<span class="token punctuation">(</span>
            self<span class="token punctuation">.</span>config<span class="token punctuation">.</span>embedder<span class="token punctuation">.</span>provider<span class="token punctuation">,</span>
            self<span class="token punctuation">.</span>config<span class="token punctuation">.</span>embedder<span class="token punctuation">.</span>config<span class="token punctuation">,</span>
            self<span class="token punctuation">.</span>config<span class="token punctuation">.</span>vector_store<span class="token punctuation">.</span>config<span class="token punctuation">,</span>
        <span class="token punctuation">)</span>
        
    <span class="token keyword">def</span> <span class="token function">add</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> message<span class="token punctuation">,</span> filters<span class="token operator">=</span>None<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""
        向知识图谱添加新信息
        实现从文本中提取实体和关系并构建知识图谱
        """</span>
        filters <span class="token operator">=</span> filters <span class="token operator">or</span> <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;&amp;#125;</span>
        
        <span class="token comment" spellcheck="true"># 1. 使用LLM提取实体</span>
        <span class="token comment" spellcheck="true"># 实体提取模块：从文本中识别相关实体及其类别</span>
        entity_prompt <span class="token operator">=</span> self<span class="token punctuation">.</span>_get_entity_extraction_prompt<span class="token punctuation">(</span>message<span class="token punctuation">)</span>
        entity_response <span class="token operator">=</span> self<span class="token punctuation">.</span>llm<span class="token punctuation">.</span>generate_response<span class="token punctuation">(</span>
            messages<span class="token operator">=</span><span class="token punctuation">[</span><span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;"role": "user", "content": entity_prompt&amp;#125;],</span>
            response_format<span class="token operator">=</span><span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;"type": "json_object"&amp;#125;,</span>
        <span class="token punctuation">)</span>
        
        <span class="token keyword">try</span><span class="token punctuation">:</span>
            <span class="token comment" spellcheck="true"># 解析LLM返回的实体列表</span>
            entity_response <span class="token operator">=</span> remove_code_blocks<span class="token punctuation">(</span>entity_response<span class="token punctuation">)</span>
            entity_data <span class="token operator">=</span> json<span class="token punctuation">.</span>loads<span class="token punctuation">(</span>entity_response<span class="token punctuation">)</span>
            entities <span class="token operator">=</span> entity_data<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">"entities"</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
            
            <span class="token comment" spellcheck="true"># 如果没有提取到实体，直接返回</span>
            <span class="token keyword">if</span> <span class="token operator">not</span> entities<span class="token punctuation">:</span>
                <span class="token keyword">return</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
                
            <span class="token comment" spellcheck="true"># 2. 使用LLM生成实体间关系</span>
            <span class="token comment" spellcheck="true"># 关系生成模块：根据上下文建立实体之间的语义关系</span>
            relation_prompt <span class="token operator">=</span> self<span class="token punctuation">.</span>_get_relation_extraction_prompt<span class="token punctuation">(</span>message<span class="token punctuation">,</span> entities<span class="token punctuation">)</span>
            relation_response <span class="token operator">=</span> self<span class="token punctuation">.</span>llm<span class="token punctuation">.</span>generate_response<span class="token punctuation">(</span>  <span class="token comment" spellcheck="true"># 核心还是构建prompt+调用大模型的方式</span>
                messages<span class="token operator">=</span><span class="token punctuation">[</span><span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;"role": "user", "content": relation_prompt&amp;#125;],</span>
                response_format<span class="token operator">=</span><span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;"type": "json_object"&amp;#125;,</span>
            <span class="token punctuation">)</span>
            
            <span class="token comment" spellcheck="true"># 解析LLM返回的关系列表</span>
            relation_response <span class="token operator">=</span> remove_code_blocks<span class="token punctuation">(</span>relation_response<span class="token punctuation">)</span>
            relation_data <span class="token operator">=</span> json<span class="token punctuation">.</span>loads<span class="token punctuation">(</span>relation_response<span class="token punctuation">)</span>
            relations <span class="token operator">=</span> relation_data<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">"relations"</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
            
            <span class="token comment" spellcheck="true"># 3. 将实体和关系添加到图数据库中</span>
            added_entities <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
            <span class="token keyword">for</span> relation <span class="token keyword">in</span> relations<span class="token punctuation">:</span>
                <span class="token comment" spellcheck="true"># 处理头实体</span>
                source_entity <span class="token operator">=</span> relation<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">"source"</span><span class="token punctuation">)</span>
                source_entity_type <span class="token operator">=</span> relation<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">"source_type"</span><span class="token punctuation">)</span>
                
                <span class="token comment" spellcheck="true"># 处理尾实体</span>
                target_entity <span class="token operator">=</span> relation<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">"target"</span><span class="token punctuation">)</span> 
                target_entity_type <span class="token operator">=</span> relation<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">"target_type"</span><span class="token punctuation">)</span>
                
                <span class="token comment" spellcheck="true"># 处理关系</span>
                relationship <span class="token operator">=</span> relation<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">"relationship"</span><span class="token punctuation">)</span>
                
                <span class="token comment" spellcheck="true"># 将实体和关系信息添加到图数据库</span>
                <span class="token keyword">if</span> source_entity <span class="token operator">and</span> target_entity <span class="token operator">and</span> relationship<span class="token punctuation">:</span>
                    <span class="token comment" spellcheck="true"># 为实体和关系生成向量嵌入，用于后续相似性检索</span>
                    source_entity_embeddings <span class="token operator">=</span> self<span class="token punctuation">.</span>embedding_model<span class="token punctuation">.</span>embed<span class="token punctuation">(</span>source_entity<span class="token punctuation">,</span> <span class="token string">"add"</span><span class="token punctuation">)</span>
                    target_entity_embeddings <span class="token operator">=</span> self<span class="token punctuation">.</span>embedding_model<span class="token punctuation">.</span>embed<span class="token punctuation">(</span>target_entity<span class="token punctuation">,</span> <span class="token string">"add"</span><span class="token punctuation">)</span>
                    
                    <span class="token comment" spellcheck="true"># 添加到图数据库并记录结果</span>
                    result <span class="token operator">=</span> self<span class="token punctuation">.</span>graph_store<span class="token punctuation">.</span>add_triple<span class="token punctuation">(</span>
                        source<span class="token operator">=</span>source_entity<span class="token punctuation">,</span>
                        source_type<span class="token operator">=</span>source_entity_type<span class="token punctuation">,</span>
                        relationship<span class="token operator">=</span>relationship<span class="token punctuation">,</span>
                        target<span class="token operator">=</span>target_entity<span class="token punctuation">,</span>
                        target_type<span class="token operator">=</span>target_entity_type<span class="token punctuation">,</span>
                        source_embedding<span class="token operator">=</span>source_entity_embeddings<span class="token punctuation">,</span>
                        target_embedding<span class="token operator">=</span>target_entity_embeddings<span class="token punctuation">,</span>
                        metadata<span class="token operator">=</span>filters
                    <span class="token punctuation">)</span>
                    
                    added_entities<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;</span>
                        <span class="token string">"source"</span><span class="token punctuation">:</span> source_entity<span class="token punctuation">,</span>
                        <span class="token string">"source_type"</span><span class="token punctuation">:</span> source_entity_type<span class="token punctuation">,</span>
                        <span class="token string">"relationship"</span><span class="token punctuation">:</span> relationship<span class="token punctuation">,</span>
                        <span class="token string">"destination"</span><span class="token punctuation">:</span> target_entity<span class="token punctuation">,</span>
                        <span class="token string">"destination_type"</span><span class="token punctuation">:</span> target_entity_type
                    <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#125;)</span>
            
            <span class="token keyword">return</span> added_entities
            
        <span class="token keyword">except</span> Exception <span class="token keyword">as</span> e<span class="token punctuation">:</span>
            logger<span class="token punctuation">.</span>error<span class="token punctuation">(</span>f<span class="token string">"Error in entity/relation extraction: &amp;#123;e&amp;#125;"</span><span class="token punctuation">)</span>
            <span class="token keyword">return</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
            
    <span class="token keyword">def</span> <span class="token function">_get_entity_extraction_prompt</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> message<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""
        生成实体提取的提示词
        指导LLM识别文本中的各类实体
        """</span>
        <span class="token keyword">return</span> <span class="token triple-quoted-string string">"""You are an entity extraction system. Your task is to identify the most important entities in the given text.
        
        An entity can be a person, place, organization, product, or concept. For each entity, provide its type.
        
        Format your response as a JSON object with a single key "entities", containing a list of entity objects.
        Each entity object should have "name" (the entity) and "type" fields.
        
        Here is the text to analyze:
        
        /```
        &amp;#123;message&amp;#125;
        /```
        
        JSON Response:
        """</span><span class="token punctuation">.</span>format<span class="token punctuation">(</span>message<span class="token operator">=</span>message<span class="token punctuation">)</span>
    
    <span class="token keyword">def</span> <span class="token function">_get_relation_extraction_prompt</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> message<span class="token punctuation">,</span> entities<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""
        生成关系提取的提示词
        指导LLM识别已提取实体之间的关系
        """</span>
        entity_names <span class="token operator">=</span> <span class="token punctuation">[</span>e<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">"name"</span><span class="token punctuation">)</span> <span class="token keyword">for</span> e <span class="token keyword">in</span> entities<span class="token punctuation">]</span>
        entity_str <span class="token operator">=</span> <span class="token string">", "</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>entity_names<span class="token punctuation">)</span>
        
        <span class="token keyword">return</span> <span class="token triple-quoted-string string">"""You are a relationship extraction system. Your task is to identify meaningful relationships between the entities in the given text.
        
        Text:
        /```
        &amp;#123;message&amp;#125;
        /```
        
        Entities: &amp;#123;entities&amp;#125;
        
        For each relationship you identify, specify:
        1. The source entity
        2. The type of the source entity
        3. The relationship (a verb or phrase describing how entities are connected)
        4. The target entity
        5. The type of the target entity
        
        Only create relationships that are explicitly or strongly implied in the text.
        Format your response as a JSON object with a single key "relations", containing a list of relationship objects.
        
        JSON Response:
        """</span><span class="token punctuation">.</span>format<span class="token punctuation">(</span>message<span class="token operator">=</span>message<span class="token punctuation">,</span> entities<span class="token operator">=</span>entity_str<span class="token punctuation">)</span>
</code></pre>
<p>Mem0g 通过 <strong>图数据库</strong> Neo4j进行节点和边的检索。具体来说，Mem0g 会计算新提取的实体与现有节点之间的语义相似度，并根据阈值决定是否更新或添加新的节点和关系。这种操作也是通过 FC 来完成的。</p>
<p><strong>记忆检索功能</strong> 则是其与 Mem0 另一个显著的区别点。Mem0g 在处理查询时，采用了 <strong>双重检索策略</strong>，一方面是基于 <strong>实体</strong> 的检索，首先通过识别查询中的关键实体并在图中找到相应节点，之后探索这些节点的关联关系及对应的尾实体。另一方面，Mem0g 采用 <strong>语义三元组检索</strong>，即通过将整个查询转换为一个 <strong>向量表示</strong>，与图中的三元组进行匹配。（就是两种检索策略叠加使用，以期获得更全面的信息）</p>
<h3 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h3><p>在长对话记忆评测基准 <a target="_blank" rel="noopener" href="https://zhida.zhihu.com/search?content_id=258720927&content_type=Article&match_order=1&q=LOCOMO&zhida_source=entity">LOCOMO</a> 上，将 Mem0 和 Mem0-g 与六大类基线方法进行了全面对比，包括已有的记忆增强系统、多种配置的RAG、全上下文方法、开源记忆方案以及商业平台。</p>
<blockquote>
<p>LOCOMO 包含 10 个长对话，每个对话约 600 轮、26000 tokens，跨多次会话。每个对话后有约 200 个问题及标准答案，问题类型包括 single-hop、multi-hop、temporal、open-domain</p>
</blockquote>
<p><strong>Evaluation Metrics</strong>：    </p>
<ul>
<li><p>Performance Metrics：</p>
<ul>
<li>**F1 Score (F1)**，传统的词级重叠指标；</li>
<li>**BLEU-1 (B1)**，单词级 BLEU 分数； </li>
<li>**LLM-as-a-Judge (J)**，综合评估回答的事实准确性、相关性、完整性和上下文适应性；</li>
</ul>
</li>
<li><p>Deployment Metrics：</p>
<ul>
<li><strong>Token Consumption</strong>（检索到的 context token 数量，反映系统的计算和成本效率）；Latency，测量Search Latency和Total Latency。</li>
</ul>
</li>
</ul>
<p><img src="https://cyan-1314223569.cos.ap-beijing.myqcloud.com/test/Pasted%20image%2020251019222809.png" alt="主实验结果"></p>
<p><img src="https://cyan-1314223569.cos.ap-beijing.myqcloud.com/test/Pasted%20image%2020251019223115.png" alt="效率实验结果"></p>
<p>在计算效率方面，Mem0 和 Mem0g 都显著优于<strong>全上下文处理</strong>方法，尤其是在响应时间和 p95 上，二者分别减少了 91% 和 85% 的延迟。此外，<strong>Mem0g 在存储效率上略有增加，因为其图结构需要更多的内存空间</strong>。</p>
<h3 id="My-Thoughts"><a href="#My-Thoughts" class="headerlink" title="My Thoughts"></a>My Thoughts</h3><p>Mem0 是 Agent Memory 领域的经典作，理解起来并不困难。</p>
<p>和 A-Mem 相比较，其实主要也就是两点不同，仍然是 Agent Memory 里最关键的两点：</p>
<ol>
<li><strong>记忆存储</strong>：Mem0 是摘要+最近消息引导大模型生成记忆，Mem0g 是图节点实体关系三元组形式，A-Mem 是笔记与链接形式；</li>
<li><strong>记忆更新</strong>：A-Mem 和 Mem0 基本都是通过 Agent 自主决策判断，通过与以往记忆比对，判定当前记忆如何操作。</li>
</ol>

                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/about" rel="external nofollow noreferrer">Cyan.</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://yukiiceeee.github.io/2025/10/20/lun-wen-mem0-building-production-ready-ai-agents-with-scalable-long-term-memory/">https://yukiiceeee.github.io/2025/10/20/lun-wen-mem0-building-production-ready-ai-agents-with-scalable-long-term-memory/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="/about" target="_blank">Cyan.</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/tags/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/">
                                    <span class="chip bg-color">论文笔记</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
                <div id="reward">
    <a href="#rewardModal" class="reward-link modal-trigger btn-floating btn-medium waves-effect waves-light red">赏</a>

    <!-- Modal Structure -->
    <div id="rewardModal" class="modal">
        <div class="modal-content">
            <a class="close modal-close"><i class="fas fa-times"></i></a>
            <h4 class="reward-title">你的赏识是我前进的动力</h4>
            <div class="reward-content">
                <div class="reward-tabs">
                    <ul class="tabs row">
                        <li class="tab col s6 alipay-tab waves-effect waves-light"><a href="#alipay">支付宝</a></li>
                        <li class="tab col s6 wechat-tab waves-effect waves-light"><a href="#wechat">微 信</a></li>
                    </ul>
                    <div id="alipay">
                        <img src="/medias/reward/alipay.jpg" class="reward-img" alt="支付宝打赏二维码">
                    </div>
                    <div id="wechat">
                        <img src="/medias/reward/wechat.png" class="reward-img" alt="微信打赏二维码">
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>

<script>
    $(function () {
        $('.tabs').tabs();
    });
</script>

            
        </div>
    </div>

    

    

    

    

    

    

    

    
        <style>
    .twikoo-card {
        margin: 1.5rem auto;
    }

    .twikoo-card .card-content {
        padding: 20px;
    }

    #tcomments textarea {
        box-sizing: border-box;
        background: url("/") 100% 100% no-repeat;
    }

    #tcomments p {
        margin: 2px 2px 10px;
        font-size: 1.05rem;
        line-height: 1.78rem;
    }

    #tcomments blockquote p {
        text-indent: 0.2rem;
    }

    #tcomments a {
        padding: 0 2px;
        color: #4cbf30;
        font-weight: 500;
        text-decoration: none;
    }

    #tcomments img {
        max-width: 100%;
        height: auto;
        cursor: pointer;
    }

    #tcomments ol li {
        list-style-type: decimal;
    }

    #tcomments ol,
    ul {
        display: block;
        padding-left: 2em;
        word-spacing: 0.05rem;
    }

    #tcomments ul li,
    ol li {
        display: list-item;
        line-height: 1.8rem;
        font-size: 1rem;
    }

    #tcomments ul li {
        list-style-type: disc;
    }

    #tcomments ul ul li {
        list-style-type: circle;
    }

    #tcomments table,
    th,
    td {
        padding: 12px 13px;
        border: 1px solid #dfe2e5;
    }

    #tcomments table,
    th,
    td {
        border: 0;
    }

    table tr:nth-child(2n),
    thead {
        background-color: #fafafa;
    }

    #tcomments table th {
        background-color: #f2f2f2;
        min-width: 80px;
    }

    #tcomments table td {
        min-width: 80px;
    }

    #tcomments h1 {
        font-size: 1.85rem;
        font-weight: bold;
        line-height: 2.2rem;
    }

    #tcomments h2 {
        font-size: 1.65rem;
        font-weight: bold;
        line-height: 1.9rem;
    }

    #tcomments h3 {
        font-size: 1.45rem;
        font-weight: bold;
        line-height: 1.7rem;
    }

    #tcomments h4 {
        font-size: 1.25rem;
        font-weight: bold;
        line-height: 1.5rem;
    }

    #tcomments h5 {
        font-size: 1.1rem;
        font-weight: bold;
        line-height: 1.4rem;
    }

    #tcomments h6 {
        font-size: 1rem;
        line-height: 1.3rem;
    }

    #tcomments p {
        font-size: 1rem;
        line-height: 1.5rem;
    }

    #tcomments hr {
        margin: 12px 0;
        border: 0;
        border-top: 1px solid #ccc;
    }

    #tcomments blockquote {
        margin: 15px 0;
        border-left: 5px solid #42b983;
        padding: 1rem 0.8rem 0.3rem 0.8rem;
        color: #666;
        background-color: rgba(66, 185, 131, .1);
    }

    #tcomments pre {
        font-family: monospace, monospace;
        padding: 1.2em;
        margin: .5em 0;
        background: #272822;
        overflow: auto;
        border-radius: 0.3em;
        tab-size: 4;
    }

    #tcomments code {
        font-family: monospace, monospace;
        padding: 1px 3px;
        font-size: 0.92rem;
        color: #e96900;
        background-color: #f8f8f8;
        border-radius: 2px;
    }

    #tcomments pre code {
        font-family: monospace, monospace;
        padding: 0;
        color: #e8eaf6;
        background-color: #272822;
    }

    #tcomments pre[class*="language-"] {
        padding: 1.2em;
        margin: .5em 0;
    }

    #tcomments code[class*="language-"],
    pre[class*="language-"] {
        color: #e8eaf6;
    }

    #tcomments [type="checkbox"]:not(:checked),
    [type="checkbox"]:checked {
        position: inherit;
        margin-left: -1.3rem;
        margin-right: 0.4rem;
        margin-top: -1px;
        vertical-align: middle;
        left: unset;
        visibility: visible;
    }

    #tcomments b,
    strong {
        font-weight: bold;
    }

    #tcomments dfn {
        font-style: italic;
    }

    #tcomments small {
        font-size: 85%;
    }

    #tcomments cite {
        font-style: normal;
    }

    #tcomments mark {
        background-color: #fcf8e3;
        padding: .2em;
    }

    #tcomments table,
    th,
    td {
        padding: 12px 13px;
        border: 1px solid #dfe2e5;
    }

    table tr:nth-child(2n),
    thead {
        background-color: #fafafa;
    }

    #tcomments table th {
        background-color: #f2f2f2;
        min-width: 80px;
    }

    #tcomments table td {
        min-width: 80px;
    }

    #tcomments [type="checkbox"]:not(:checked),
    [type="checkbox"]:checked {
        position: inherit;
        margin-left: -1.3rem;
        margin-right: 0.4rem;
        margin-top: -1px;
        vertical-align: middle;
        left: unset;
        visibility: visible;
    }
</style>

<div class="card twikoo-card" data-aos="fade-up">
    <div class="comment_headling" style="font-size: 20px; font-weight: 700; position: relative; padding-left: 20px; top: 15px; padding-bottom: 5px;">
        <i class="fas fa-comments fa-fw" aria-hidden="true"></i>
        <span>评论</span>
    </div>
    <div class="card-content" style="display: grid">
        <div id="tcomments"></div>
    </div>
</div>

<script src="/libs/twikoo/twikoo.all.min.js"></script>
<script>
    twikoo.init({
        envId: 'https://mt-twikoo-repo.vercel.app/',
        el: '#tcomments',
        region: '',
        path: ''
    }).then(function () {
        var tkInputs = document.querySelector('#twikoo').getElementsByTagName('input');
        for (var tkInputsIndex = 0; tkInputsIndex < tkInputs.length; tkInputsIndex++) {
            if (tkInputs[tkInputsIndex]) {
                tkInputs[tkInputsIndex].classList.add('browser-default');
            }
        }
    });
</script>

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/2025/10/25/xue-xi-function-calling-mcp/">
                    <div class="card-image">
                        
                        <img src="https://cyan-1314223569.cos.ap-beijing.myqcloud.com/test/Pasted%20image%2020251025135841.png" class="responsive-img" alt="Function Calling and MCP">
                        
                        <span class="card-title">Function Calling and MCP</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Function Calling 是让大模型具备工具调用能力的关键。通过 SFT 等 post-train 手段，我们可以让大模型遵循指令生成一个特定格式的 tools 调用文件（xml, json），并通过代码解析该文件来确定当前对话轮次要调用的 function 信息。而 MCP 对这一过程做了标准化，提供了统一的接口与服务。
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-10-25
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-user fa-fw"></i>
                            Cyan.
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">
                        <span class="chip bg-color">学习笔记</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/2025/10/18/xue-xi-build-an-agentic-rag-system/">
                    <div class="card-image">
                        
                        <img src="https://cyan-1314223569.cos.ap-beijing.myqcloud.com/test/kappframework-Zbogca(1)(1).png" class="responsive-img" alt="Build an Agentic RAG System">
                        
                        <span class="card-title">Build an Agentic RAG System</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Agentic RAG 相比传统的一步检索式 Native RAG 有了更卓越的表现，通过牺牲了一些推理时间来换取了更令人满意的效果。本质上就是利用 Agent 多步决策的思路，使模型在检索相关文档时能够有思考、回退、改写等等决策，而不是简单地根据相似度直接得到结果。
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-10-18
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-user fa-fw"></i>
                            Cyan.
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">
                        <span class="chip bg-color">学习笔记</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/libs/codeBlock/codeBlockFuction.js"></script>



<!-- 代码语言 -->

<script type="text/javascript" src="/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>

    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="2193335871"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/libs/aplayer/APlayer.min.js"></script>
<script src="/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 0px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2023-2025</span>
            
            <a href="/about" target="_blank">Cyan.</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- 运行天数提醒. -->
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/yukiiceeee" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:Yukiice27@outlook.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>







    <a href="tencent://AddContact/?fromId=50&fromSubId=1&subcmd=all&uin=849379190" class="tooltipped" target="_blank" data-tooltip="QQ联系我: 849379190" data-position="top" data-delay="50">
        <i class="fab fa-qq"></i>
    </a>







</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- 白天和黑夜主题 -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/libs/materialize/materialize.min.js"></script>
    <script src="/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/libs/aos/aos.js"></script>
    <script src="/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/js/matery.js"></script>

    <canvas class="fireworks" style="position: fixed;left: 0;top: 0;z-index: 1; pointer-events: none;" ></canvas> 
    <script type="text/javascript" src="//cdn.bootcss.com/animejs/2.2.0/anime.min.js"></script> 
    <script type="text/javascript" src="/js/fireworks.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // 只在桌面版网页启用特效
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/libs/others/sakura.js"><\/script>');
            }
        </script>
    

    <script type="text/javascript">
        //只在桌面版网页启用特效
        var windowWidth = $(window).width();
        if (windowWidth > 768) {
            document.write('<script type="text/javascript" src="/js/sakura.js"><\/script>');
        }
        </script>

    <script src="/js/cursor.js"></script>

    <!--动态线条背景-->
    <script type="text/javascript"
    color="122 103 238" opacity='0.7' zIndex="-2" count="200" src="//cdn.bootcss.com/canvas-nest.js/1.0.0/canvas-nest.min.js">
    </script>

    <!-- 雪花特效 -->
    

    <!-- 鼠标星星特效 -->
     
        <script type="text/javascript">
            // 只在桌面版网页启用特效
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/libs/others/star.js"><\/script>');
            }
        </script>
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
        <script type="text/javascript">
            // 只在桌面版网页启用特效
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/libs/others/clicklove.js"><\/script>');
            }
        </script>
    
    
    <script async src="https://unpkg.com/busuanzi.pure.js@2.3.0/busuanzi.pure.mini.js"></script>
    

    

    

    <!--腾讯兔小巢-->
    
    

    

    

    
    <script src="/libs/instantpage/instantpage.js" type="module"></script>
    

    <script type="text/javascript">
    	var OriginTitile=document.title,st;
        document.addEventListener("visibilitychange",function(){
            document.hidden?(document.title="ヽ(●-`Д´-)ノ你要玩捉迷藏嘛",clearTimeout(st)):(document.title="(Ő∀Ő3)ノ好哦！",st=setTimeout(function(){document.title=OriginTitile},3e3))
        })
    </script>
</body>

</html>
